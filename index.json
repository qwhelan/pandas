{"project": "pandas", "project_url": "https://pandas.pydata.org/", "show_commit_url": "https://github.com/pandas-dev/pandas/commit/", "hash_length": 8, "revision_to_hash": {"288": "4906ee79d730f77be02ec586ec7f66c95a0433da", "862": "9e406c50b77949433ed8f7fd094fd30b5421a35e", "874": "645d61131ad5acf768fff906a25e9e34b53efb92", "926": "cdc607c8ebd05419c0c446298a89814eac817459", "933": "ba1ff88c95b081741eb28c8630aaa6b0423900e0", "981": "35c6b68facf00788e9092d1fcedd53acbf99be89", "1029": "a8b14798fe18050e486845b26370d4899f46a8b3", "1084": "a0aa6a96d8a2456523d9f407d3f9f936f24dd7c8", "1185": "8f79f7c6e01874bbf7f3b9bc38af01551c90121e", "1192": "cf32be202dff38f92f10c792cbcae5c2f2ebaaf1", "1194": "da3e95da95e1e07acc535b8e734b9b80a0972609", "1342": "010a620da89e5babc137b924dd1f632b4f6e6fee", "1440": "d5fbdcc26520d1c92b5dd73bb6e9a9902756ad16", "1632": "2ca93a17ed4609960f0ee3b8704b8b2edca1db5b", "1812": "06f608182ecd516abcd140531c65e07b30293eb0", "2072": "13f5db0ac0ba5a30d64866cdbd02b9985efa6303", "2077": "abc59ab02622560f226dd32bd068857053bc96d0", "2196": "776d80c2145ce4a4df1cf5c9ad21140b09df671d", "2197": "a2e86c20f893075ed8efe6c199507582c4880df6", "2247": "483ca398bd20ae42dd1a9d12f972634b384d560b", "2358": "4117b4fde3ffbc74a48b01f3a28f1f76b2db05fd", "2539": "9d0949396a8533d9fb9b0a6d0fb90a9f0ac16b23", "2555": "dfd7447e47562a941bb355af51c475823520f9e3", "3088": "5b98fdfeae2ef42d78242c4cca1e0959b9c710db", "3276": "fde270b20861fbf36d3063d504fb299d0b58695b", "3280": "a1d768829015796d16486cbc1e99020348901e25", "3358": "1c08383fc3cf24d503ae221c5d31b93899da6473", "3374": "5f5df2aa34f027d3fc83abb19cf7840ababd4557", "3375": "5d90f7d0e7e9bb53e55fdb7b70f972aa502004ed", "3407": "c91f6d1f62d02a65af78651f61f8db9a62c58b1b", "3426": "a901af2cdfe411d6aa9f9b1f6fa3223738f3e514", "3432": "f5a1bc9cda068f724d2de2ddc0da8ac2c518095b", "3509": "1c24700c3ba74419988e74319fd46e1f937c1f4d", "3566": "4e95b311bbf320d7b88edd6f8ce17194e48b8145", "3572": "23fa6f8b3d1f823dbafb64dc52e5a96fefe9236c", "3927": "e1b6e44bed02f47f59bf2d71c836f42f6e130dea", "3970": "6d9bd5a6374f1d6b4c18d3d53fc0413c82a16b49", "4041": "b5956fdc123b0208cf36fafc1b80a9671c66efbb", "4264": "2d576ee9b9337210a8c85f11e48177db42ecd57f", "4306": "9867f8af6e20cd2248626548f9b3f9a66b57789c", "4741": "78ce0ce8baef9c66bbee77083c0d12a47d5e294f", "4834": "1751bae723d336904bca81945097b3b700b11801", "5044": "31ecaa9d06f71b5d652d15441cf6b2dcc6f7e640", "5790": "258c7e3c5ec5dca7bec32308925b94267fbcff61", "5886": "f9eea308611152f1f7bb89981380fa5d85685f48", "6687": "b96ab6bddd5f2e84bd88a0659c4d98154819cffc", "6817": "8c0a34f15f8a87def3f7ad6ebdac052de44669f2", "8008": "16052e501adc3dedec3bf8cf65a7ea24300de1b1", "8164": "a5410ed841759badae2c3fe4cc71335c9dd6ad92", "8259": "db18d443dc0eac6454b864e179579619493899dc", "8352": "48c005ea761adcaf6b76a84aa94da0d35db8c6d6", "8705": "d10a658673b7d2c2e7a346461c9a4bfc5233d7e1", "9657": "76f6cf0050025ec5a6187e17957ea9a158cc2d56", "9753": "da0f7ae362bb0ee747c3c5c141327d1d8ba161bc", "10180": "d839555f5e080a981ce5faf89b4df7dfe0924541", "10541": "12248ffc942acf3a224922495102462c6999c804", "10833": "8dfbe09c1443334fc3036465712195a36c773f4b", "10893": "017adeaa4b70d63fe6c788db457dc9d31562f4d6", "10996": "d8ab3415373ea42713c096a97c3d9ed5c9cb82ee", "11082": "f1b270fcf5d505eebe4bf964f0541d6a43c3560e", "11228": "18ea1d856d45c87fe18a41d1a267ede46e10880e", "11578": "9e859f40c1651b38f9528aaccd211b1706cf317e", "11634": "c91bdbadfdbf9f60879ead8dd86bd1e72ca18ccf", "11993": "ca9eefc3c4733f368c054e33537ff18384114b43", "12164": "06832891870119984c6a5404bc7f7a471f43b99c", "12178": "6b1055c765c488e6fb411eed452abf75ff8df4bb", "12823": "9687145e06aed545c14630460d24a9693c9a0b39", "12968": "071cffd63e4b99362c68a5e2d472b629618c50a1", "12997": "fe48704835323c140846d1bde5e1387aa0cac3d4", "13266": "6c30cbecf8e5ae610f2a37ba821116bd9f77044d", "13628": "9259a56c600f6ea247a9c58c00af017790fe5e21", "13719": "e5ed87b33ab6cd9dade10df945bc5d7452310b7d", "13730": "e462ece64b7cb12fe7cad6e085f62f3bfe9785c6", "13940": "87b0f4dc1e91571cc4dd933b7cb181b99606ad20", "14386": "497a3bcbf6a1f97a9596278f78b9883b50a4c66f", "14434": "b97dbd01e49f54ae6fa8df382d6f6e4c771d2bc0", "14539": "27b783986230a3d044d045604b72a51acd13b7be", "14810": "825876ca7ee8ac7bea463925399c083d5f190b3e", "15404": "19fc8dac68e088126ffd132dc322dbf8a163ec69", "15461": "2002da33b0a755fcf7ef64b2c87ca4252f0e7df0", "15469": "a31c96d34d00dc757908b564dc93991e867d83e2", "15475": "e346c663cf76186c22f4d3b703461b1b60db280f", "15476": "e5134306bd47db9f6d0f125d2cafd0b8a789e065", "15678": "2814061730893bc8122caa4e01197c699da352e6", "15790": "3a7f956c30528736beaae5784f509a76d892e229", "16199": "c277cd76416d4e930b1f05da873b9eaf101139da", "16245": "81372093f1fdc0c07e4b45ba0f47b0360fabd405", "16246": "fc1e50733ea4c372f4c9eb3a53bf35e102d5d215", "16696": "7bb204a05fee20c3c825e7da39ccaf39fbeb8ca5", "16798": "fae79204e2b60ac1ff2b2309352ffb5d9382a017", "16825": "a00154dcfe5057cb3fd86653172e74b6893e337d", "16905": "8acdf801c501a0ce2ac14ddd676cd248f0f32180", "17457": "3e14b8d7cfa1ee2016d4af7541783187c7f2c1c1", "17634": "44ccca1f3c27795322b979cf6e5dbd49422b5173", "17636": "b02c69ac7309ccf63a17471b25475bf0c0ebe3c3", "17693": "3147a86e1b20571766b488a8444c74cef29729ad", "17694": "2eb5a67999552d60f7a2a9e1922549d5417d714f", "17755": "1a23779f09abc6ebf908d66ee88b973b767e2e3c", "17792": "9b0f560a73d11b2fa72c48d7fd16126b5137f349", "17796": "edb71fda022c6a155717e7a25679040ee0476639", "17804": "0409521665bd436a10aea7e06336066bf07ff057", "18009": "117d0b1011c090b4658b0e84c2b572ee713e21de", "18215": "6703ace009a5a52c6be70c86e618cb3aee34a04a", "18268": "de39bfc5e5c6483cb2669773fa10ddc2e32ca111", "18279": "6b9318c132f53fd4e2ca588c67c16249b75c3b16", "18280": "555adc2497746986e24e471beba61c40031f3cbf", "18281": "2eef8652fac582978a3828ac307b808c739932ad", "18365": "ce62a5c12069c3ac54c65fdca41d3c0a473b3dfb", "18438": "2d766b60a6f9416bbc8a552a66d8eac886a030bf", "18613": "08395af43b813b69b1cf038d260104cfeeb3e787", "18624": "d7e96d830c3f765565d2fd9d3f80f888fa261f02", "18625": "1d3ed917638b9890e0410fa996a447c4a780429e", "18665": "a102b0c942b532026d45a4946fc95addbd942ac8", "18826": "08c920eab602dac261b8fe55ffe439593c095e12", "18839": "3086e0a170934d87b01fa910f371002a55fd07b9", "18854": "f4f37f458d5f1d00b84b48534550fdd3a365f432", "18855": "c1af4f5ede3f6dfb1d1652c62afbcdc88b5eef91", "18862": "80295f9483176b1335226680f1b55f09ded9ad46", "18873": "41b2b18b94ade34a172483cf8307ce16bbbfc7c1", "18875": "02a97c0a150377fab02fa22580d232c8242b5baa", "18916": "d89b2a62d9f0d86ff883d253cc0aef8f5e892e56", "18958": "62506ca3c37b6b0d84833a8329e50c000316250e", "18974": "917538735504bcbae91b904ec24bf683a13d0846", "18986": "cb31b2b0912c99e40b22a26e598e640548ea8f14", "19011": "f074abef5b3b59d072cc4568949673a39bf58dd1", "19067": "c1a81fe512604ff1b241e688d145dc7628558241", "19068": "fdc4db25a9988a7b595a3756760d05a6c177123d", "19069": "33f91d8f9f2e84f2b5f3ac3f0481b691c977c427", "19097": "17a6bc56e5ab6ad3dab12d3a8b20ed69a5830b6f", "19128": "853cd7031ff98737b9a50404c4a181dcda67a0be", "19143": "5761e359b65631db491349a65fc21d0da51dcc0f", "19152": "14b68eabb4b7750c04ccd3ed17247504aceae35a", "19153": "8a8a0830f5a021f7c8d272fabdfa699b4502edd3", "19154": "c8aae3540e4d22d2581e66843740fba10e9ea0b1", "19155": "83eb2428ceb6257042173582f3f436c2c887aa69", "19156": "0c4113fa0906273007cc12a4bcadff85d943dc84", "19169": "95f8dca47723192ddeed5a2f198d0521c687c9aa", "19250": "1700680381bdbfbc1abe9774f96881801b24d6ca", "19314": "3ab9318f2c0806a7fd38d4b4dc47bf6c3803c1e7", "19403": "cc5b73e9807e5d4527fdd36187ebd11d744217de", "19491": "cb00deb94500205fcb27a33cc1d0df79a9727f8b", "19501": "10173821965fa65654b172891b2102a8426132ca", "19511": "64f5961798438f09f2c6b6c474065909f5ebc336", "19538": "fc24c2cdbc1e63d5bfd6726fddd14a4c925d3580", "19567": "72f4098ca91fb7f9051021b0f78adecec3f28fdf", "19635": "fa9c7de77ab09835cd0ce883623111cd9af68811", "19645": "2769ebf3da8d9c2869ba5811ae9409d84b0cf28a", "19726": "d86553b00fe263d264bd0b2ce691724591dc7b01", "19733": "aad77394b14f1997786850e6110154d4c78faffd", "19738": "68b1da7f53f043b21e3f722e8872e19941a10250", "19785": "88062f75dbca929ec082295c936edd07cc912dbf", "19798": "48ea04fe5d3ba9b618152ae83aef703dbbb2c3f4", "19836": "ca1a36ab3a793d9a87900537de066fa676cbf237", "19852": "cf9ed41a51211027e313261a4001b74adb17ad9f", "19913": "b99e84fb1d3bfa3506bf067bcdd0628ec7ace40c", "19986": "c57f206360108c327d8256e716080fb1a2523fd8", "19989": "8ef9a6356f9f00e22908dd04aa47b2a5d6c38725", "19990": "e0c41f79104c5bc61952c9a14f1883cd5bda53f7", "20000": "649ad5c91aabb95d7f200eec84b82cae1459fc65", "20004": "3ff4f38f2b4572af92946af9ce9d50481413358d", "20005": "cdc07fde42c86f52c37fbf68a55a40452b0db28d", "20007": "9a67ff478a2e9fb8c78e43fee348bbdb26d6d9d4", "20027": "0f3e8e8bd2118d56c7febe5d6081c5058cb22be7", "20038": "d47fc0cba3cf94ebd289ad3776bf7ff3fe60dfb8", "20043": "13023c6515ca11a3353d98645f48a403243101cf", "20115": "a14874f3e85bae66c32ab1ae4c1cd8a72e741ffe", "20123": "cf74b0272af2e13e5b9ce40c8bf42df750ddc560", "20150": "19d5d53988dbfa58ce1ecc3d83b7025e4171a6e5", "20151": "d94146cf5d5d9f899a31308d0a4d9e5d132f6442", "20152": "edf5ae8585a5cc45ab0a95d924555fd9ec2576d7", "20153": "e9555159afd8caabc88b45ca6c06a16efe2f6afc", "20154": "1452e714bd3484d8da1bc060357e619e9de97c11", "20155": "c1673cf42e2827c06b16c3f9bc2affd9df7c311a", "20156": "b80df7b7ea216f119cab87eb6fd2c4c6b81b3303", "20157": "f8b0b9fa2b5811a8c49d7096dbe47254e341054e", "20158": "38ab7523c15d09e23c538755703aeb338ec35a1c", "20159": "27f9d05aa3852741571e274681512423c441f72d", "20160": "b387da894076c7427ba7a2fb467c3e821a2cef27", "20161": "46cd7f0dd56a7189c46412cd873abc0735f38748", "20162": "1c0eb45803f7c901d5cd04480e0b4327912a01c2", "20163": "f5131913b32b756bc72d6dd33ecd4c52369edd3b", "20164": "8b48f5c75a058c239a5d0eb9ee4f1593f1be1810", "20165": "de0867f8bedab9ce7d8d4f46267c4c123ff3166c", "20166": "ce86c21ce7c64089d488965821ac36ac6eddddc9", "20167": "08a599b3478b5fb7d9e6edf6b9e0278809e6ac7b", "20168": "87d7cdf2600223f67df4b73edac4252d71155c9f", "20169": "bd72942eac5c175942034cdb8b8dcf96cb562084", "20170": "a65b2e31258d69cddc0810a7645a3c4eb9ee3d91", "20171": "cfb9bbe5a15f8ca3a133b396c5b90494c095e26f", "20172": "de22a483ace1c0cb1ff6ac1d245c4afe5e514ce6", "20173": "c3133dbebb8442773ab5a6453d78dfbde4742219", "20174": "e9f9ca1f18f22215bb32cfd182f69997792b50e4", "20175": "71379386cdbf4db38718e0f344c8b7ac7035d474", "20176": "45ea26763da832189747ac9f86630fece84b4f18", "20177": "6af58407cd5ac56ca11f5dffc1fd9b636ad68fb6", "20178": "4ef793f2658bd7c8752e604548e55c2bcdd82d7b", "20179": "a272b60aabc2a3b4128a7365e9b2b0080bcd5121", "20180": "be4b48e7a3a2a9ef1e636bafb6c332bc3a50e2de", "20181": "1be0561df529ef0597465c6dfe023e34f7dd6d4d", "20182": "b618eb6ecb19f243f9f68e73f56a67f3f629e09d", "20183": "3a53954a86df1d321b3c4ea766905f25bb225adc", "20184": "9693230aa0637c5856587a34485d3e411599d0f4", "20185": "ad18ea35ba461a92b1ea2204f4edc55bb42e9d71", "20186": "497c4ebe2ff87b3ee8ab6f7ba44ef15bb5d36c0d", "20187": "110c02f4e2fa3884057ef3520484ec006fb969ec", "20188": "d7d26bed4365d33f6f47f54fbe3b4221c52fe098", "20189": "dd11fc22a3e76721e2c6634cc7c68840f5f1b636", "20190": "f331c5610afb2bd5f36f983004799ea9e1545969", "20191": "d050791acd77849246d9da4a70f6c71ccc59a633", "20192": "989f912eec97df2ebd921a1423534e4d49133e12", "20193": "b640530a788206fb445a7295fafdf9ed53b78567", "20194": "67eec4eefdf8a77082efe149301c0342bb803e5e", "20195": "cb5b75b0916e037fdd141ce1648521e2832a4d51", "20196": "14e1c5a5469db2bfa3ba2682955427caf458b00f", "20197": "2811464a87e6e18f5daef87ee700075ebd8a5e7d", "20231": "355e322b5ed4a31c9e1cab9652510e85a54f23a3", "20273": "2efb60717bda9fc64344c5f6647d58564930808e", "20274": "a61218d9ed92eeb31c83fa6517a740c54d907f5d", "20278": "1219b0fb0d8e07b5018381a0bd8e0b4b89029dc7", "20362": "a4c19e7aea4989f42dd021313af7523ed52fea3b", "20377": "d1accd032b648c9affd6dce1f81feb9c99422483", "20378": "ed0c598946b0309575f57e1886d498a6ed41021b", "20389": "9bab81e013af33084c48b54dc2a6ef188acfd225", "20398": "5bd57f90c3e8a714c77ca559d63409644c36c5ef", "20591": "be6c3690040642cdcbf0c93025af2527a2fb1df4", "20594": "6665f20086d374efcecd82fa34fe3da7adac2e53", "20700": "171c71611886aab8549a8620c5b0071a129ad685", "21099": "0efc71b53f019c6c5a8da7a38e08646ca75c17d9", "21236": "62a87bf4a2af02a8d3bc271ad26e5994292b8e6a", "22249": "d3f08566a80239a18a813ebda9a2ebb0368b1dc5", "22257": "f887eb09ba19311408717c0bed1f36732ab8f71a", "22258": "ea360858d0ac7057547850b23ab94b87f81d8529"}, "revision_to_date": {"288": 1298163988000, "862": 1315859521000, "874": 1316017084000, "926": 1317000085000, "933": 1317048249000, "981": 1317617173000, "1029": 1318197429000, "1084": 1318951906000, "1185": 1319509932000, "1192": 1320022791000, "1194": 1320196542000, "1342": 1322277354000, "1440": 1323817436000, "1632": 1325734840000, "1812": 1327034032000, "2072": 1328826175000, "2077": 1328843532000, "2196": 1330553078000, "2197": 1329737298000, "2247": 1330658997000, "2358": 1331927660000, "2539": 1334253112000, "2555": 1334276689000, "3088": 1338253482000, "3276": 1339519295000, "3280": 1339521874000, "3358": 1340247840000, "3374": 1340393682000, "3375": 1340394271000, "3407": 1340820112000, "3426": 1340986814000, "3432": 1340991466000, "3509": 1342184152000, "3566": 1342986141000, "3572": 1343003671000, "3927": 1348197360000, "3970": 1348710085000, "4041": 1349655420000, "4264": 1352505519000, "4306": 1352940069000, "4741": 1355269526000, "4834": 1355762888000, "5044": 1358831994000, "5790": 1365818352000, "5886": 1366678471000, "6687": 1373346771000, "6817": 1374697106000, "8008": 1385527286000, "8164": 1388422887000, "8259": 1389186315000, "8352": 1389878709000, "8705": 1391395738000, "9657": 1400278770000, "9753": 1401450122000, "10180": 1405035967000, "10541": 1410094321000, "10833": 1412642319000, "10893": 1413672736000, "10996": 1415452422000, "11082": 1416578711000, "11228": 1418306362000, "11578": 1426255236000, "11634": 1427031398000, "11993": 1431306604000, "12164": 1434192334000, "12178": 1434584708000, "12823": 1441988415000, "12968": 1443887330000, "12997": 1444306718000, "13266": 1448038103000, "13628": 1455378460000, "13719": 1457534291000, "13730": 1457732611000, "13940": 1462283462000, "14386": 1473277332000, "14434": 1475416385000, "14539": 1478182795000, "14810": 1482594798000, "15404": 1492832004000, "15461": 1493909668000, "15469": 1493951109000, "15475": 1494003581000, "15476": 1494012477000, "15678": 1496609647000, "15790": 1499446527000, "16199": 1507858703000, "16245": 1509117925000, "16246": 1509128814000, "16696": 1513050947000, "16798": 1514550565000, "16825": 1514663812000, "16905": 1515676913000, "17457": 1521435448000, "17634": 1525259813000, "17636": 1525272424000, "17693": 1526415166000, "17694": 1526438450000, "17755": 1528825328000, "17792": 1530828264000, "17796": 1530976196000, "17804": 1533316766000, "18009": 1537450810000, "18215": 1540517897000, "18268": 1540991089000, "18279": 1541073760000, "18280": 1541091949000, "18281": 1541092012000, "18365": 1541701822000, "18438": 1542492595000, "18613": 1543852988000, "18624": 1543929063000, "18625": 1543936745000, "18665": 1544342539000, "18826": 1545869982000, "18839": 1545938782000, "18854": 1546029088000, "18855": 1546030992000, "18862": 1546049462000, "18873": 1546114716000, "18875": 1546121289000, "18916": 1546298464000, "18958": 1546536079000, "18974": 1546564214000, "18986": 1546627078000, "19011": 1546716420000, "19067": 1547215672000, "19068": 1547215888000, "19069": 1547289134000, "19097": 1547674130000, "19128": 1548168572000, "19143": 1548356483000, "19152": 1548426187000, "19153": 1548428076000, "19154": 1548428149000, "19155": 1548430346000, "19156": 1548451808000, "19169": 1548524921000, "19250": 1549228549000, "19314": 1549914016000, "19403": 1551577462000, "19491": 1552425131000, "19501": 1552507848000, "19511": 1552577174000, "19538": 1553043976000, "19567": 1553461005000, "19635": 1554470169000, "19645": 1554877220000, "19726": 1555361119000, "19733": 1555399560000, "19738": 1555435036000, "19785": 1556139731000, "19798": 1556469939000, "19836": 1557192410000, "19852": 1557405117000, "19913": 1558297718000, "19986": 1559735620000, "19989": 1559739274000, "19990": 1559739552000, "20000": 1559842699000, "20004": 1559926919000, "20005": 1559934061000, "20007": 1559939647000, "20027": 1560117596000, "20038": 1560187920000, "20043": 1560205695000, "20115": 1561155044000, "20123": 1561291086000, "20150": 1561577085000, "20151": 1561578523000, "20152": 1561601822000, "20153": 1561603741000, "20154": 1561650246000, "20155": 1561653456000, "20156": 1561656293000, "20157": 1561659387000, "20158": 1561660399000, "20159": 1561667964000, "20160": 1561670557000, "20161": 1561670582000, "20162": 1561670702000, "20163": 1561670837000, "20164": 1561671188000, "20165": 1561672788000, "20166": 1561677207000, "20167": 1561677239000, "20168": 1561677610000, "20169": 1561724002000, "20170": 1561724022000, "20171": 1561725161000, "20172": 1561725205000, "20173": 1561725511000, "20174": 1561727604000, "20175": 1561731020000, "20176": 1561731143000, "20177": 1561734902000, "20178": 1561734958000, "20179": 1561736259000, "20180": 1561739103000, "20181": 1561740249000, "20182": 1561743691000, "20183": 1561746752000, "20184": 1561751690000, "20185": 1561752252000, "20186": 1561759981000, "20187": 1561762433000, "20188": 1561762581000, "20189": 1561773364000, "20190": 1561774286000, "20191": 1561775780000, "20192": 1561775864000, "20193": 1561822535000, "20194": 1561827760000, "20195": 1561832948000, "20196": 1561841642000, "20197": 1561841667000, "20231": 1561999265000, "20273": 1562213026000, "20274": 1562333523000, "20278": 1562343848000, "20362": 1563408360000, "20377": 1563465802000, "20378": 1563479176000, "20389": 1563537319000, "20398": 1563654974000, "20591": 1565360342000, "20594": 1565486547000, "20700": 1566484565000, "21099": 1571414970000, "21236": 1572553014000, "22249": 1578605090000, "22257": 1578700653000, "22258": 1578772534000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz"], "machine": ["T470", "T470-W10"], "num_cpu": ["4", null], "os": ["Linux 4.4.0-17134-Microsoft", "Linux 5.0.0-20-generic"], "ram": ["20305904", "20822880"], "python": ["3.5", "3.6"], "numpy": [""], "Cython": [""], "matplotlib": [""], "sqlalchemy": [""], "scipy": [""], "numexpr": [""], "pytables": [""], "openpyxl": [""], "xlsxwriter": [""], "xlrd": [""], "xlwt": [""], "pytest": [""], "odfpy": ["", null], "bottleneck": ["", null], "branch": ["master"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz", "machine": "T470", "num_cpu": "4", "os": "Linux 5.0.0-20-generic", "ram": "20305904", "python": "3.6", "numpy": "", "Cython": "", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numexpr": "", "pytables": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "xlwt": "", "pytest": "", "branch": "master", "odfpy": null, "bottleneck": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz", "machine": "T470", "num_cpu": "4", "os": "Linux 5.0.0-20-generic", "ram": "20305904", "python": "3.6", "numpy": "", "Cython": "", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numexpr": "", "pytables": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "xlwt": "", "odfpy": "", "pytest": "", "branch": "master", "bottleneck": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz", "machine": "T470", "num_cpu": "4", "os": "Linux 5.0.0-20-generic", "ram": "20305904", "python": "3.5", "numpy": "", "Cython": "", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numexpr": "", "pytables": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "xlwt": "", "pytest": "", "branch": "master", "odfpy": null, "bottleneck": null}, {"Cython": "", "arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz", "machine": "T470-W10", "matplotlib": "", "numexpr": "", "numpy": "", "openpyxl": "", "os": "Linux 4.4.0-17134-Microsoft", "pytables": "", "pytest": "", "python": "3.6", "ram": "20822880", "scipy": "", "sqlalchemy": "", "xlrd": "", "xlsxwriter": "", "xlwt": "", "branch": "master", "num_cpu": null, "odfpy": null, "bottleneck": null}], "benchmarks": {"algorithms.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, keep, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N).repeat(5)),\n            \"uint\": pd.UInt64Index(np.arange(N).repeat(5)),\n            \"float\": pd.Float64Index(np.random.randn(N).repeat(5)),\n            \"string\": tm.makeStringIndex(N).repeat(5),\n        }\n        self.idx = data[dtype]\n        # cache is_unique\n        self.idx.is_unique", "min_run_count": 2, "name": "algorithms.Duplicated.time_duplicated", "number": 0, "param_names": ["keep", "dtype"], "params": [["'first'", "'last'", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "74d6904a4bd50534781f98df04db6cad3f61dbf663cdaaec5cb0306797741aed", "warmup_time": -1}, "algorithms.DuplicatedUniqueIndex.time_duplicated_unique": {"code": "class DuplicatedUniqueIndex:\n    def time_duplicated_unique(self, dtype):\n        self.idx.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DuplicatedUniqueIndex:\n    def setup(self, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N)),\n            \"uint\": pd.UInt64Index(np.arange(N)),\n            \"float\": pd.Float64Index(np.random.randn(N)),\n            \"string\": tm.makeStringIndex(N),\n        }\n        self.idx = data[dtype]\n        # cache is_unique\n        self.idx.is_unique", "min_run_count": 2, "name": "algorithms.DuplicatedUniqueIndex.time_duplicated_unique", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a46b27b0257c0e2a3385d7779f3fe1eb50f2894bfebfc8d8b210244b23d49fe6", "warmup_time": -1}, "algorithms.Factorize.time_factorize": {"code": "class Factorize:\n    def time_factorize(self, sort, dtype):\n        self.idx.factorize(sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, sort, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N).repeat(5)),\n            \"uint\": pd.UInt64Index(np.arange(N).repeat(5)),\n            \"float\": pd.Float64Index(np.random.randn(N).repeat(5)),\n            \"string\": tm.makeStringIndex(N).repeat(5),\n        }\n        self.idx = data[dtype]", "min_run_count": 2, "name": "algorithms.Factorize.time_factorize", "number": 0, "param_names": ["sort", "dtype"], "params": [["True", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e02c1b21bd27cdf082811994cc3c225e4e70105d30566e9e4abe13d3e68a7cf", "warmup_time": -1}, "algorithms.FactorizeUnique.time_factorize": {"code": "class FactorizeUnique:\n    def time_factorize(self, sort, dtype):\n        self.idx.factorize(sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FactorizeUnique:\n    def setup(self, sort, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N)),\n            \"uint\": pd.UInt64Index(np.arange(N)),\n            \"float\": pd.Float64Index(np.arange(N)),\n            \"string\": tm.makeStringIndex(N),\n        }\n        self.idx = data[dtype]\n        assert self.idx.is_unique", "min_run_count": 2, "name": "algorithms.FactorizeUnique.time_factorize", "number": 0, "param_names": ["sort", "dtype"], "params": [["True", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "972e2a720d37ed580dc20fa1382cb6e675876cfcffa3d07a0151bdef7e92ec47", "warmup_time": -1}, "algorithms.Hashing.time_frame": {"code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_frame", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "algorithms:114", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bc2c6db74bd1f488ca6783b5cd81a4b851a81e246014b6cec2110b954ec00bdd", "warmup_time": -1}, "algorithms.Hashing.time_series_categorical": {"code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df[\"categories\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_categorical", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "algorithms:114", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab02ec2d092fd346762565de36d662fc7324aa0eb98c8a444fcaa3e2931b3d79", "warmup_time": -1}, "algorithms.Hashing.time_series_dates": {"code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df[\"dates\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_dates", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "algorithms:114", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "36b45d66b4bf69f87d243de165371713e9669e1ad65b7583cfc86cc9fa07c79d", "warmup_time": -1}, "algorithms.Hashing.time_series_float": {"code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df[\"floats\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_float", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "algorithms:114", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a28e3e5aae224b2c4f9ef82cc9649b606348c9af7ad9d8df5ae6d6affd49917c", "warmup_time": -1}, "algorithms.Hashing.time_series_int": {"code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df[\"ints\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "algorithms:114", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4b75325e885a3f804e718278e33960d6f81b5896d368b6ee7bfd810aa1a9b54", "warmup_time": -1}, "algorithms.Hashing.time_series_string": {"code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df[\"strings\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "algorithms:114", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b4e01cea19ae95b5b36ae39ae3347cff5a134b7b64a539b3bd8415d43649144", "warmup_time": -1}, "algorithms.Hashing.time_series_timedeltas": {"code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df[\"timedeltas\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_timedeltas", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "algorithms:114", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb99aa0738d0481fed160deda787db0a56b025989985028ec0bb84423e16749e", "warmup_time": -1}, "algorithms.MaybeConvertObjects.time_maybe_convert_objects": {"code": "class MaybeConvertObjects:\n    def time_maybe_convert_objects(self):\n        lib.maybe_convert_objects(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertObjects:\n    def setup(self):\n        N = 10 ** 5\n    \n        data = list(range(N))\n        data[0] = pd.NaT\n        data = np.array(data)\n        self.data = data", "min_run_count": 2, "name": "algorithms.MaybeConvertObjects.time_maybe_convert_objects", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03820a97e076c4a119a3158f0b32576f52912a74115c24ebc90f8d23a265e82b", "warmup_time": -1}, "algorithms.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.idx.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": np.arange(N),\n            \"uint\": np.arange(N).astype(np.uint64),\n            \"float\": np.random.randn(N),\n        }\n        self.idx = pd.Series(data[dtype].repeat(5))", "min_run_count": 2, "name": "algorithms.Quantile.time_quantile", "number": 0, "param_names": ["quantile", "interpolation", "dtype"], "params": [["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"], ["'float'", "'int'", "'uint'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ebf62e9c35a12781054738fc93719e6aee86d91242279f49a8d3c3a82c211159", "warmup_time": -1}, "algorithms.SortIntegerArray.time_argsort": {"code": "class SortIntegerArray:\n    def time_argsort(self, N):\n        self.array.argsort()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIntegerArray:\n    def setup(self, N):\n        data = np.arange(N, dtype=float)\n        data[40] = np.nan\n        self.array = pd.array(data, dtype=\"Int64\")", "min_run_count": 2, "name": "algorithms.SortIntegerArray.time_argsort", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8511c08938a6a85d1e3a650d9497946016c62ea27123f3f61a330eaee124870", "warmup_time": -1}, "array.BooleanArray.time_from_bool_array": {"code": "class BooleanArray:\n    def time_from_bool_array(self):\n        pd.array(self.values_bool, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]", "min_run_count": 2, "name": "array.BooleanArray.time_from_bool_array", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1300208dbee40a0e0a49224011d3e0821b59a8b1bfc6ec6bfcdd05269fad57f1", "warmup_time": -1}, "array.BooleanArray.time_from_float_array": {"code": "class BooleanArray:\n    def time_from_float_array(self):\n        pd.array(self.values_float, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]", "min_run_count": 2, "name": "array.BooleanArray.time_from_float_array", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6e2b9cc5e9e82dd8939127c9650d80d65c38e754e29a605ac54a2df96173bb25", "warmup_time": -1}, "array.BooleanArray.time_from_integer_array": {"code": "class BooleanArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_array", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aeb019ef8003a7408d799ffc2d87a20a960c16a936ea978098b87c11c1376d7a", "warmup_time": -1}, "array.BooleanArray.time_from_integer_like": {"code": "class BooleanArray:\n    def time_from_integer_like(self):\n        pd.array(self.values_integer_like, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_like", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71d94b45e8964ebda4c654107b04a31a23d371ee9c747cb35a2c259eb27384fe", "warmup_time": -1}, "attrs_caching.CacheReadonly.time_cache_readonly": {"code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CacheReadonly:\n    def setup(self):\n        class Foo:\n            @cache_readonly\n            def prop(self):\n                return 5\n    \n        self.obj = Foo()", "min_run_count": 2, "name": "attrs_caching.CacheReadonly.time_cache_readonly", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "318b441bdf0d107918b25d827fd88753a42d9fa4c589ff7faef49aabb4e7ddd4", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_get_index": {"code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.foo = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_get_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "724af0b0b4b503c9c173dad92121ac975bf7f69a8816d35742b2f9303aa5729d", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_set_index": {"code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_set_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "419269e3a9cd0e10128bbb97214df797a349d4c774c362be4e57cc055d1db0ad", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_arr_mask_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_arr_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, arr_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_arr_mask_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d293d47dc8f9c6cc9656559e3d67b5cde6efdd98b69be653bc46cc847a14df2", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_arr_rev": {"code": "class AddOverflowArray:\n    def time_add_overflow_arr_rev(self):\n        checked_add_with_arr(self.arr, self.arr_rev)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_arr_rev", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fc092d7ae693dd485812cf381907c566521cf4e92690cd03fe5b989699f58242", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_b_mask_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_b_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, b_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_b_mask_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "991c0150153d97ecd1306b9ce45c968001c7e603e95d48a6c29469bb36aa7a9c", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_both_arg_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_both_arg_nan(self):\n        checked_add_with_arr(\n            self.arr, self.arr_mixed, arr_mask=self.arr_nan_1, b_mask=self.arr_nan_2\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_both_arg_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c73fa08cd242ac103fc3fe6cda9b8e2d7fdba867d6a6fd89778db2c8adad06b", "warmup_time": -1}, "binary_ops.AddOverflowScalar.time_add_overflow_scalar": {"code": "class AddOverflowScalar:\n    def time_add_overflow_scalar(self, scalar):\n        checked_add_with_arr(self.arr, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowScalar:\n    def setup(self, scalar):\n        N = 10 ** 6\n        self.arr = np.arange(N)", "min_run_count": 2, "name": "binary_ops.AddOverflowScalar.time_add_overflow_scalar", "number": 0, "param_names": ["scalar"], "params": [["1", "-1", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "658dd351bdd9a0f422fbdd678d0bc66905208a2ea7a9bcef4bba739c0c7b5653", "warmup_time": -1}, "binary_ops.IntFrameWithScalar.time_frame_op_with_scalar": {"code": "class IntFrameWithScalar:\n    def time_frame_op_with_scalar(self, dtype, scalar, op):\n        op(self.df, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntFrameWithScalar:\n    def setup(self, dtype, scalar, op):\n        arr = np.random.randn(20000, 100)\n        self.df = DataFrame(arr.astype(dtype))", "min_run_count": 2, "name": "binary_ops.IntFrameWithScalar.time_frame_op_with_scalar", "number": 0, "param_names": ["dtype", "scalar", "op"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>"], ["2", "3.0", "4", "5.0"], ["<built-in function add>", "<built-in function sub>", "<built-in function mul>", "<built-in function truediv>", "<built-in function floordiv>", "<built-in function pow>", "<built-in function mod>", "<built-in function eq>", "<built-in function ne>", "<built-in function gt>", "<built-in function ge>", "<built-in function lt>", "<built-in function le>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec06f3b152b50f2c1b6f2897411283c9bf6a5b2a1d8903c1e11787cbc2906515", "warmup_time": -1}, "binary_ops.Ops.time_frame_add": {"code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_add", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "67a855b2c3c992c101f27a9879f9ae9736100576e8d003480f4c96b146c8a00f", "warmup_time": -1}, "binary_ops.Ops.time_frame_comparison": {"code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_comparison", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39273acf4a197d818e315a21b66466e0f9c80be9ff4f8f76675f01e2b06d443c", "warmup_time": -1}, "binary_ops.Ops.time_frame_mult": {"code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_mult", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "728dac3dec55093590972641a530323e7733dc873d4756bc51f384dd65b314f4", "warmup_time": -1}, "binary_ops.Ops.time_frame_multi_and": {"code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_multi_and", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "692513ff2b1a23ee1bec954ddae34ac53fac5f3b6c87633ae3087d8f1c3177b1", "warmup_time": -1}, "binary_ops.Ops2.time_frame_dot": {"code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_dot", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad70c0c75ea6103b6f919b2a834d154b77790c03cb4b2b883810406413353df1", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_div": {"code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_div", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "540eee8f97793c40404ebf85acf29d8a38dbba061a39fd9bf3b04042f54764f1", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_div_by_zero": {"code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_div_by_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d512dbd604e6343f79ef81ca1974a77e55b654b91d89dfd1fa3d045e0e544750", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_floor_by_zero": {"code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_floor_by_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06aa58fa65573b3e4ed064e870f0624fc64ddbe5fe4af26841870c4f0919910c", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_mod": {"code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_mod", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f10eed057397643346e27d6cf17ddf4bec9d56b4a42411971dc048e3b789f859", "warmup_time": -1}, "binary_ops.Ops2.time_frame_int_div_by_zero": {"code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_int_div_by_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c6b1ce4e9bc0036dbf458265bb584e662839a1e3c05a6562c373355bd340284e", "warmup_time": -1}, "binary_ops.Ops2.time_frame_int_mod": {"code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_int_mod", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d612b555bda0db0cd2dac900fd62078e386410041c5173d1c50d2337284c57a", "warmup_time": -1}, "binary_ops.Ops2.time_frame_series_dot": {"code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_series_dot", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "524612747dc8b88b4a00e9099c26e6524ab0266b379a13454f56de19cb9f410a", "warmup_time": -1}, "binary_ops.Ops2.time_series_dot": {"code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_series_dot", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1a991daf3f6f3240a58cc36892fc8a2028caf2aa1cf9174c2cad4adfda8a8fb0", "warmup_time": -1}, "binary_ops.Timeseries.time_series_timestamp_compare": {"code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_series_timestamp_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2c83ef0d799936822029c6993ac17e2aa3fba411660ebb46b4a187a061c37584", "warmup_time": -1}, "binary_ops.Timeseries.time_timestamp_ops_diff": {"code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_timestamp_ops_diff", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfbd8cfc82cbb7938f3d207cc44a2cd9cdd4d0d19b152ea361caf8d3b830f835", "warmup_time": -1}, "binary_ops.Timeseries.time_timestamp_ops_diff_with_shift": {"code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_timestamp_ops_diff_with_shift", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8273bc69a5b133323dc319285f8dd641b46188d07244cbb3035b814cf467d58", "warmup_time": -1}, "binary_ops.Timeseries.time_timestamp_series_compare": {"code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_timestamp_series_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a8526ede350ba7c4f65ca375b76d5b0edb3eeffb3ed17f4caad0911d08f1f610", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_array": {"code": "class TimeLogicalOps:\n    def time_and_array(self):\n        self.left & self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_array", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f948c075c42597b3abbe166b111d3f02c0aa11a2fd01b376b96547a7a0ece18", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_scalar": {"code": "class TimeLogicalOps:\n    def time_and_scalar(self):\n        self.left & True\n        self.left & False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73483ccace6f6debdb2fd885f8fd8ffee9883f4e6dad1587a13239b8be135868", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_array": {"code": "class TimeLogicalOps:\n    def time_or_array(self):\n        self.left | self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_array", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dc01bb9cbcdc979b4fbe050df208268a15ff5f328081a7fd09c41283c33bfa5d", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_scalar": {"code": "class TimeLogicalOps:\n    def time_or_scalar(self):\n        self.left | True\n        self.left | False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9dcf90a110c0c703887ee44358e18a6930758987f7f1e9f921dd5ff4c84234e", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_array": {"code": "class TimeLogicalOps:\n    def time_xor_array(self):\n        self.left ^ self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_array", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e093e59c2f51a4998acf114ad54d2ab5d62d38548aab71f3f5c6adbe6bc46792", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_scalar": {"code": "class TimeLogicalOps:\n    def time_xor_scalar(self):\n        self.left ^ True\n        self.left ^ False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb50d9fee1d2beff8da51a2f128bb84bfa76379e9a699ae60dec8e82655bef3c", "warmup_time": -1}, "categoricals.CategoricalOps.time_categorical_op": {"code": "class CategoricalOps:\n    def time_categorical_op(self, op):\n        getattr(self.cat, op)(\"b\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalOps:\n    def setup(self, op):\n        N = 10 ** 5\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)", "min_run_count": 2, "name": "categoricals.CategoricalOps.time_categorical_op", "number": 0, "param_names": ["op"], "params": [["'__lt__'", "'__le__'", "'__eq__'", "'__ne__'", "'__ge__'", "'__gt__'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa1b3ce94df35beb0f96ec4778b51ea09499d0160d76f9ed54a2301242704f56", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_bool_array": {"code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "86a011011ac395f8fc5f29a50aa4bd848502098da8633bcec5bb7b26901129a4", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list": {"code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80573150f24a008d1e506af102b79e9043600c6bdf44167720392fdb6c2710ec", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list_like": {"code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "382a78a3f7ccfa9221eeac2207adaf0d469c8ac86b136bae34d73bb653a53d3a", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_scalar": {"code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a6fbf8be1b80d334be577d8daf846fff77cf4dfd3d9281863f2ef60dcb76296", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_slice": {"code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[: self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b2d401b4fc5613f63e4d9e2dd91da5a0b5048d9fc7cd70d3ffe103001f08a59", "warmup_time": -1}, "categoricals.Concat.time_concat": {"code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)", "min_run_count": 2, "name": "categoricals.Concat.time_concat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63fd9790f736284e924ed307c6421ee1f09bb33fffdb2d42a549b0947bf61d4d", "warmup_time": -1}, "categoricals.Concat.time_union": {"code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)", "min_run_count": 2, "name": "categoricals.Concat.time_union", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0b7407df4167f119dc61fda5455d8d813df42e2a707e92b9a642b82205590535", "warmup_time": -1}, "categoricals.Constructor.time_all_nan": {"code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_all_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9b025ed98b0af3757435cc3f5068bda73201de9aadcca2903d2e378b27481ec1", "warmup_time": -1}, "categoricals.Constructor.time_datetimes": {"code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ed71726ba69bec3e598802562749f3d68e59c9379a6fe97532b031c6808d998a", "warmup_time": -1}, "categoricals.Constructor.time_datetimes_with_nat": {"code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes_with_nat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fec01c81f0925b2376ceaa1ac678d6dbe9663c3da15f8ef817693d030a1c1179", "warmup_time": -1}, "categoricals.Constructor.time_existing_categorical": {"code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_categorical", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "605f4412feaf1f523743b59d2e270c3dfaedfdf94c72cda862b9a6fa1b91fb92", "warmup_time": -1}, "categoricals.Constructor.time_existing_series": {"code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f456053be0757c67b42419473dea42a6c402bbbf4af2527a3330bc7db56f03f9", "warmup_time": -1}, "categoricals.Constructor.time_fastpath": {"code": "class Constructor:\n    def time_fastpath(self):\n        pd.Categorical(self.codes, self.cat_idx, fastpath=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_fastpath", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2a34575b0930b2df5f06b8a43ddf73d38c0b19c63952c1f51505c24d19f87f0", "warmup_time": -1}, "categoricals.Constructor.time_from_codes_all_int8": {"code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_from_codes_all_int8", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d061d4e5744ecf77f79dd4d70f9bda9bbcfd11f9e5a3598ba3c35577c27a937f", "warmup_time": -1}, "categoricals.Constructor.time_regular": {"code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_regular", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "514b215a884179242991414691d877433248533cd2235f4894ab2cb5fec12126", "warmup_time": -1}, "categoricals.Constructor.time_with_nan": {"code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_with_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "638472edeb14c0bd1ebbf69ce0c350663f8fa5612f29b3afec70aafd50315c47", "warmup_time": -1}, "categoricals.Contains.time_categorical_contains": {"code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3d8dd005efc545cefe492bdd925b434abf10b89f6f92f8aeceb482e39d02144c", "warmup_time": -1}, "categoricals.Contains.time_categorical_index_contains": {"code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd8ebae02bfdb922015c48f72b1b1a6aff2ae989ea22d489c56158f7a2965e8e", "warmup_time": -1}, "categoricals.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_align", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e81509916cd399ab60fd97fc8cca7ca8cfacd82ec3952aec12ff5fbb91086fbf", "warmup_time": -1}, "categoricals.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "449dbdb6fe573b7b07fcfbdc500fb28fa1df6ef5a7e62c816545a5161bd47eac", "warmup_time": -1}, "categoricals.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5688fa14a16c913a25b8798aff106cd4dea846874c4f4a48f4bb7c3988d9b621", "warmup_time": -1}, "categoricals.Indexing.time_reindex": {"code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fd56f04d448d0b21abfb503d90d9ca5470fe2f200f2d3569080c0e560235ece", "warmup_time": -1}, "categoricals.Indexing.time_reindex_missing": {"code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex([\"a\", \"b\", \"c\", \"d\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex_missing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0911734d40abf3f6930c4e093d08bc6ea37d98b56ce012f33d8ed2cf8307af35", "warmup_time": -1}, "categoricals.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c6539cca059f9c95ebd6d085d95ca43169338f32c8305e671919b3a4cd072c6c", "warmup_time": -1}, "categoricals.Indexing.time_shape": {"code": "class Indexing:\n    def time_shape(self):\n        self.index.shape\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_shape", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29c65b11293651668fca2a1876f1d9a438e17819c73c26d700c68164ed7b1256", "warmup_time": -1}, "categoricals.Indexing.time_sort_values": {"code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_sort_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7824f70d9198203326e632dad2ab979dd3b695d065a5df07434ef0a6720a2358", "warmup_time": -1}, "categoricals.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0416d555edd6329b37769db364734b1460b9298d49a5ebc7c67f7d81711f49cc", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa5876d4a3142dd06fb9b9b448e26396b1d87e2bcd0f53971f22d05f01d74b69", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd56718c84977ba1058dc6d1b12a27633b8ebb7c6d94fc9ab288ae9800841446", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "49356d52f4a8f0166e1a989f49c536ba51f2aec3d37077d4ae104c3cbd9643be", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0253b760f0377ec35dbff5bdf6ff5cd2c0e7cef1ec0cb4d0903b7c355b8f14da", "warmup_time": -1}, "categoricals.Isin.time_isin_categorical": {"code": "class Isin:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.sample)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        np.random.seed(1234)\n        n = 5 * 10 ** 5\n        sample_size = 100\n        arr = list(np.random.randint(0, n // 10, size=n))\n        if dtype == \"object\":\n            arr = [f\"s{i:04d}\" for i in arr]\n        self.sample = np.random.choice(arr, sample_size)\n        self.series = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.Isin.time_isin_categorical", "number": 0, "param_names": ["dtype"], "params": [["'object'", "'int64'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7e35fd79e4133b0f26ebe62a5f85ea6d2c0dfadb6062034f98a326e9adcb07d6", "warmup_time": -1}, "categoricals.Rank.time_rank_int": {"code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "680add1ecee5abc1808455f95e0237006661dcf01e0fa79ca426f2081d4b89c1", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat": {"code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aacf23031ae813ac93768492d8ee858b0b21e100e85b79f999268c0bf0234323", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat_ordered": {"code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat_ordered", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea7b6de9f4513a45416a379bae165c30b2ce9967fa61b019d56bd193eeb28e57", "warmup_time": -1}, "categoricals.Rank.time_rank_string": {"code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "72479466fb69f7e3dd9a98b644a58b1ccc03cab38fba35a04c0fb6a8eaca98c4", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat": {"code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35f35b1a0188eeb3b7b3892c057db7de26f954111267929b35347a470187d781", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat_ordered": {"code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat_ordered", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "70869417885aee2a19a08e0dd52d9fa72cdad8d9f78308f0c62e56eb31825ca2", "warmup_time": -1}, "categoricals.RemoveCategories.time_remove_categories": {"code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.RemoveCategories.time_remove_categories", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "88ef9b1206f5f38104b565cd51c23dfdf2fd3baf306436d71c9e67ca721871d2", "warmup_time": -1}, "categoricals.Repr.time_rendering": {"code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")", "min_run_count": 2, "name": "categoricals.Repr.time_rendering", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f043899c68a0bddf1ee7a921bb598b5f105966be3ae78c715d752eade54db7b5", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_contains": {"code": "class SearchSorted:\n    def time_categorical_contains(self):\n        self.c.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "423139351f82c3ea6882246443b5161c2ad06c75b2d76c0371a7109e6fdb636b", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_index_contains": {"code": "class SearchSorted:\n    def time_categorical_index_contains(self):\n        self.ci.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb3fad7ac713a5ae6d7140c3fa5ac53d3076492a4dc74aa1ff381c7ad0402e19", "warmup_time": -1}, "categoricals.SetCategories.time_set_categories": {"code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.SetCategories.time_set_categories", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "228f5a07bcfaf64253ff659a31090e385cb2482a3a3d8e2a978bd2ca99b36b68", "warmup_time": -1}, "categoricals.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.ValueCounts.time_value_counts", "number": 0, "param_names": ["dropna"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38c3c415a2f65b9bf52a5803806e4f310656fdf7c6e25332ef2819dc58beb1cc", "warmup_time": -1}, "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {"code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10 ** 4\n        self.iterables = [tm.makeStringIndex(N), range(20)]", "min_run_count": 2, "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "392b00af1f28ca8721dd73fb40cf295df0b722d6cc90d82906674f32ff61833f", "warmup_time": -1}, "ctors.SeriesConstructors.time_series_constructor": {"code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        if data_fmt in (gen_of_str, gen_of_tuples) and with_index:\n            raise NotImplementedError(\n                \"Series constructors do not support using generators with indexes\"\n            )\n        N = 10 ** 4\n        if dtype == \"float\":\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None", "min_run_count": 2, "name": "ctors.SeriesConstructors.time_series_constructor", "number": 1, "param_names": ["data_fmt", "with_index", "dtype"], "params": [["<function no_change>", "<class 'list'>", "<function list_of_str>", "<function gen_of_str>", "<function arr_dict>", "<function list_of_tuples>", "<function gen_of_tuples>", "<function list_of_lists>", "<function list_of_tuples_with_none>", "<function list_of_lists_with_none>"], ["False", "True"], ["'float'", "'int'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7eef9b16b4736229aefbb3892dd90808d3615cf5a5b492a0b1e695fff6bbe4dc", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aeeff25a8f96d74fadfcf452661c48a61f77b2a3133d78b9ec317245c0bc754c", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccec589dc5d6fd152e60291c4dc2fb0242a2015a404235e26ad46a0d993ee7dd", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a23dc31f8d89a80bc087a24e080af596c00b9d4dc78e6cbe5f1615fa460cb31", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_string": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2df00803b4b6e76d5d33a1469de09fd5f7124242499149081029f29e71742ac8", "warmup_time": -1}, "dtypes.Dtypes.time_pandas_dtype": {"code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.Dtypes.time_pandas_dtype", "number": 0, "param_names": ["dtype"], "params": [["dtype('int64')", "dtype('int32')", "dtype('uint32')", "dtype('uint64')", "dtype('float32')", "dtype('float64')", "dtype('int16')", "dtype('int8')", "dtype('uint16')", "dtype('uint8')", "dtype('<M8')", "dtype('<m8')", "dtype('O')", "<class 'pandas.core.arrays.integer.Int8Dtype'>", "<class 'pandas.core.arrays.integer.Int16Dtype'>", "<class 'pandas.core.arrays.integer.Int32Dtype'>", "<class 'pandas.core.arrays.integer.Int64Dtype'>", "<class 'pandas.core.arrays.integer.UInt8Dtype'>", "<class 'pandas.core.arrays.integer.UInt16Dtype'>", "<class 'pandas.core.arrays.integer.UInt32Dtype'>", "<class 'pandas.core.arrays.integer.UInt64Dtype'>", "<class 'pandas.core.dtypes.dtypes.CategoricalDtype'>", "<class 'pandas.core.dtypes.dtypes.IntervalDtype'>", "datetime64[ns, UTC]", "period[D]", "'int64'", "'int32'", "'uint32'", "'uint64'", "'float32'", "'float64'", "'int16'", "'int8'", "'uint16'", "'uint8'", "'datetime64'", "'timedelta64'", "'object'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'category'", "'interval'", "'datetime64[ns, UTC]'", "'period[D]'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c636a90f2e83bdd77f2d6ee44d53f3f544eae867d47edcc9aa01c5fac4e847c1", "warmup_time": -1}, "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {"code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid", "number": 0, "param_names": ["dtype"], "params": [["'scalar-string'", "'scalar-int'", "'list-string'", "'array-string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0e5e9090205efd4b2b0eaae96ef388c13f2755cbcd2e6d6055c789e521e8f26", "warmup_time": -1}, "dtypes.InferDtypes.time_infer": {"code": "class InferDtypes:\n    def time_infer(self, dtype):\n        lib.infer_dtype(self.data_dict[dtype], skipna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.InferDtypes.time_infer", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9f08a1b4c5dd7a61ae3d57337a61766165738cab3fa03c160a777caa6e0d5f7d", "warmup_time": -1}, "dtypes.InferDtypes.time_infer_skipna": {"code": "class InferDtypes:\n    def time_infer_skipna(self, dtype):\n        lib.infer_dtype(self.data_dict[dtype], skipna=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.InferDtypes.time_infer_skipna", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "422394f64731ac108c37b7bdf4ea9f082e18ddf647e1b642dfd87e9b25c35e79", "warmup_time": -1}, "eval.Eval.time_add": {"code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval(\"self.df + self.df2 + self.df3 + self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_add", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f66cb4c7625db55ad2fb47d6f967fb6168e37ad7c155ab90f9e67f3bd7352d8", "warmup_time": -1}, "eval.Eval.time_and": {"code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval(\n            \"(self.df > 0) & (self.df2 > 0) & (self.df3 > 0) & (self.df4 > 0)\",\n            engine=engine,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_and", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ceb98dd9d1fd4885f6a40036d8b20f03e014564fd923d2f526372cb342b5846", "warmup_time": -1}, "eval.Eval.time_chained_cmp": {"code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval(\"self.df < self.df2 < self.df3 < self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_chained_cmp", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "537101344193d00bb2f4e3ac5fcc1229b541ea3bc2d4688ed9cbc4574b7f62fa", "warmup_time": -1}, "eval.Eval.time_mult": {"code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval(\"self.df * self.df2 * self.df3 * self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_mult", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb3ea8ccc283549666fb49bc038fc7463a0957adbf7b59586b03ce2616e0c2b8", "warmup_time": -1}, "eval.Query.time_query_datetime_column": {"code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query(\"dates < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_column", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0bc55ac7b144ae912fe08427150c3d516602fb5dc28d8c9d8c3fe801b52b2e52", "warmup_time": -1}, "eval.Query.time_query_datetime_index": {"code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query(\"index < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0146c2044d79deef45a880798c23724d841bbb6f2b4bca8359698b6e49f4ee1f", "warmup_time": -1}, "eval.Query.time_query_with_boolean_selection": {"code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query(\"(a >= @self.min_val) & (a <= @self.max_val)\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_with_boolean_selection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19e71a2c95d218f6a6faf4f3b31e293759b0496727e95819bad7bf06851cd6bc", "warmup_time": -1}, "frame_ctor.FromDicts.time_list_of_dict": {"code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_list_of_dict", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "700022477b9677e7b5545687666583c3fe1598083ea6cda0a118e8efd3d92e03", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict": {"code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75cb6dc9abe3905bc87ea3c8de2bbe6cf1ce749569b554f7645b895244b42fee", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_columns": {"code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8432cbe52051c2d12cfb5123339cd0d8598ef01619ee8a374f1927732cdd967f", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index": {"code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe4ed1625674e550132871dd0a50063896b08c06b762c09223f1ae2022245de4", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index_columns": {"code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55423a0a7e2c5ba4d57abdc2879dedf93a15440fad062022da3cfc6ad502a53b", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_int64": {"code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_int64", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab236bf17616730a48159c4c93de7fc679eee4232a0b8dcb96ce3e587670d750", "warmup_time": -1}, "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {"code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10 ** 3\n        np.random.seed(1234)\n        idx = date_range(Timestamp(\"1/1/1900\"), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()", "min_run_count": 2, "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets", "number": 0, "param_names": ["offset"], "params": [["<Nano>", "<Hour>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24655c635e25c11abb8847125ce555c1eb61aa4e6c112a3b95f9e4a3a2feff02", "warmup_time": -1}, "frame_ctor.FromLists.time_frame_from_lists": {"code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [list(range(M)) for i in range(N)]", "min_run_count": 2, "name": "frame_ctor.FromLists.time_frame_from_lists", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53551e4d1da11be641b0c0122b6943106204c9bda18ddd18263ac5c56c7f042b", "warmup_time": -1}, "frame_ctor.FromNDArray.time_frame_from_ndarray": {"code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)", "min_run_count": 2, "name": "frame_ctor.FromNDArray.time_frame_from_ndarray", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6fb5f6568d301464fbdc79a5b9701a4b5435aee21d09337b878ce3a016c89d80", "warmup_time": -1}, "frame_ctor.FromRange.time_frame_from_range": {"code": "class FromRange:\n    def time_frame_from_range(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRange:\n    def setup(self):\n        N = 1_000_000\n        self.data = range(N)", "min_run_count": 2, "name": "frame_ctor.FromRange.time_frame_from_range", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55f9a56a0976f7068d59705a8a0ae5b86787af28fd44e70cb7b4677b62bdeab9", "warmup_time": -1}, "frame_ctor.FromRecords.time_frame_from_records_generator": {"code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))", "min_run_count": 2, "name": "frame_ctor.FromRecords.time_frame_from_records_generator", "number": 1, "param_names": ["nrows"], "params": [["None", "1000"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eec7b09b4fa409f895b70cac11929c08947074b5e92dfb4b844dc4f349e04474", "warmup_time": -1}, "frame_ctor.FromSeries.time_mi_series": {"code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)", "min_run_count": 2, "name": "frame_ctor.FromSeries.time_mi_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31cd15987aceabc0ef946bd94b0df86240ada3c11a2d7a04358bc512d7920595", "warmup_time": -1}, "frame_methods.Apply.time_apply_axis_1": {"code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_axis_1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ced675e528437c2b073f9a06b43fb56462e93b2a712fcf31709614aae3e76f7", "warmup_time": -1}, "frame_methods.Apply.time_apply_lambda_mean": {"code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_lambda_mean", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14f8c150feae7c93c72079a2d91274c9b1a2eb977ea7ae0e61ced9369f9a5507", "warmup_time": -1}, "frame_methods.Apply.time_apply_np_mean": {"code": "class Apply:\n    def time_apply_np_mean(self):\n        self.df.apply(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_np_mean", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1aba79d189a50e4a68431728911ddbd16de5d3a6fb214db52c554aef6476527", "warmup_time": -1}, "frame_methods.Apply.time_apply_pass_thru": {"code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_pass_thru", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "833e1aa610793ea8e28d7d50100375dea01251e0adc0fd5f45e37fd3fc189568", "warmup_time": -1}, "frame_methods.Apply.time_apply_ref_by_name": {"code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x[\"A\"] + x[\"B\"], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_ref_by_name", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "47628925adc375cbfba3d3daeae599dca7bde70a57b35847fe97b285eb9ce42b", "warmup_time": -1}, "frame_methods.Apply.time_apply_user_func": {"code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_user_func", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d047285f574fea23abcaaeef80ea9b06ab9b7ae6ea21c38ac27de97a3b05b3e6", "warmup_time": -1}, "frame_methods.Count.time_count_level_mixed_dtypes_multi": {"code": "class Count:\n    def time_count_level_mixed_dtypes_multi(self, axis):\n        self.df_mixed.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )", "min_run_count": 2, "name": "frame_methods.Count.time_count_level_mixed_dtypes_multi", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f17091e394ff7c4fc5d65c56e2edaed818c6c6ee9e6dcd6400d1fcfabc215aff", "warmup_time": -1}, "frame_methods.Count.time_count_level_multi": {"code": "class Count:\n    def time_count_level_multi(self, axis):\n        self.df.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )", "min_run_count": 2, "name": "frame_methods.Count.time_count_level_multi", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "623b9ec8c38e3e1d55c7e8127aa688a8f03b1fcc709e445c53bbd50e833a9533", "warmup_time": -1}, "frame_methods.Describe.time_dataframe_describe": {"code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, int(1e6)),\n                \"b\": np.random.randint(0, 100, int(1e6)),\n                \"c\": np.random.randint(0, 100, int(1e6)),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_dataframe_describe", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "10f5f80daba076d94357f45b12a52f3adb2537f264e95b88b63f41f00dd051cf", "warmup_time": -1}, "frame_methods.Describe.time_series_describe": {"code": "class Describe:\n    def time_series_describe(self):\n        self.df[\"a\"].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, int(1e6)),\n                \"b\": np.random.randint(0, 100, int(1e6)),\n                \"c\": np.random.randint(0, 100, int(1e6)),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_series_describe", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c648e66e7487deea98e2727c7eb1455592e523348d0fb53d40c0ce4ec676c4f1", "warmup_time": -1}, "frame_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d01b5ecba6e71b95f96b5f57c37e5aa4624895e14df9defa1da1fbda82ada076", "warmup_time": -1}, "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {"code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a31dc90001e787678b625fe82b8d7ef75f2a4053a1b20af3ba6d2223c4b34cde", "warmup_time": -1}, "frame_methods.Dtypes.time_frame_dtypes": {"code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))", "min_run_count": 2, "name": "frame_methods.Dtypes.time_frame_dtypes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1eca85c37df3c0fa5ffab4f92c77a0352a28513588025f23251dda0c36027ac3", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated": {"code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ddedf9c76ae2eec8e8a76fe34e8be24de43ebeb34817893c792e4d16e93b7054", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_wide": {"code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f159660d9f422b498ae7ffaada1dabe55000ad646dc7ea02e4020e126d6d097", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_equal": {"code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9297a53ea439df3ab2e9ca02044edc3ee3b07c33e8cd19be23917b37e339798b", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_unequal": {"code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_unequal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd24ede72fb979c40804fb5634728fdc1e5c582a2dae3456ae5ed5f7949c8507", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_equal": {"code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c344b5c1ca16e353416823f96f00eb0491fc789311705dd5b07406b32e7fb14b", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_unequal": {"code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_unequal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56b832b60731a2f00414080bac6349d1c70454fe294b6cfc77545161a915b8a9", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_equal": {"code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "344424713951304187cedfdfad4fffd04681938114bba4504411955542e56dd7", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_unequal": {"code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_unequal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6ec9d7e64303ee2fd28c0a0a4822fc56d58320a05ebed4945b50e681834f2abe", "warmup_time": -1}, "frame_methods.Fillna.time_frame_fillna": {"code": "class Fillna:\n    def time_frame_fillna(self, inplace, method):\n        self.df.fillna(inplace=inplace, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, method):\n        values = np.random.randn(10000, 100)\n        values[::2] = np.nan\n        self.df = DataFrame(values)", "min_run_count": 2, "name": "frame_methods.Fillna.time_frame_fillna", "number": 0, "param_names": ["inplace", "method"], "params": [["True", "False"], ["'pad'", "'bfill'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7dcf12633de089958156ed6dc74812a3fb114da3adf3e4ebcd39cb9da424baf8", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {"code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        with warnings.catch_warnings(record=True):\n            self.df._data.get_dtype_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fffd9dd0fe8ac93d6541911c76531c1fde1a21c326f02d6b07c74d3737cfd4cf", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_info": {"code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_info", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f9da084cf6f28a48a82fd2244d9854c98469727387a60271fc1b0da6df4e4a3", "warmup_time": -1}, "frame_methods.GetNumericData.time_frame_get_numeric_data": {"code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df[\"foo\"] = \"bar\"\n        self.df[\"bar\"] = \"baz\"\n        self.df = self.df._consolidate()", "min_run_count": 2, "name": "frame_methods.GetNumericData.time_frame_get_numeric_data", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c74ad94b824669d079bb2add80253ef91c59a14b0db4aed51afda0f17a8ff361", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate": {"code": "class Interpolate:\n    def time_interpolate(self, downcast):\n        self.df.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        self.df = DataFrame(np.random.randn(N, 100))\n        self.df.values[::2] = np.nan\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate", "number": 0, "param_names": ["downcast"], "params": [["None", "'infer'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95ef90ea2f99dc9713649feda12cc3b3bda0eef0e3a1e0294c1895927e35070a", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate_some_good": {"code": "class Interpolate:\n    def time_interpolate_some_good(self, downcast):\n        self.df2.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        self.df = DataFrame(np.random.randn(N, 100))\n        self.df.values[::2] = np.nan\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate_some_good", "number": 0, "param_names": ["downcast"], "params": [["None", "'infer'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14387244c741fc0a9c417d2ddc0036504e3d07e5b8fa986556cda28fd2a07b09", "warmup_time": -1}, "frame_methods.Isnull.time_isnull": {"code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b71f7a1ceb5631d4166280889a916e7bf24743aa74d3030cb57762915e397e2f", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_floats_no_null": {"code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_floats_no_null", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6cbb0c9dfc9c03b851b70be35012d788c4b4642efead9593f18d10cd9e9da659", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_obj": {"code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_obj", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19f4e217d85cdd700e6df3d8b6b1f6e5349092e0b351ce981051f81b168d408d", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_strngs": {"code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_strngs", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "42add58893d4f3a78db469f145a20501402213a51e5b2da27438b4c84fac5c7a", "warmup_time": -1}, "frame_methods.Iteration.mem_itertuples_raw_start": {"code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "8f73632b8d6514e777fd45d195014fd85bf88269338484ec4beb185fa3b37d01"}, "frame_methods.Iteration.mem_itertuples_raw_to_list": {"code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "4d9806126b8a3cb2ff6e82cbf25460c29943fff894fc8fe80bf032cd15ef67f7"}, "frame_methods.Iteration.mem_itertuples_read_first": {"code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_read_first", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "78ad32e399a89c43ad93586e027787799be54fd90afc0d706a92b41371074f3f"}, "frame_methods.Iteration.mem_itertuples_start": {"code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "1267273cf0568d2681a230f6c8299c306eddebcc35409648c1b22e80386c655f"}, "frame_methods.Iteration.mem_itertuples_to_list": {"code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "adca29baae0fae04e49fdb080966f578eca240942c97f441b71142bb25dd5def"}, "frame_methods.Iteration.peakmem_itertuples": {"code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3125af828cfaafb34b7b6989409191fe30095c4dd2c3396fc1abdbf78658a852"}, "frame_methods.Iteration.peakmem_itertuples_raw": {"code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "dea3a043745ff926b3eb23127f6ae1b6db83a7149ae9334aa14ed81887e8a832"}, "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {"code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "8fe359c715fd2ae9fcd23ce032db63b614c54a7ffa93d0d09f372ca8ce650a2d"}, "frame_methods.Iteration.peakmem_itertuples_raw_start": {"code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "272b9bfb026dbc2a26ff243d1472c4c5000b043b7f6d08475c58d2eea0fb7479"}, "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "5735b8cbc4657bb6b1c7647dd87916cb025ab7a0c03046967ff91328699f579b"}, "frame_methods.Iteration.peakmem_itertuples_start": {"code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "30ee8bfd4e1b0f7b3886a25e7b6b58eb841daf95d86fe777078dc3a1a6e0f7fc"}, "frame_methods.Iteration.peakmem_itertuples_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "29022ec60f31363adfe95a6e0c89b1fee588d6ff0bb60110c42cb4e6cafae3f8"}, "frame_methods.Iteration.time_items": {"code": "class Iteration:\n    def time_items(self):\n        # (monitor no-copying behaviour)\n        if hasattr(self.df, \"_item_cache\"):\n            self.df._item_cache.clear()\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "a3861731bf05eda7aa3c8d5664873ea18b2c4fff788e54c2301204b199b7a510", "warmup_time": -1}, "frame_methods.Iteration.time_items_cached": {"code": "class Iteration:\n    def time_items_cached(self):\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items_cached", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "fb2c6167ac23608e8554e7ead95d4caa02e0036638a4d25114ef18538ee25acf", "warmup_time": -1}, "frame_methods.Iteration.time_iteritems_indexing": {"code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iteritems_indexing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "e4bdc415d5210b84a25d0b2e993dfdceae965ceeb8837359a273ff01d3e119c8", "warmup_time": -1}, "frame_methods.Iteration.time_iterrows": {"code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iterrows", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9ce5cae5c87117f30c0c5bdc7bc767f0a1124338a6ccb32f389b9a79a2693b1f", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples": {"code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "359feef2c7d34f2d7df329153ee31b137f37876d15e2ccf7765abb5bf4032ddc", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_read_first": {"code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_read_first", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "57f8b0d028caac0a0d1bd16e3052d34395cd73b9c63a06c08633b378b0db9e1d", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_start": {"code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_start", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "bf751d74248c9383bc8944d91a0c6ab80eafa400d2b46d613d2a030b0535167f", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples": {"code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9a82a07e0fb33911d647b925938129fa483b40cb4987aede10c9facfcb79d95a", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {"code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "fe5b93cb5dd6cd5ed81e748d434d9e61c55c84c4de6335b795a1ce1687060238", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_read_first": {"code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_read_first", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "f9855924a32ef13ddffb66de6c9f3b3028a50906f6817a7099e10ea7faa8b3b8", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_start": {"code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_start", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "051b433da4956d7a94bee1a13cb59b3b5aa8a1ab161c335ddc0d0855710760b6", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_to_list": {"code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_to_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9d6036b304df237988082bfb3950a32acc0f34300fb5a5dad2fd3731cfaca9e1", "warmup_time": -1}, "frame_methods.Lookup.time_frame_fancy_lookup": {"code": "class Lookup:\n    def time_frame_fancy_lookup(self):\n        self.df.lookup(self.row_labels, self.col_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8), columns=list(\"abcdefgh\"))\n        self.df[\"foo\"] = \"bar\"\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype=\"object\"\n        )\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype=\"object\"\n        )", "min_run_count": 2, "name": "frame_methods.Lookup.time_frame_fancy_lookup", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2b604e96edba00f1ff7d6d45598080562d7e9b1340a5f668fb04db9ce4916ecc", "warmup_time": -1}, "frame_methods.Lookup.time_frame_fancy_lookup_all": {"code": "class Lookup:\n    def time_frame_fancy_lookup_all(self):\n        self.df.lookup(self.row_labels_all, self.col_labels_all)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8), columns=list(\"abcdefgh\"))\n        self.df[\"foo\"] = \"bar\"\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype=\"object\"\n        )\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype=\"object\"\n        )", "min_run_count": 2, "name": "frame_methods.Lookup.time_frame_fancy_lookup_all", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0aca21cb40a6490db9c288e401928c525db508aba823dfc83d7f09a91a821ff", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_bools": {"code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_bools", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53396c27fe51bab040f207946d8fb824d0e5193a4a546c2a956b13c6471a17bc", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_floats": {"code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8ab2826673211a03105b29836d30048ce03a984a5717e2b7be1add61ab6fe617", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_one_column": {"code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f196da50ee662e5f45fc59348ba8dab8cd8001a8c0803391b04a15a5ab9ba1c6", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_two_columns": {"code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1cc9433dc1b9753c4cab5d1956c45fd1ab74e93f448a89f1546d440a4a0665de", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_one_column": {"code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27c5184fe8335848e6623274d362d512693ced3fc8c65554e82ee94d4a455b22", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_two_columns": {"code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad2ef1d4cc6afb192ebca737f1e7386a643327e98a08ed5aaec53dadb9240879", "warmup_time": -1}, "frame_methods.Nunique.time_frame_nunique": {"code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))", "min_run_count": 2, "name": "frame_methods.Nunique.time_frame_nunique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7e9a2a2bfaa0bd91728100f010a191c5df8ebb6b4195374fab430a8ed55aec4", "warmup_time": -1}, "frame_methods.Quantile.time_frame_quantile": {"code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Quantile.time_frame_quantile", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de7bdc35beb87fb5a1b8686e508e01472f6a3d0b1a9826051fcdf2e62a8f9f1f", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis0": {"code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis0", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f0b49140d8abc5c02950056d69ffc319f6fb3ebb415055a0b7dd1440ec33640", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1": {"code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a7cfa7fcb0fa34d014a7dccd82441b76e93cacfae68adefe4dd166acdf271c19", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_both_axes": {"code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_both_axes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92e767dd4cbc042705f4af6551bca8b62b036a30fcf00a57190673fa70427c8a", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_upcast": {"code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_upcast", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "26e863db12a9ed65563619a29a002b111054581eaa177a39d8ab3edeef952240", "warmup_time": -1}, "frame_methods.Rename.time_dict_rename_both_axes": {"code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_dict_rename_both_axes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2599de00e34952820784b2cdcd16a948a82a3d6ca752820e080958e93387a7f", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis0": {"code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis0", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77c58d2084037dbbe231d9375b7f07069698815487f491bf7433010fd87e506c", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis1": {"code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f3a4bf2fd3d707fd9c6712b755c75fa979469fa3f1eda253d1d2a9ef7633689", "warmup_time": -1}, "frame_methods.Rename.time_rename_both_axes": {"code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_both_axes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1cb408763b71013feeaac0a79d55e743d2379c3c79927e75c2e68f64342a151", "warmup_time": -1}, "frame_methods.Rename.time_rename_single": {"code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_single", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "89c801d31118615ff40353f240e20122e6e43990886fced880152dfcbec70948", "warmup_time": -1}, "frame_methods.Repr.time_frame_repr_wide": {"code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_frame_repr_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb568593c4b33a8ed38975470fe6b29f317e157c2bff6ad7e3194854ce3bbbf0", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_mi": {"code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_mi", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "640e4b10b23c1fa98c0a07091d957e75121bc0a9d12182901ff89421df574cb9", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_si": {"code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_si", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0625c38f50ef3e2614a975c3b97cfa8b69d5ba7babc9417f10f946020fd6ddfe", "warmup_time": -1}, "frame_methods.Repr.time_repr_tall": {"code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_repr_tall", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f32bf0352558e8826294895745a574c3f76d158504f298372a9f26190ec8aba7", "warmup_time": -1}, "frame_methods.SelectDtypes.time_select_dtypes": {"code": "class SelectDtypes:\n    def time_select_dtypes(self, n):\n        self.df.select_dtypes(include=\"int\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, n):\n        self.df = DataFrame(np.random.randn(10, n))", "min_run_count": 2, "name": "frame_methods.SelectDtypes.time_select_dtypes", "number": 0, "param_names": ["n"], "params": [["100", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "528d5c7263626d3ea9389215f47d94b249559e56b82daa7eea802418d9f5f72e", "warmup_time": -1}, "frame_methods.Shift.time_shift": {"code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))", "min_run_count": 2, "name": "frame_methods.Shift.time_shift", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "395684e7863d6ac7ba645245929a877db93acae804ce3111495aa5b0f1a8209a", "warmup_time": -1}, "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns": {"code": "class SortIndexByColumns:\n    def time_frame_sort_values_by_columns(self):\n        self.df.sort_values(by=[\"key1\", \"key2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndexByColumns:\n    def setup(self):\n        N = 10000\n        K = 10\n        self.df = DataFrame(\n            {\n                \"key1\": tm.makeStringIndex(N).values.repeat(K),\n                \"key2\": tm.makeStringIndex(N).values.repeat(K),\n                \"value\": np.random.randn(N * K),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d00f619ddd6ecf75003e3d3b3abffea78395e46922a4fdbb70b1cf564736228f", "warmup_time": -1}, "frame_methods.SortValues.time_frame_sort_values": {"code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by=\"A\", ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list(\"AB\"))", "min_run_count": 2, "name": "frame_methods.SortValues.time_frame_sort_values", "number": 0, "param_names": ["ascending"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4f4ef42c704be9a9d5954f164ec62917e674951b3721eeacfc378e2879de9bb", "warmup_time": -1}, "frame_methods.ToHTML.time_to_html_mixed": {"code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range(\"2000\", periods=nrows)\n        self.df2[1] = range(nrows)", "min_run_count": 2, "name": "frame_methods.ToHTML.time_to_html_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "715ba060a149d5eeee2b41ed24c38cd5641e94cd24868829505b1eff341d2bcb", "warmup_time": -1}, "frame_methods.ToString.time_to_string_floats": {"code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))", "min_run_count": 2, "name": "frame_methods.ToString.time_to_string_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35ba9d12bdf34f2d470d8cdd3bec022ad580be8c77b8ff412859229dd04409cd", "warmup_time": -1}, "frame_methods.XS.time_frame_xs": {"code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10 ** 4\n        self.df = DataFrame(np.random.randn(self.N, self.N))", "min_run_count": 2, "name": "frame_methods.XS.time_frame_xs", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12a817f099f2facea621b0b1853a0bedd3fd9787540882c16193a6fdc0407561", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_day": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_day", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75e772362637063b852fed995fbd98c374b63eed21ea2e967b8da73c77bb69e6", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0aa4a324839c08d386eda4a105f2f8a0bd6af4b353e736e795ef25ed08391bb6", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_normalize": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "89124d4eab67def513c8a25a8f196d8502c315b20ebdefbd181ed431772472cb", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_year": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_year", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2724c46d71779f44374a89c344c88bc6e9b0d2d6c8a81987d3be3a0b85703573", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_to_period": {"code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period(\"S\")\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_to_period", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09f7045f2217de016bf68db96710a9939c4bf111ec80c48977bbf1dd4dfc8154", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_period_to_datetime": {"code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n    \n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_period_to_datetime", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2974d0fe033a251229974e89054e318e26caaabf40044728c5ee5bf5b44aba8", "warmup_time": -1}, "gil.ParallelFactorize.time_loop": {"code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_loop", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "94e3f40e863170a2303d591ae0d7400bb3eb6c245c888b97d317bdbb2e4a40f5", "warmup_time": -1}, "gil.ParallelFactorize.time_parallel": {"code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_parallel", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57bd0790bc69db5cef047e9d0babf38de7c440cd50472f73f9682893205d1231", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_loop": {"code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        ngroups = 10 ** 3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_loop", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8852a82cee7fa6b0f7655a97f691cb45eb83fd83184e9b5e02f319388fa9696c", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_parallel": {"code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        ngroups = 10 ** 3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_parallel", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b33555c38212d27b55ba46856fb83c428872611d48c338819637dfd796de8cb2", "warmup_time": -1}, "gil.ParallelGroups.time_get_groups": {"code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        size = 2 ** 22\n        ngroups = 10 ** 3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n    \n        self.get_groups = get_groups", "min_run_count": 2, "name": "gil.ParallelGroups.time_get_groups", "number": 0, "param_names": ["threads"], "params": [["2", "4", "8"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "58c29e33ad3624c669c3f7af162f16befbe7896262c6f9c4e3a0bfe21c410d04", "warmup_time": -1}, "gil.ParallelKth.time_kth_smallest": {"code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 7\n        k = 5 * 10 ** 5\n        kwargs_list = [{\"arr\": np.random.randn(N)}, {\"arr\": np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n    \n        self.parallel_kth_smallest = parallel_kth_smallest", "min_run_count": 2, "name": "gil.ParallelKth.time_kth_smallest", "number": 1, "param_names": [], "params": [], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b23b01de21edf57804e7b0c39020a966a6d357e5616f58beeb2f078162420bf4", "warmup_time": -1}, "gil.ParallelReadCSV.time_read_csv": {"code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        rows = 10000\n        cols = 50\n        data = {\n            \"float\": DataFrame(np.random.randn(rows, cols)),\n            \"datetime\": DataFrame(\n                np.random.randn(rows, cols), index=date_range(\"1/1/2000\", periods=rows)\n            ),\n            \"object\": DataFrame(\n                \"foo\", index=range(rows), columns=[\"object%03d\" for _ in range(5)]\n            ),\n        }\n    \n        self.fname = f\"__test_{dtype}__.csv\"\n        df = data[dtype]\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n    \n        self.parallel_read_csv = parallel_read_csv", "min_run_count": 2, "name": "gil.ParallelReadCSV.time_read_csv", "number": 1, "param_names": ["dtype"], "params": [["'float'", "'object'", "'datetime'"]], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "70fd4b5b4fe0d106731b8f8aea1e553d0823b8d39fc3126a026c02f7cc25b628", "warmup_time": -1}, "gil.ParallelRolling.time_rolling": {"code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, \"rolling\"):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n    \n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {\n                \"median\": rolling_median,\n                \"mean\": rolling_mean,\n                \"min\": rolling_min,\n                \"max\": rolling_max,\n                \"var\": rolling_var,\n                \"skew\": rolling_skew,\n                \"kurt\": rolling_kurt,\n                \"std\": rolling_std,\n            }\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n    \n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError", "min_run_count": 2, "name": "gil.ParallelRolling.time_rolling", "number": 0, "param_names": ["method"], "params": [["'median'", "'mean'", "'min'", "'max'", "'var'", "'skew'", "'kurt'", "'std'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5474eeb3521a09356dc9f3427339f0b76363f1cc500804964145af389add9c49", "warmup_time": -1}, "gil.ParallelTake1D.time_take1d": {"code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        df = DataFrame({\"col\": np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_1d(df[\"col\"].values, indexer)\n    \n        self.parallel_take1d = parallel_take1d", "min_run_count": 2, "name": "gil.ParallelTake1D.time_take1d", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'float64'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5818928be5c1d540612006783a650fd8fdd5350f79d4eef42d55d07b6fd5ea0c", "warmup_time": -1}, "groupby.AggFunctions.time_different_numpy_functions": {"code": "class AggFunctions:\n    def time_different_numpy_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": np.mean, \"value2\": np.var, \"value3\": np.sum}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_numpy_functions", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:259", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6ee4cc58184d4aa1269bb6a2ac74fc444182645971a229353f27b1912da5be37", "warmup_time": -1}, "groupby.AggFunctions.time_different_python_functions_multicol": {"code": "class AggFunctions:\n    def time_different_python_functions_multicol(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_python_functions_multicol", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:259", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3edc4f3884f2bbd2493f58ca31381e1bd77a0c16cc6d11542b0682b4e551b8ac", "warmup_time": -1}, "groupby.AggFunctions.time_different_python_functions_singlecol": {"code": "class AggFunctions:\n    def time_different_python_functions_singlecol(self, df):\n        df.groupby(\"key1\").agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_python_functions_singlecol", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:259", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b8e71e5376fa38e20f04d7a1c681fad844d81fa1776dc44a6a81eb61223c3dc", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions": {"code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:259", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb0cebddbe4907ca29f6eae3b6fd8e031f8eecd9af3ca590b195a872442f7411", "warmup_time": -1}, "groupby.Apply.time_copy_function_multi_col": {"code": "class Apply:\n    def time_copy_function_multi_col(self, df):\n        df.groupby([\"key\", \"key2\"]).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_copy_function_multi_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:72", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7caa7cf81a6dd8d45f4b3b086c550c6f4d2c8016efb3c7b07a9870780caadf93", "warmup_time": -1}, "groupby.Apply.time_copy_overhead_single_col": {"code": "class Apply:\n    def time_copy_overhead_single_col(self, df):\n        df.groupby(\"key\").apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_copy_overhead_single_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:72", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a45a72a6e4efcf344d8245420af3e0987cad2a4658119959a42dd0cfa795afab", "warmup_time": -1}, "groupby.Apply.time_scalar_function_multi_col": {"code": "class Apply:\n    def time_scalar_function_multi_col(self, df):\n        df.groupby([\"key\", \"key2\"]).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_multi_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:72", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91c0160c3a4ba10d96e163a79a23e8a38f733cd7e582d2c1bf5f2390b4ac02d8", "warmup_time": -1}, "groupby.Apply.time_scalar_function_single_col": {"code": "class Apply:\n    def time_scalar_function_single_col(self, df):\n        df.groupby(\"key\").apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_single_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:72", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe75d3db2c5a68826fe04e4e30e5e72486b6f605865a3940b2b8ba57304d8608", "warmup_time": -1}, "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {"code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(\n            lambda x: {\"first\": x.values[0], \"last\": x.values[-1]}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))", "min_run_count": 2, "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7306d0425d24ffcac744bea3e865fc95af5c142c68b6548a1297223cf7df7188", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_nosort": {"code": "class Categories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_nosort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "189523e24e4fe739d68e72ec32a88e9f4cb687916fc9de16172a97521d5f10a7", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_sort": {"code": "class Categories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_sort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8c1449a8fb8244310d26844f5d5dcfeb175739bb6b72e93b659249c0ceb0c7f6", "warmup_time": -1}, "groupby.Categories.time_groupby_nosort": {"code": "class Categories:\n    def time_groupby_nosort(self):\n        self.df.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_nosort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eba44e107187ca1878919c2640adadc899230bdfe8e7aeaf3bcdf450087869e6", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_nosort": {"code": "class Categories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_nosort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1b657acae0e919defc1d9c2dee71e1f055f48461f1c6d87863a9df9aa10221e3", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_sort": {"code": "class Categories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_sort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28a34a32d7309935dabcb3ef1ec2765996888aa364f568f84d03e23a4522ad2e", "warmup_time": -1}, "groupby.Categories.time_groupby_sort": {"code": "class Categories:\n    def time_groupby_sort(self):\n        self.df.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_sort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "245f7173c9eb7ea7e56723e6668e1fff81d3d7f681e1ea70321f6512d09ce505", "warmup_time": -1}, "groupby.CountMultiDtype.time_multi_count": {"code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64(\"nat\")\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64(\"nat\")\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list(\"ab\"), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"dates\": dates,\n                \"value2\": value2,\n                \"value3\": np.random.randn(n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"obj\": obj,\n                \"offsets\": offsets,\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiDtype.time_multi_count", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:210", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5155fc72a8f81e6f45a2f0a8bb61e21d723c3a10d15e404505ec60dfb103688b", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_count": {"code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_count", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:239", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7e39723ecb7101115788a8afb077129248a15ef9441d15fd33b3a8cfbaea10a9", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_nunique": {"code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby([\"key1\", \"key2\"]).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_nunique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:239", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0690c0c32a6300fc9db91ca9e638ae425b9725583089932aa680314382244798", "warmup_time": -1}, "groupby.DateAttributes.time_len_groupby_object": {"code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2005\", freq=\"H\")\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)", "min_run_count": 2, "name": "groupby.DateAttributes.time_len_groupby_object", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a56ea61ccf5d9d27faa0d9faa16af0eba4ae94278ce39fe3ba51014da44af8c9", "warmup_time": -1}, "groupby.Datelike.time_sum": {"code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10 ** 4\n        rng_map = {\n            \"period_range\": period_range,\n            \"date_range\": date_range,\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\n        }\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\n        self.df = DataFrame(np.random.randn(10 ** 4, 2))", "min_run_count": 2, "name": "groupby.Datelike.time_sum", "number": 0, "param_names": ["grouper"], "params": [["'period_range'", "'date_range'", "'date_range_tz'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e12f97af6eba16938d143b14c6627f690bf3ced55ad523e17dd883d5e6bc6cda", "warmup_time": -1}, "groupby.Float32.time_sum": {"code": "class Float32:\n    def time_sum(self):\n        self.df.groupby([\"a\"])[\"b\"].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame(dict(a=arr, b=arr))", "min_run_count": 2, "name": "groupby.Float32.time_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29518f4ff1b0f70b59a4ef5c928a6b81f00f2520372c1ee22920d3b834269041", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_field": {"code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application):\n        if method in method_blacklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups)\n        values = rng.take(np.random.randint(0, ngroups, size=size))\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        df = DataFrame({\"values\": values, \"key\": key})\n    \n        if application == \"transform\":\n            if method == \"describe\":\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\"key\")[\"values\"].transform(method)\n            self.as_field_method = lambda: df.groupby(\"values\")[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[\"values\"], method)\n            self.as_field_method = getattr(df.groupby(\"values\")[\"key\"], method)", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_field", "number": 0, "param_names": ["dtype", "method", "application"], "params": [["'int'", "'float'", "'object'", "'datetime'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'ffill'", "'first'", "'head'", "'last'", "'mad'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a485337d85204b3e1473848a1064ca72445b722ec729acff37787d3599f5f8a", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_group": {"code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application):\n        if method in method_blacklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups)\n        values = rng.take(np.random.randint(0, ngroups, size=size))\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        df = DataFrame({\"values\": values, \"key\": key})\n    \n        if application == \"transform\":\n            if method == \"describe\":\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\"key\")[\"values\"].transform(method)\n            self.as_field_method = lambda: df.groupby(\"values\")[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[\"values\"], method)\n            self.as_field_method = getattr(df.groupby(\"values\")[\"key\"], method)", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_group", "number": 0, "param_names": ["dtype", "method", "application"], "params": [["'int'", "'float'", "'object'", "'datetime'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'ffill'", "'first'", "'head'", "'last'", "'mad'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a5b5b9ebe1d23030e36afbe07997101457434455ff0f3930a65f430968e8cda", "warmup_time": -1}, "groupby.GroupManyLabels.time_sum": {"code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "groupby.GroupManyLabels.time_sum", "number": 0, "param_names": ["ncols"], "params": [["1", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5b70f52b943e8d1c375a69663a0b6ae86596f170b8e7a1f57fd4866f5dad6b9f", "warmup_time": -1}, "groupby.GroupStrings.time_multi_columns": {"code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list(\"abcd\")).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10 ** 5\n        alpha = list(map(\"\".join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list(\"abcd\"))\n        self.df[\"joe\"] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)", "min_run_count": 2, "name": "groupby.GroupStrings.time_multi_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c31f22cdb9dd824661e0a4bf02aff6eac40b0ebfe0dd33467433546f64f09801", "warmup_time": -1}, "groupby.Groups.time_series_groups": {"code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10 ** 6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                tm.makeStringIndex(100).take(np.random.randint(0, 100, size=size))\n            ),\n            \"object_large\": Series(\n                tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=size))\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_groups", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:110", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3ce3b30e8ceabf2d69d9a261f981be1ef6b768be0bd74e29989cd5bda3dbac12", "warmup_time": -1}, "groupby.Int64.time_overflow": {"code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list(\"abcde\")\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df[\"jim\"], self.df[\"joe\"] = np.random.randn(2, len(self.df)) * 10", "min_run_count": 2, "name": "groupby.Int64.time_overflow", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0e43d115b658d3b62215c2050ccaed24e564025449b1faf46ba3c2e67a2e041c", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_lambda_sum": {"code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_lambda_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:306", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c476b17358172730bd4043672625a485a7b4659e0828670015f38eac3b968f5e", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_numpy_sum": {"code": "class MultiColumn:\n    def time_col_select_numpy_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(np.sum)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_numpy_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:306", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e48dd2290719f18ad5dd837520e9f7e3fe4cefbb9ce91ac8bb7561f714f7039", "warmup_time": -1}, "groupby.MultiColumn.time_cython_sum": {"code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_cython_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:306", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a2214dc48f432326d77ce11df2627f49ae9922194113517c30031f7aabd6bb57", "warmup_time": -1}, "groupby.MultiColumn.time_lambda_sum": {"code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_lambda_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "groupby:306", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e650fba9f344fbb2ce9dc61688ac6af919e0e412e2eb07306ee5e01d187f9c2d", "warmup_time": -1}, "groupby.Nth.time_frame_nth": {"code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby(\"key\").nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ebe980da4feeaca34e4dc52b26d89c9e0570323731a4af2150495ef9d2b69ffb", "warmup_time": -1}, "groupby.Nth.time_frame_nth_any": {"code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3029d981fc91e28f368b3e0b4569602da798a238ba8333c5fa2c0b72c52f92e2", "warmup_time": -1}, "groupby.Nth.time_groupby_nth_all": {"code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_groupby_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23f7e6ede34c209838cbe9c73289a14ba2c0ad7e57a2375840140629fc5106d4", "warmup_time": -1}, "groupby.Nth.time_series_nth": {"code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59c3e2002d3c65896d846fb8023fc334c7fc919545c50a5e8462e880b0734d37", "warmup_time": -1}, "groupby.Nth.time_series_nth_all": {"code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aa31908cb47f493080b6cd080b5a2e3fae3a3183a0933df228b06e8d0e14780", "warmup_time": -1}, "groupby.Nth.time_series_nth_any": {"code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6db5b0eafed4133c74568f9202b340fa1f36719945c502f83f7e2e86fee7a1d4", "warmup_time": -1}, "groupby.RankWithTies.time_rank_ties": {"code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby(\"key\").rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10 ** 4\n        if dtype == \"datetime64\":\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.array([1] * N, dtype=dtype)\n        self.df = DataFrame({\"values\": data, \"key\": [\"foo\"] * N})", "min_run_count": 2, "name": "groupby.RankWithTies.time_rank_ties", "number": 0, "param_names": ["dtype", "tie_method"], "params": [["'float64'", "'float32'", "'int64'", "'datetime64'"], ["'first'", "'average'", "'dense'", "'min'", "'max'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccf1cafbd0467da2e8612f6cb698a5477d2885a1a66f8267a5e680ea5781d06a", "warmup_time": -1}, "groupby.Size.time_category_size": {"code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10 ** 5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_category_size", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b28daff814909c3d3c6f8ca23a0ff6f7759d36b37272b23a0a1c26909839c61", "warmup_time": -1}, "groupby.Size.time_multi_size": {"code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby([\"key1\", \"key2\"]).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10 ** 5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_multi_size", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9f6465bc98fff46ce57ece80e25ecc0e5bde5e02392c407a6e62d54f625c26cb", "warmup_time": -1}, "groupby.SumBools.time_groupby_sum_booleans": {"code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby(\"ii\").sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})", "min_run_count": 2, "name": "groupby.SumBools.time_groupby_sum_booleans", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7f248f14a0823a7af30345b84ab55ba9feb6084d4f677d14118b6e3f9fe2575", "warmup_time": -1}, "groupby.SumMultiLevel.time_groupby_sum_multiindex": {"code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame(\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\n        ).set_index([\"A\", \"B\"])", "min_run_count": 2, "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120.0, "type": "time", "unit": "seconds", "version": "2959228e76e229f21b04fbd29c8c128202ad3b4031495a0d59434107c009b3c7", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max": {"code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "510ed5bd300d4ac3695b2ab7f87d0d5e9405d033e94a237920e11a7af764ab4a", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key1": {"code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b6e99cc02e93f33ab106ddc56b9c8b178b732204345b60108e6cfca51fe93a7", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key2": {"code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key2", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2db34559a8a4094936f602d70c633eab0743c7ff4d5a2ec2e6291237b938184", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key3": {"code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key3", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7d9027428bfdffa896a33cc0127342dae16b98bf0789b723cb1cb5f9bacce38e", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key4": {"code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key4", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e848d5275cd586086c28efae0628532e22465426edec3d58993f2b5f4df49dd9", "warmup_time": -1}, "groupby.Transform.time_transform_ufunc_max": {"code": "class Transform:\n    def time_transform_ufunc_max(self):\n        self.df.groupby(level=\"lev1\").transform(np.max)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_ufunc_max", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d02119cc9120b46a559681e1c0010c616f58757a2f62061b22bb9ce8ed6019c", "warmup_time": -1}, "groupby.TransformBools.time_transform_mean": {"code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df[\"signal\"].groupby(self.g).transform(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({\"signal\": np.random.rand(N)})", "min_run_count": 2, "name": "groupby.TransformBools.time_transform_mean", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3c8ace12e915b437833994829c31c9e5aaefabe53ae9f050777abf3db40fd883", "warmup_time": -1}, "groupby.TransformNaN.time_first": {"code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby(\"key\").transform(\"first\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame(\n            {\"key\": np.repeat(np.arange(1000), 10), \"B\": np.nan, \"C\": np.nan}\n        )\n        self.df_nans.loc[4::10, \"B\":\"C\"] = 5", "min_run_count": 2, "name": "groupby.TransformNaN.time_first", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5bb589e7fa70fb9fa5dc5684673945c3241d9e25f86c388763f8466a1a16166c", "warmup_time": -1}, "import_pandas.timeraw_pandas": {"code": "def timeraw_pandas():\n    import pandas", "min_run_count": 2, "name": "import_pandas.timeraw_pandas", "number": 1, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "078f0008997bd8662c50352aa8e59e93a8b64cc7fd71c1dac72168dd2cbf0d0a", "warmup_time": -1}, "index_cached_properties.IndexCache.time_engine": {"code": "class IndexCache:\n    def time_engine(self, index_type):\n        self.idx._engine\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_engine", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22886df3174aadd081d39301092cd5a83cd3927ee01737dc9e5fc2ab7d9b0456", "warmup_time": -1}, "index_cached_properties.IndexCache.time_inferred_type": {"code": "class IndexCache:\n    def time_inferred_type(self, index_type):\n        self.idx.inferred_type\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_inferred_type", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28782009ee036ae76e6de0b4aa60b7f9f2e94d3ca1937d5bb4705913d9762a02", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_all_dates": {"code": "class IndexCache:\n    def time_is_all_dates(self, index_type):\n        self.idx.is_all_dates\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_all_dates", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a88e3ddebee412b9855740bfc79d1b23c8ce39660af4e1ca99883ea4f07ba1bf", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic": {"code": "class IndexCache:\n    def time_is_monotonic(self, index_type):\n        self.idx.is_monotonic\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "280197412c68b43fed51f974a9c2346521dfea1bbef8f514bc99598bf4d88981", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_decreasing": {"code": "class IndexCache:\n    def time_is_monotonic_decreasing(self, index_type):\n        self.idx.is_monotonic_decreasing\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_decreasing", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef0a35420de447d051cb7695bd696117cc9c577a4e6d90bc192a5d04cc89ba61", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_increasing": {"code": "class IndexCache:\n    def time_is_monotonic_increasing(self, index_type):\n        self.idx.is_monotonic_increasing\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_increasing", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d836875b644ef366895a1df3a14ef938bc172f65dcfa7aea7c5d5a49422bc26d", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_unique": {"code": "class IndexCache:\n    def time_is_unique(self, index_type):\n        self.idx.is_unique\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_unique", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09e53af7a5c8f70acb193aae594306a520897eed07aeb3a58751c215f014bdf6", "warmup_time": -1}, "index_cached_properties.IndexCache.time_shape": {"code": "class IndexCache:\n    def time_shape(self, index_type):\n        self.idx.shape\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_shape", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cab239b729088391da012d78c4355d5bc9140608bc5825d88461dbf10f851e73", "warmup_time": -1}, "index_cached_properties.IndexCache.time_values": {"code": "class IndexCache:\n    def time_values(self, index_type):\n        self.idx._values\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_values", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cccb8ab07373e14e1fa046b9ae21a97f24bd125f84e61fa952c7e201acafaefe", "warmup_time": -1}, "index_object.Datetime.time_is_dates_only": {"code": "class Datetime:\n    def time_is_dates_only(self):\n        self.dr._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datetime:\n    def setup(self):\n        self.dr = date_range(\"20000101\", freq=\"D\", periods=10000)", "min_run_count": 2, "name": "index_object.Datetime.time_is_dates_only", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cebe44ddc8aaa0eade94145651bbc278ac56b85b05ed24584a218bc4c03a71f8", "warmup_time": -1}, "index_object.Float64IndexMethod.time_get_loc": {"code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100000\n        a = np.arange(N)\n        self.ind = Float64Index(a * 4.8000000418824129e-08)", "min_run_count": 2, "name": "index_object.Float64IndexMethod.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "717e6a136bc8af946792fa946550ad5e4bef98b9fdb2fedec255480da8bb1021", "warmup_time": -1}, "index_object.GC.peakmem_gc_instances": {"code": "class GC:\n    def peakmem_gc_instances(self, N):\n        try:\n            gc.disable()\n    \n            for _ in range(N):\n                self.create_use_drop()\n        finally:\n            gc.enable()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "name": "index_object.GC.peakmem_gc_instances", "param_names": ["param1"], "params": [["1", "2", "5"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "19eab650f43bb724de22b58f71bcf63648dc31a8adce583af46e2ff2c2d9c482"}, "index_object.IndexAppend.time_append_int_list": {"code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_int_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "84bdbae116c9d458d7aa0d0e3c60241c8b4084e00781ce5957f485786bc7135b", "warmup_time": -1}, "index_object.IndexAppend.time_append_obj_list": {"code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_obj_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8551feb1646d6669519eabeb2447116679f19811ff8a28df5fe062bd91096ed", "warmup_time": -1}, "index_object.IndexAppend.time_append_range_list": {"code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_range_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27559b03a1f8d22f5b568f9f42f26f762810d1ec943e6cff4cdd670eed65714f", "warmup_time": -1}, "index_object.IndexEquals.time_non_object_equals_multiindex": {"code": "class IndexEquals:\n    def time_non_object_equals_multiindex(self):\n        self.idx_non_object.equals(self.mi_large_slow)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexEquals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "index_object.IndexEquals.time_non_object_equals_multiindex", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d5fd78ff71db5e2967d39bc632710857978db0a0807063d803bbcbc37234dc0e", "warmup_time": -1}, "index_object.Indexing.time_boolean_array": {"code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_array", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "88e41542fcda1655b0e327484e5a2791e52b48d6df879f0bcb1dddff041b9676", "warmup_time": -1}, "index_object.Indexing.time_boolean_series": {"code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_series", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a43d44d409e334426748c97e80a3c694c5644c384304a82390813812ee35c37", "warmup_time": -1}, "index_object.Indexing.time_get": {"code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b652464f0cef1cd2a0569439ac74cb523b2b3c95d171f3ab12510bb26847627", "warmup_time": -1}, "index_object.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4449dbcb88ecf1102e2e73c52b3b2a28d2f49ab56190cb530edb9f84d1b8f9f3", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique": {"code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "47f9ce0d7a77081fe55addf205d1b77538be5ac7b9018bcfc38965051c0f0e3b", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique_sorted": {"code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07996d309a0ca7f3f08eff5be63e3cc1195083275c97ca1d30551c37ad227f42", "warmup_time": -1}, "index_object.Indexing.time_get_loc_sorted": {"code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9c84db1451cb5f3ea84215225eccfa8523ea69719288ada2a57fb9c3ae680a9a", "warmup_time": -1}, "index_object.Indexing.time_slice": {"code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd3b856934e5e005ce9770a69eef64d01fedd0b44fe041f010a9661de4107e27", "warmup_time": -1}, "index_object.Indexing.time_slice_step": {"code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice_step", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a2c8a2141617fde24eba6b45201f6cdaffb70be49e4a5f9039cb3a45762d7312", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection": {"code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1dcb14770d7a11f5fcb5398eac30dcce92c18cd130e63cb292a80917185f9c72", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_both_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_both_duplicate(self, N):\n        self.intv.intersection(self.intv2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_both_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5fafac0a96fc25f47987b70a09c6ea47260acb9daf2ed69b72c77bc05c032fe9", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_one_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_one_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_one_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ffe2919c41d4c4ffd3a311c7c19334552a05de247520b4ab61b5194e7d575327", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_is_unique": {"code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_is_unique", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91a07134997fae00ab3a85d58bcb8a58257cdfc76d83d2479442822e1cebad6f", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_monotonic_inc": {"code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_monotonic_inc", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9a9d95dcf29fdc121f84000852f2dd79bd50e668370052c0c0a15f784a04822", "warmup_time": -1}, "index_object.Ops.time_add": {"code": "class Ops:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_add", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9a27bdb0508682402c6011b57cd52b70405fb2db79ae1f1fbd2cd427f1fb745", "warmup_time": -1}, "index_object.Ops.time_divide": {"code": "class Ops:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_divide", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13d9bce65f7ea1d1069706c8512f12687f9bf805eacb36e767e2a212523504f9", "warmup_time": -1}, "index_object.Ops.time_modulo": {"code": "class Ops:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "97e246a9aa14adeeaa85399d2f6e04dd674e09b61ed53929ae3a6d91d69bb912", "warmup_time": -1}, "index_object.Ops.time_multiply": {"code": "class Ops:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61a2bea9b99becefd7cfb5a0d725ecab21ccfc180b2de74954f3bec7edcf2a0f", "warmup_time": -1}, "index_object.Ops.time_subtract": {"code": "class Ops:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0cf7b3f984f0faaf17990da778b2a61226940d04e19b8811d1ca93b584207776", "warmup_time": -1}, "index_object.Range.time_get_loc_dec": {"code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_dec", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c637ad2dbd4b2ea661306e0be175c081bcb12061c848fe50df2e6e58e3aba060", "warmup_time": -1}, "index_object.Range.time_get_loc_inc": {"code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_inc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7cdbbc3c2b1c7a3122af0270781ca0e33080f8b350992c4f9438bd0b784659e7", "warmup_time": -1}, "index_object.Range.time_max": {"code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e897124434bead9e78ede51a609aee324026105fb462e8952dd25f1b227db39e", "warmup_time": -1}, "index_object.Range.time_max_trivial": {"code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max_trivial", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd72f017bc895baed90a243a31dcade0debc4aba24efe0439b302ca4dbb77216", "warmup_time": -1}, "index_object.Range.time_min": {"code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "84937dfafb2c2c9b37034f7ab47223fd93f2969104ae67b5ff97686452a4f449", "warmup_time": -1}, "index_object.Range.time_min_trivial": {"code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min_trivial", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca1ee4918edcec6e4b845e203280b6bc8cbb86cd98fe7d64cb3a62c829f5b9e9", "warmup_time": -1}, "index_object.SetDisjoint.time_datetime_difference_disjoint": {"code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10 ** 5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))", "min_run_count": 2, "name": "index_object.SetDisjoint.time_datetime_difference_disjoint", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b328ef6c80cf460a653d047d315f3d3f7d5e9156d930534dc92f0c73ac88b2c", "warmup_time": -1}, "index_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, dtype, method):\n        N = 10 ** 5\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        str_left = tm.makeStringIndex(N)\n        data = {\n            \"datetime\": {\"left\": dates_left, \"right\": dates_left[:-1]},\n            \"date_string\": {\"left\": date_str_left, \"right\": date_str_left[:-1]},\n            \"int\": {\"left\": int_left, \"right\": int_left[:-1]},\n            \"strings\": {\"left\": str_left, \"right\": str_left[:-1]},\n        }\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "index_object.SetOperations.time_operation", "number": 0, "param_names": ["dtype", "method"], "params": [["'datetime'", "'date_string'", "'int'", "'strings'"], ["'intersection'", "'union'", "'symmetric_difference'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31d550b482a01731e8abfb829a061e54c40d3ab183c06064faba13545556983e", "warmup_time": -1}, "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {"code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df[\"date\"] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range(\"1/1/2000\", periods=N, freq=\"H\")\n        self.df = DataFrame(np.random.randn(N, 1), columns=[\"A\"], index=idx)", "min_run_count": 2, "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff4000b15590520dfb25fa7169074fa847935af40c34df6617ddc79edd57e28b", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_indexer_list": {"code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa6956f658740e1066ccc45e9cddabc78355527c842ad0f8a38aa29a34eadd71", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7deee8a9f2b62b539266fdedc0ad3f6e56a95b030f8e0a74e7bfbe62d05fa50f", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75ddac18c92308b52fb7c7da5872a7b39398393d49482295bc22d919cfcbc0d1", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "258f428b267e252048768d80218d63718aa3cc6e29b7dd2de068ab7326deedf6", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list_like": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef5ac9629b65a2048822806ff49716f0fefd4130168a5c0c6fb8cba6c59b51fc", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "911683d935114f519649b6207c580be69bf054f6ed1a05af048811426aadea12", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_slice": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[: self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eccb3a7227263b535722c0b3fcfc87021585810a096b050a24420d254939e587", "warmup_time": -1}, "indexing.ChainIndexing.time_chained_indexing": {"code": "class ChainIndexing:\n    def time_chained_indexing(self, mode):\n        with warnings.catch_warnings(record=True):\n            with option_context(\"mode.chained_assignment\", mode):\n                df = DataFrame({\"A\": np.arange(self.N), \"B\": \"foo\"})\n                df2 = df[df.A > self.N // 2]\n                df2[\"C\"] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ChainIndexing:\n    def setup(self, mode):\n        self.N = 1000000", "min_run_count": 2, "name": "indexing.ChainIndexing.time_chained_indexing", "number": 0, "param_names": ["mode"], "params": [["None", "'warn'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce151f23acedb4a97684f559f4396ec2f4c39c842b913555a660b8f7e1452fa8", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_bool_indexer": {"code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_bool_indexer", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6de0b2afadd58cd7b2f09554a7b46ae628d905f4231710a150204d724b6d0e3c", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc": {"code": "class DataFrameNumericIndexing:\n    def time_iloc(self):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19c77440ecbc85666fb74478b31bd63f2e4087850ad61df0a33ea2d3bba11395", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc_dups", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57a810caa20e61e3f3257bed744e297d7bda5a4a486a895b41eacc16b8e02b54", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc": {"code": "class DataFrameNumericIndexing:\n    def time_loc(self):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38ba16b6a15d8ccaba376f2efaf127505173abbe9de65e3da7e7b31e37e900f8", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc_dups", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "65132c2abbdc4a03cc6b29c6b764e744ab6184801cf20aa904a3410de6ec74dd", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "909df29a7981acb729c0d74ad01b2fde70d9db6c8766880129b4f6c91949065a", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_boolean": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_boolean(self):\n        self.df[self.boolean_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_boolean", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad2218e3663453449d7d0e971fd0f1c1891d9f299e56691c61b78bd7439f9487", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_object": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a637aea5af16f14f984df3627006e6124c79719cdaf391ee0a33bfea315971c8", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_getitem_scalar": {"code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "048eff27f550bbf927ad212542f312da0a186fb06a4efc3e463cd72709bf269c", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_loc": {"code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "028080e47acace6d78fb5ac4a5bc5636eb8f3001eea44d6379b29055fae22558", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c04f84e3ca8985e8c14002de68bee23e270131c90ed5e5a6e7c1814f49374ff9", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col[\"A\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "405816f15047a9da353da4892c1b8c710e76a0ea536a9e7513cc606cd62e6b76", "warmup_time": -1}, "indexing.InsertColumns.time_assign_with_setitem": {"code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        np.random.seed(1234)\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_with_setitem", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2969827df8ba2aae6baddb199107178510011031bfd2605b88cda016b4f86788", "warmup_time": -1}, "indexing.InsertColumns.time_insert": {"code": "class InsertColumns:\n    def time_insert(self):\n        np.random.seed(1234)\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N), allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ab80f68ab16150297f79788288d53cde5933b9e18dab0592503f8e06bcfee90", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_list": {"code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "indexing:221", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ceabe9099f794f534a3cee65209eef67ef8fe5910032d09dc873b61f7db9311", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_scalar": {"code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "indexing:221", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a5ed39d9e010bebebaedde8c09666f2e8ad83c8ecc321854014b0126a9262ef4", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_list": {"code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "indexing:221", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53a67c0ae3f4a03fb6ddb93ef70355a41aaab9b4eb41712bf564868bb0ecb3c9", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_scalar": {"code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "indexing:221", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3727b780fbb12d812e665dcc2f04f1833e4fa43f9b2be7586340a83331e9535a", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_iloc": {"code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_iloc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "indexing:283", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8964b2421e6b4b74545350fae7ce591768d80f855cd1182bcfbcda2882780356", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_loc": {"code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "indexing:283", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "513fe43a7b6d5bafa7f3ab6edd7d17d16ee76988a435c950cfd10a89236d6c7c", "warmup_time": -1}, "indexing.MultiIndexing.time_index_slice": {"code": "class MultiIndexing:\n    def time_index_slice(self):\n        self.mdt.loc[self.idx, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        with warnings.catch_warnings(record=True):\n            self.mdt = DataFrame(\n                {\n                    \"A\": np.random.choice(range(10000, 45000, 1000), n),\n                    \"B\": np.random.choice(range(10, 400), n),\n                    \"C\": np.random.choice(range(1, 150), n),\n                    \"D\": np.random.choice(range(10000, 45000), n),\n                    \"x\": np.random.choice(range(400), n),\n                    \"y\": np.random.choice(range(25), n),\n                }\n            )\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index([\"A\", \"B\", \"C\", \"D\"]).sort_index()", "min_run_count": 2, "name": "indexing.MultiIndexing.time_index_slice", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2fc576ed6b10238b53e8145382fa98427e2b75a2e7f7a7f73503b732fefa0b8b", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[: self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "99d9d0a3c72340406e9c37c2104ec9e9df330782ddb1084a5438c8be26872562", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "638479bc71b9403fd79c9fe69e4f4604ca5813f4a5706c3fb59509f2cf0de3ca", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "875d502213f42e6e1cdef59908c5c6987f6700cbb82cdff5ae205a48ba24b6e6", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "168b34323ee5105765d201a5ed6f8bdc36ae40c5480284041fd0fc059a531d36", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_array": {"code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_array", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae22c331c3449871a8e27d8a37ee88c889540e859c136cf089bebb4f7313ba8f", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_list_like": {"code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d49633e9027f593fbce47bb24f44053ee36c2ce26a43d3f21ab7bb7a686d2b98", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_lists": {"code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_lists", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09d7580b7af7e32faa56384447eddf16a5cc98e2d6f3d64c22279389f6672059", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_scalar": {"code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48f8d223342a0802b997f34f3dd0c5bc49cf2ae0fc10472262bb33dbd8f046c8", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_slice": {"code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27d99618a9bd1494a08d3f9a1011797507465e72c89ead8f6cb17e8b72e24c82", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_array": {"code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_array", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96a04807ebf048ea69feb892a8fe2c717be3b3becbe6f7e6b63953326a25a96a", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d2b828f2a548c34b2f1d44be78105402e3f21721e604949e53982a9b8443b799", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35efe8fc92a9df0c26a945e0f1202b755cb8c1ee2fcb827e63aced364c91a051", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_slice": {"code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "df3ac870720d93dd89fd8b0ba0b955b2f95d22c76aa650b791c846d6d18165a1", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_array": {"code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_array", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c457baf2423e9ad2e3dd99148e0bab8580bb1a6c6db79224861cb7df5fa125d2", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d2d656826803610dd5976d17fed734f462bfd65d91791d3e56ca3ca982b65386", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "080e246574aa42955d9b58aff2a36b4c0f8bb65c12499309623a6c17ba7b4133", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0f40c2d4a063345280f6980c701cde07f2d4a8466823a565450e7b24f86ee19", "warmup_time": -1}, "indexing.Take.time_take": {"code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": Int64Index(np.arange(N)),\n            \"datetime\": date_range(\"2011-01-01\", freq=\"S\", periods=N),\n        }\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = [True, False, True, True, False] * 20000", "min_run_count": 2, "name": "indexing.Take.time_take", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "568fafa0e10416e2d2c5296f3aa63ea1cf6e7fb89447324246d339bdce96b857", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc": {"code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type):\n        self.data.get_loc(2)\n\n    def setup(self, engine_and_dtype, index_type):\n        engine, dtype = engine_and_dtype\n        N = 10 ** 5\n        values = list([1] * N + [2] * N + [3] * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=dtype),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=dtype),\n            \"non_monotonic\": np.array([1, 2, 3] * N, dtype=dtype),\n        }[index_type]\n    \n        self.data = engine(lambda: arr, len(arr))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aff10ff0b98d7e5652aaf857313e2c8e50394552d45c7160a6057efd3c87bb7e", "warmup_time": -1}, "indexing_engines.ObjectEngineIndexing.time_get_loc": {"code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc(\"b\")\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=object),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=object),\n            \"non_monotonic\": np.array(list(\"abc\") * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(lambda: arr, len(arr))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(\"b\")", "min_run_count": 2, "name": "indexing_engines.ObjectEngineIndexing.time_get_loc", "number": 0, "param_names": ["index_type"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "527fa7b8e67a6a391e13d9dfb924ef23c00f914aba0a8dae3de9fd26044a91b1", "warmup_time": -1}, "inference.DateInferOps.time_add_timedeltas": {"code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df[\"timedelta\"] + df[\"timedelta\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "inference.DateInferOps.time_add_timedeltas", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "inference:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb7e2773a0f9bd346ce94d9f4dc5f9eacf4de924e0c2d1a93fc43f146c7efba6", "warmup_time": -1}, "inference.DateInferOps.time_subtract_datetimes": {"code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df[\"datetime64\"] - df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "inference.DateInferOps.time_subtract_datetimes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "inference:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b453ef478e1c5c7a80311d1a50eac02abf69ba0c4e2100456af6434263cd940b", "warmup_time": -1}, "inference.DateInferOps.time_timedelta_plus_datetime": {"code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df[\"timedelta\"] + df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "inference.DateInferOps.time_timedelta_plus_datetime", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "inference:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ac4ad8ad95440b9da9c76ca8b914eb2b3cb13a1b7f7d2a6ab1a20e44ce175900", "warmup_time": -1}, "inference.MaybeConvertNumeric.time_convert": {"code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10 ** 6\n        arr = np.repeat([2 ** 63], N) + np.arange(N).astype(\"uint64\")\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data", "min_run_count": 2, "name": "inference.MaybeConvertNumeric.time_convert", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "inference:111", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e38cc43b80293bccee8efc27da3b3d6752ae5cf181feb6d44a5c9055a46bb389", "warmup_time": -1}, "inference.NumericInferOps.time_add": {"code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df[\"A\"] + self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_add", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd937919f68d16ec0fd2647801a9f0aeac01c03cae6f5f8d538a4c9654c26775", "warmup_time": -1}, "inference.NumericInferOps.time_divide": {"code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df[\"A\"] / self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_divide", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccb4fb941944b9bb519412cf3539bedd422f799a0104b1e2d9ef9f903d2da238", "warmup_time": -1}, "inference.NumericInferOps.time_modulo": {"code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df[\"A\"] % self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71cec0c2d3b56c09f945371b92cbd378e45dfeec0ba75bef727955f93039460b", "warmup_time": -1}, "inference.NumericInferOps.time_multiply": {"code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df[\"A\"] * self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d46e497f4485a3e6f194a018797ad7df742dceff761f9dd7545bdcf654c5958a", "warmup_time": -1}, "inference.NumericInferOps.time_subtract": {"code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df[\"A\"] - self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cd556417211d5e88dac11ad2c705be3ae213b190a49f326bf692641b93b83cb3", "warmup_time": -1}, "inference.ToNumeric.time_from_float": {"code": "class ToNumeric:\n    def time_from_float(self, errors):\n        to_numeric(self.float, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_float", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6980309784b744feb3040ae3bf845c253edc4fa597b811329cd9c220a809ce6e", "warmup_time": -1}, "inference.ToNumeric.time_from_numeric_str": {"code": "class ToNumeric:\n    def time_from_numeric_str(self, errors):\n        to_numeric(self.numstr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_numeric_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "78f51ee5f45aeb6a13548d96cc6ddcfb7c0c836c2c7c13a889d989b0d33fe0ff", "warmup_time": -1}, "inference.ToNumeric.time_from_str": {"code": "class ToNumeric:\n    def time_from_str(self, errors):\n        to_numeric(self.str, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ded33a5d0188d8345078f054a4577205b9539b5130a9f22b36e5ad001c511e11", "warmup_time": -1}, "inference.ToNumericDowncast.time_downcast": {"code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]", "min_run_count": 2, "name": "inference.ToNumericDowncast.time_downcast", "number": 0, "param_names": ["dtype", "downcast"], "params": [["'string-float'", "'string-int'", "'string-nint'", "'datetime64'", "'int-list'", "'int32'"], ["None", "'integer'", "'signed'", "'unsigned'", "'float'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a3bf441be7d1a1da58fe7040606ed5576597205aa570100b6ca3d07c8ecdb8da", "warmup_time": -1}, "io.csv.ParseDateComparison.time_read_csv_dayfirst": {"code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                sep=\",\",\n                header=None,\n                names=[\"Date\"],\n                parse_dates=[\"Date\"],\n                cache_dates=cache_dates,\n                dayfirst=True,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f73f177914ab98c71399aa7026fdd59ab6c80f75503635ba1e801fa2465635aa", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {"code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17b4d261cf1c73e37deaa136aaca086c661550b58f128907bd9940c7768c4689", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {"code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, format=\"%d-%m-%Y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ab638a45c1a6c6ee0db60c1bf6765c0de04d1720d23c9c4b0c1abe57576ae60", "warmup_time": -1}, "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {"code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                header=None,\n                parse_dates=[0],\n                cache_dates=do_cache,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache):\n        data = (\"\\n\".join(f\"10/{year}\" for year in range(2000, 2100)) + \"\\n\") * 10\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached", "number": 0, "param_names": ["do_cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4323d984705aa43fdf7942a64ea504291f5c7a9b38ea1436a8cfe6bfc72462fd", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_direct": {"code": "class ReadCSVCategorical:\n    def time_convert_direct(self):\n        read_csv(self.fname, dtype=\"category\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_direct", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "db5db07a8cf168c9e0f85a33decd8997127975714ce52c6f7b65e942890da392", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_post": {"code": "class ReadCSVCategorical:\n    def time_convert_post(self):\n        read_csv(self.fname).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_post", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22aea17946407fdca71fff00c5ec0d5e4011d1a6639f955be9f2e9914990167f", "warmup_time": -1}, "io.csv.ReadCSVComment.time_comment": {"code": "class ReadCSVComment:\n    def time_comment(self):\n        read_csv(\n            self.data(self.StringIO_input), comment=\"#\", header=None, names=list(\"abc\")\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self):\n        data = [\"A,B,C\"] + ([\"1,2,3 # comment\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))", "min_run_count": 2, "name": "io.csv.ReadCSVComment.time_comment", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a16f905694db4953dd220235a105b637321b368d013503a7efe7da4f096b76c7", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetime.time_read_csv": {"code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=50000, freq=\"S\")\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(self.iso8601).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetime.time_read_csv", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80ee6cd634fd130589419018dad2e012555ecda1755c35188bf424d2bb8981e2", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {"code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\", \"bar\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO((f\"{bad_date_value},\\n\") * 50000)", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv", "number": 0, "param_names": ["bad_date_value"], "params": [["'nan'", "'0'", "''"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9ed06d5e45df9d39dac2022a1735901cc1ef50a63e4ed9e564a4fcbde02a7e2", "warmup_time": -1}, "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {"code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, infer_datetime_format, format):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=infer_datetime_format,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, infer_datetime_format, format):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        formats = {\n            \"custom\": \"%m/%d/%Y %H:%M:%S.%f\",\n            \"iso8601\": \"%Y-%m-%d %H:%M:%S\",\n            \"ymd\": \"%Y%m%d\",\n        }\n        dt_format = formats[format]\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(dt_format).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv", "number": 0, "param_names": ["infer_datetime_format", "format"], "params": [["True", "False"], ["'custom'", "'iso8601'", "'ymd'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7b1d4d1ebd61a742cecc7053c2692782936c07878abf2c4d3e9bfb81858c5ae", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            names=list(\"abc\"),\n            float_precision=float_precision,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join(random.choice(string.digits) for _ in range(28)) for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}\" + \"{}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d37c9fd7e4f064fb5c4124e87dc2bbc00c62ae795ebb10ac007d4911fe53844", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            engine=\"python\",\n            float_precision=None,\n            names=list(\"abc\"),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join(random.choice(string.digits) for _ in range(28)) for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}\" + \"{}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05412abc1aed7a5168bc58ab5497637fe53ee137ed1a2e4a84a73e1dd4ba775e", "warmup_time": -1}, "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {"code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self):\n        with open(self.fname, \"w\") as f:\n            for i in range(self.num_rows):\n                f.write(f\"{i}\\n\")", "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks", "param_names": [], "params": [], "timeout": 60.0, "type": "memory", "unit": "bytes", "version": "ee68693f3121602831d5e6509e8961531654380b29fb99d4412e8acbb0f0e0d7"}, "io.csv.ReadCSVParseDates.time_baseline": {"code": "class ReadCSVParseDates:\n    def time_baseline(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=\",\",\n            header=None,\n            parse_dates=[1],\n            names=list(string.digits[:9]),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_baseline", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "287600b6755c20a5c91d611f3fc05337fedf7a1688ea39657371e7bdbeb4ae08", "warmup_time": -1}, "io.csv.ReadCSVParseDates.time_multiple_date": {"code": "class ReadCSVParseDates:\n    def time_multiple_date(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=\",\",\n            header=None,\n            names=list(string.digits[:9]),\n            parse_dates=[[1, 2], [1, 3]],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_multiple_date", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cca952c91310c9c575faa995b840ac6bbba864b8f5ab49ae6a059ff2c312545e", "warmup_time": -1}, "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {"code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=\",\",\n            header=None,\n            names=[\"Date\"],\n            parse_dates=[\"Date\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date", "number": 0, "param_names": ["value"], "params": [["'mY'", "'mdY'", "'hm'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "240689baeab768b6d6a54d64115e92b04bc5bd826144e79f91c95969c600b698", "warmup_time": -1}, "io.csv.ReadCSVSkipRows.time_skipprows": {"code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows):\n        read_csv(self.fname, skiprows=skiprows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows):\n        N = 20000\n        index = tm.makeStringIndex(N)\n        df = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        df.to_csv(self.fname)", "min_run_count": 2, "name": "io.csv.ReadCSVSkipRows.time_skipprows", "number": 0, "param_names": ["skiprows"], "params": [["None", "10000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c7da67f437633156061d68c994d3b1bf80e4c3e29f8e11d78b3d60c2e0c2b95", "warmup_time": -1}, "io.csv.ReadCSVThousands.time_thousands": {"code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands):\n        read_csv(self.fname, sep=sep, thousands=thousands)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = f\":{thousands}\"\n            fmt = \"{\" + fmt + \"}\"\n            df = df.applymap(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)", "min_run_count": 2, "name": "io.csv.ReadCSVThousands.time_thousands", "number": 0, "param_names": ["sep", "thousands"], "params": [["','", "'|'"], ["None", "','"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1dd3e2773e985d14913bdfb6bd71dd3e7ee1afecf3d9eeeb7e7b5350ef82735", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64": {"code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17e0ce93c2ffbe91868c4c9454080bfea64887fc4aac2e31ce44edcd67b64e0d", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_na_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(\n            self.data(self.data1), header=None, names=[\"foo\"], na_values=self.na_values\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5bb15a6455b80413a7aea5e48c5ead9f95b3434d39be6fec7bcd9e2ea995589f", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b13e96b5532c39113abca9a8ba087353bacd1ee2352bcf5059f1a56574e96379", "warmup_time": -1}, "io.csv.ToCSV.time_frame": {"code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame(\n            {\n                \"A\": np.arange(50000),\n                \"B\": np.arange(50000) + 1.0,\n                \"C\": np.arange(50000) + 2.0,\n                \"D\": np.arange(50000) + 3.0,\n            }\n        )\n        mixed_frame = DataFrame(\n            {\n                \"float\": np.random.randn(5000),\n                \"int\": np.random.randn(5000).astype(int),\n                \"bool\": (np.arange(5000) % 2) == 0,\n                \"datetime\": date_range(\"2001\", freq=\"s\", periods=5000),\n                \"object\": [\"foo\"] * 5000,\n            }\n        )\n        mixed_frame.loc[30:500, \"float\"] = np.nan\n        data = {\"wide\": wide_frame, \"long\": long_frame, \"mixed\": mixed_frame}\n        self.df = data[kind]", "min_run_count": 2, "name": "io.csv.ToCSV.time_frame", "number": 0, "param_names": ["kind"], "params": [["'wide'", "'long'", "'mixed'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90e6b4dd3c08772f28fbb5df66a793feba4b9ca12a04d1187349aaeb8681ea89", "warmup_time": -1}, "io.csv.ToCSVDatetime.time_frame_date_formatting": {"code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        self.data = DataFrame(rng, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetime.time_frame_date_formatting", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4425639bac7423c5376508d10e2980d898ecfb10a52b6e16d7499e104a85f7f", "warmup_time": -1}, "io.csv.ToCSVDatetimeBig.time_frame": {"code": "class ToCSVDatetimeBig:\n    def time_frame(self, obs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeBig.time_frame", "number": 0, "param_names": ["obs"], "params": [["1000", "10000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "fdb685350c42f049920d2e6fce84174c827d4fff16f164412c6f6b50635bf951", "warmup_time": -1}, "io.excel.ReadExcel.time_read_excel": {"code": "class ReadExcel:\n    def time_read_excel(self, engine):\n        fname = self.fname_odf if engine == \"odf\" else self.fname_excel\n        read_excel(fname, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcel.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'xlrd'", "'openpyxl'", "'odf'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "io.excel:62", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d93bce609801ba36167f62d23c589182c3b26fa16c937f99d81a26e7677c7881", "warmup_time": -1}, "io.excel.WriteExcel.time_write_excel": {"code": "class WriteExcel:\n    def time_write_excel(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        writer = ExcelWriter(bio, engine=engine)\n        self.df.to_excel(writer, sheet_name=\"Sheet1\")\n        writer.save()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcel:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcel.time_write_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'", "'xlwt'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3af7a398bcc4dfb382470ff59aade5b638bcefe7a39f6305168ed4956ccd999a", "warmup_time": -1}, "io.hdf.HDF.time_read_hdf": {"code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_read_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f74c8778c8a22a9aaaf7ffe7941c24433a00b5e3987d212b7ddbc03229b866b0", "warmup_time": -1}, "io.hdf.HDF.time_write_hdf": {"code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, \"df\", format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_write_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e636486ff92b3c290a4222c8dad28c5dc9142c0ee0b8d788fd29c96e8e162324", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select(\"table\", where=\"index > self.start and index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "555dd869ab62720acc41e3e1b9a803fe2d90ea5b623a783fb6d20c259a98ffa1", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select(\n            \"table_wide\", where=\"index > self.start_wide and index < self.stop_wide\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1860c67f997f06a5c947c9065653d0f0a31e7d1b9b0caed204f51d4e504c92ab", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store": {"code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get(\"fixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ccb4328affc895b3cdbdd2a3e3563447bd991b1549f5675788dd2e92f597799", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get(\"fixed_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d473fde84bcb32a4c6c8f90bb7e14bf3980caed546cba6eacd3e75f5ecd984f6", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select(\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e00270973784628580bfef5094f06c6dcd78d0d72ebeb910bc549d5ff94dc640", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select(\"table_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2192d54818f634111c18685c319dfbcc297d6896a7d6ef21cbdba0651dc78dfa", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select(\"table_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e750543230fe3ac766a829d9445bd13a5b967b914c184cfa9e48a42d5237b481", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_info": {"code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_info", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e8ad8bc1498f7b0f58559e63f7d98affe5aed8386eb0db44979cadedb9c7867", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_repr": {"code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_repr", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ff12499f9fa02efe754206c409f0331291cf50c6a0e9bc851dc6e635149d28f", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_str": {"code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_str", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "009e600cb001919cfcf188c4533f6c5e9702ec0e86a6bd80ad747ed11cedb324", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store": {"code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put(\"fixed_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00b2b7bde5f48f8d27a8bbf4c796be230842af99048b685a54e3190558374bb0", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put(\"fixed_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0871ae497b0da012ef574dfe4650e840aaff1c843885ace3f8d06f8c714b915e", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append(\"table_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4afe099b1a17c0ffd25aabae7e6fabfe0bef93f5a465710ffe77306b15d0803c", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append(\"table_dc_write\", self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43df69c535ce00beddf72e671f61d912dab128cbb618868adb7f34c818d49212", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append(\"table_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a4ccfff0de1e76b6b8633e8777d57fcee94022106768b8a016b00550e316121", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append(\"table_wide_write\", self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1fa31c661440c5add11f5726add4b3223bb06a787e4741c6cd142b228ec7709e", "warmup_time": -1}, "io.json.ReadJSON.time_read_json": {"code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=orient)", "min_run_count": 2, "name": "io.json.ReadJSON.time_read_json", "number": 0, "param_names": ["orient", "index"], "params": [["'split'", "'index'", "'records'"], ["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d34aebc17d59bfe05dab62ccac5292d0f72306f4bd5a50a229be6d3625a69b88", "warmup_time": -1}, "io.json.ReadJSONLines.peakmem_read_json_lines": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "8789ab40f3731850597841b1ce0c146427effd7840f6d4efb6b9540bb3ae9086"}, "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "a95da73684f684eea2e51244d330b49e45259e1a1fbb243b44beb34cd157dcee"}, "io.json.ReadJSONLines.time_read_json_lines": {"code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a3c9b78ef553f52887dcc255b44714915ebb5d92f54acb9b8e6e2569299aaac", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_concat", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9ce484aa6c962166e907627318c31e53ed94d754fd854cc91a6b988ff7c23e22", "warmup_time": -1}, "io.json.ToJSON.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "name": "io.json.ToJSON.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "0c9f5b7b52c8e2dcf833f15805eb6f177941ca0d4ba87df71208727c720da30c"}, "io.json.ToJSON.peakmem_to_json_wide": {"code": "class ToJSON:\n    def peakmem_to_json_wide(self, orient, frame):\n        base_df = getattr(self, frame).copy()\n        df = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        df.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "name": "io.json.ToJSON.peakmem_to_json_wide", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "8068ca33b740a20040ca567d4d93e105b18103f64dc97fde07ad0a70fb35a604"}, "io.json.ToJSON.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSON.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a3a49e528f8f84259bc8abd61fd06bb038ff70a11900deca35cd0669b14f30e5", "warmup_time": -1}, "io.json.ToJSON.time_to_json_wide": {"code": "class ToJSON:\n    def time_to_json_wide(self, orient, frame):\n        base_df = getattr(self, frame).copy()\n        df = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        df.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSON.time_to_json_wide", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e76990445670143a19ec0f6b13f7415578069b0cc2098a4571e1317f578318b0", "warmup_time": -1}, "io.json.ToJSONISO.time_iso_format": {"code": "class ToJSONISO:\n    def time_iso_format(self, orient):\n        self.df.to_json(orient=orient, date_format=\"iso\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONISO:\n    def setup(self, orient):\n        N = 10 ** 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        self.df = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONISO.time_iso_format", "number": 0, "param_names": ["orient"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7fb854fdd2839d0aaa7bf0bafa8c08a917bfafc980f682ec91a12aac528e63d", "warmup_time": -1}, "io.json.ToJSONLines.time_delta_int_tstamp_lines": {"code": "class ToJSONLines:\n    def time_delta_int_tstamp_lines(self):\n        self.df_td_int_ts.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_delta_int_tstamp_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "76faaadd02f2e65df8ab178f1771556bc080ffddb95721ac49ca8934cd740c89", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_lines": {"code": "class ToJSONLines:\n    def time_float_int_lines(self):\n        self.df_int_floats.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fb93ea1aedb6e92636aa1fa32482812e0e917ee47e280f3230c3446a7153a7a", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_str_lines": {"code": "class ToJSONLines:\n    def time_float_int_str_lines(self):\n        self.df_int_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_str_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41fbc44d6df2d6734d2b3f16f48c782cf9ecbf51d82c706605371a1dc593ab8b", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_dt_index_lines": {"code": "class ToJSONLines:\n    def time_floats_with_dt_index_lines(self):\n        self.df_date_idx.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_dt_index_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7715157a172d0d422ba6e29b0939e726dcd56c84d3a1a173abd5cf909acb12d6", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_int_idex_lines": {"code": "class ToJSONLines:\n    def time_floats_with_int_idex_lines(self):\n        self.df.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_int_idex_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "afc0a804f66ebae7230ba386079ccd41d527c5a0d8bb5e8a25b9eeb48ef2feaa", "warmup_time": -1}, "io.json.ToJSONMem.peakmem_float": {"code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames[\"float\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\"int\": df, \"float\": df.astype(float)}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_float", "param_names": [], "params": [], "setup_cache_key": "io.json:224", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "197a0a56ae900f371a8645d68f2d35d645047a5d5b1139d123120b47ac30354d"}, "io.json.ToJSONMem.peakmem_int": {"code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames[\"int\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\"int\": df, \"float\": df.astype(float)}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_int", "param_names": [], "params": [], "setup_cache_key": "io.json:224", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "2e27c15e78b9cc97477694de369542bc9b2220f8903b8b2b06cee187d47e1f93"}, "io.parsers.ConcatDateCols.time_check_concat": {"code": "class ConcatDateCols:\n    def time_check_concat(self, value, dim):\n        _concat_date_cols(self.object)\n\n    def setup(self, value, dim):\n        count_elem = 10000\n        if dim == 1:\n            self.object = (np.array([value] * count_elem),)\n        if dim == 2:\n            self.object = (\n                np.array([value] * count_elem),\n                np.array([value] * count_elem),\n            )", "min_run_count": 2, "name": "io.parsers.ConcatDateCols.time_check_concat", "number": 0, "param_names": ["value", "dim"], "params": [["1234567890", "'AAAA'"], ["1", "2"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "84c246e01e34c7b357ea8e6e9ae2b49854271d403aff72e89ffee50fdbf9f6ac", "warmup_time": -1}, "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {"code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000", "min_run_count": 2, "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes", "number": 0, "param_names": ["value"], "params": [["'2Q2005'", "'0.0'", "'10000'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7", "warmup_time": -1}, "io.pickle.Pickle.time_read_pickle": {"code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_read_pickle", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f57eda8d55e808305c1ca1b52e16da17adb3390c5cec487c50cae3e5f32a629", "warmup_time": -1}, "io.pickle.Pickle.time_write_pickle": {"code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_write_pickle", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31372bfc8f01bd027acaa0195886dc5125eb3a5dd286dc904366c7c3ef9a9825", "warmup_time": -1}, "io.sas.SAS.time_read_sas": {"code": "class SAS:\n    def time_read_sas(self, format):\n        read_sas(self.f, format=format)\n\n    def setup(self, format):\n        # Read files that are located in 'pandas/io/tests/sas/data'\n        files = {\"sas7bdat\": \"test1.sas7bdat\", \"xport\": \"paxraw_d_short.xpt\"}\n        file = files[format]\n        paths = [\n            os.path.dirname(__file__),\n            \"..\",\n            \"..\",\n            \"..\",\n            \"pandas\",\n            \"tests\",\n            \"io\",\n            \"sas\",\n            \"data\",\n            file,\n        ]\n        self.f = os.path.join(*paths)", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas", "number": 0, "param_names": ["format"], "params": [["'sas7bdat'", "'xport'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dc7867fee89f34daadcb5fd80fc4eda940ef2ba3c04c875a095f04a6170eef6f", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_all": {"code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_all", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93795b7490c5b3636789316ac8feb36202260fa5551819a502abdb1565e7aac7", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {"code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(\n            self.table_name,\n            self.con,\n            columns=[\"datetime_string\"],\n            parse_dates=[\"datetime_string\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b6173baf897c1ea5a6bf7f0b5af3710b99e19f181195f7231d2b76a92531977f", "warmup_time": -1}, "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {"code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e4cc858ae9f0e599e81579656ea7c93f8f17697ed3dd8d490754734addadbf3b", "warmup_time": -1}, "io.sql.SQL.time_read_sql_query": {"code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_read_sql_query", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "79016042e99815670145c7e48a4beb2b3c675d5a8199bacf53a58e61153e57ce", "warmup_time": -1}, "io.sql.SQL.time_to_sql_dataframe": {"code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_to_sql_dataframe", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f151c8d9b77be3cb95750ddb63c47b0b21b7ff4be47e198fa982b2b3e12e9b1", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {"code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e9eaa9d9e275ab02db0cb80a0c1bb612922a840ec6d35d75d75ae708e74f1f94", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {"code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fc3602e4a9ccdccfde7ae3bdc00c986fb80e9dbd1260e939b2bb2b81da048e1", "warmup_time": -1}, "io.stata.Stata.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77e3031e044e76658d6a5d5c3492e759416dd5e84e53428cf38ec919c3bdc1b7", "warmup_time": -1}, "io.stata.Stata.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e49dabe6a2ca0fdd6c7ce58e5b7c618d038e6247499641a0d4914f6518e575bc", "warmup_time": -1}, "io.stata.StataMissing.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cfcbe658a923605375cc7b0cbd5c285e378d2d5ec34bc82034af623e10889ac5", "warmup_time": -1}, "io.stata.StataMissing.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12d0ab04f51e54180002a6044381d6ee75653701f4e8345e8dad76fd2b97e12b", "warmup_time": -1}, "join_merge.Align.time_series_align_int64_index": {"code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10 ** 5\n        rng = np.arange(0, 10 ** 13, 10 ** 7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_int64_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3308a741ed72316f1e3ceba8cae34b8a0e4bbe12a827d8c7d09cda3ca638c289", "warmup_time": -1}, "join_merge.Align.time_series_align_left_monotonic": {"code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join=\"left\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10 ** 5\n        rng = np.arange(0, 10 ** 13, 10 ** 7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_left_monotonic", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa41898004f3566f630b221aab2716c93ef63d62983ae232cb91acfe94e8ccd4", "warmup_time": -1}, "join_merge.Append.time_append_homogenous": {"code": "class Append:\n    def time_append_homogenous(self):\n        self.df1.append(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1[\"obj1\"] = \"bar\"\n        self.mdf1[\"obj2\"] = \"bar\"\n        self.mdf1[\"int1\"] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index", "min_run_count": 2, "name": "join_merge.Append.time_append_homogenous", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d98df4ffdaa16119e4b7b252473797a72fa9b08c5277fd247576e38b0f12ee5a", "warmup_time": -1}, "join_merge.Append.time_append_mixed": {"code": "class Append:\n    def time_append_mixed(self):\n        self.mdf1.append(self.mdf2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1[\"obj1\"] = \"bar\"\n        self.mdf1[\"obj2\"] = \"bar\"\n        self.mdf1[\"int1\"] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index", "min_run_count": 2, "name": "join_merge.Append.time_append_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d03c315fcf9755e023f11fb9ff9952497582a58044533d52b4d4049ffa21d2d6", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_left": {"code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_left", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5f9ad5afe1e660817d50e70247e33a3f703afd2df8be1876f04763d0be0db37", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_right": {"code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_right", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "33e07ea8976d21a40107e7d5a0b7c1ef1ac3e653fbe099d27337e2acaae07d72", "warmup_time": -1}, "join_merge.Concat.time_concat_mixed_ndims": {"code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_mixed_ndims", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9413ed44e4c0aab2c13a5268d35037f512b4af709c8c40a099e603e2ef411e0c", "warmup_time": -1}, "join_merge.Concat.time_concat_series": {"code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_series", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "591b2816028fe5343a9e969d1f6fcd64081fa9c6ea6627daa86ddfc5a1ac8c52", "warmup_time": -1}, "join_merge.Concat.time_concat_small_frames": {"code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_small_frames", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d2cfb29a06db532b9a18e7b751af74b44c42f04f80bb0d506a6b34d6b8af705", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_c_ordered": {"code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_c_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48754d9f949305e562998495e7af54bda99baeb1ff03cf3bd849e9eb2fd5e011", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_f_ordered": {"code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_f_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48643c33763bfdacb7c96d0bc792ca010df9bbf8d6558807116cbcab1c584763", "warmup_time": -1}, "join_merge.I8Merge.time_i8merge": {"code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10 ** 6\n        self.left = DataFrame(\n            np.random.randint(low, high, (n, 7)), columns=list(\"ABCDEFG\")\n        )\n        self.left[\"left\"] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({\"left\": \"right\"}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right[\"right\"] *= -1", "min_run_count": 2, "name": "join_merge.I8Merge.time_i8merge", "number": 0, "param_names": ["how"], "params": [["'inner'", "'outer'", "'left'", "'right'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "021318fb7704cd5c3234f886011f5c807a3869d1826f118f6d21c0aaad33d6e1", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_multi": {"code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=[\"key1\", \"key2\"], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_multi", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "790821ad4bfe9150772c02fa7993d900cc3328796aec8996e155bfadb87bc369", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {"code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f9b7ee80173ebebd55faa4ad3bb60cb0ff7808ec9e32cb39fd85f67fa8dd66b", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_bigger": {"code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50b7166efa7ef17c24c79b834c7b1bf7dfc87058c53b02f8955952342e6a0786", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_small": {"code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_small", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13bb010c58575e8f4c6531d36d58ca2a76bd0b6ed389ec8dbe303891d7a93231", "warmup_time": -1}, "join_merge.JoinIndex.time_left_outer_join_index": {"code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on=\"jim\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 50000\n        self.left = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jim\", \"joe\"]\n        )\n        self.right = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jolie\", \"jolia\"]\n        ).set_index(\"jolie\")", "min_run_count": 2, "name": "join_merge.JoinIndex.time_left_outer_join_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9dab93d66fd2e264a14e27edc03f595fa4c43784ba6fe7c0458beb9767330a70", "warmup_time": -1}, "join_merge.JoinNonUnique.time_join_non_unique_equal": {"code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range(\"01-Jan-2013\", \"23-Jan-2013\", freq=\"T\")\n        daily_dates = date_index.to_period(\"D\").to_timestamp(\"S\", \"S\")\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype(\"timedelta64[ns]\")\n        self.fracofday = self.fracofday.astype(np.float64) / 86400000000000.0\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq=\"D\")\n        self.temp = Series(1.0, index)[self.fracofday.index]", "min_run_count": 2, "name": "join_merge.JoinNonUnique.time_join_non_unique_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b6bc3f8f5cc0b7814c325d02f69b998d8b7dbb37e746a671134bcbed6a092e58", "warmup_time": -1}, "join_merge.Merge.time_merge_2intkey": {"code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_2intkey", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ed945be79fa4f758895da38ae20e7a18708f23a0ca200274d028e94bf6601b2", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_2key": {"code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_2key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "146b4d12d3e7f46fe75784d48e6ed757ff81dab132ccf6dc7a3b9f1e7be8567e", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_key": {"code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57a9ceb8a12f4bccde9a1f65caa8dc8154e0eb846bf341e0952b5a3eebb6dda9", "warmup_time": -1}, "join_merge.MergeAsof.time_by_int": {"code": "class MergeAsof:\n    def time_by_int(self, direction, tolerance):\n        merge_asof(\n            self.df1c,\n            self.df2c,\n            on=\"time\",\n            by=\"key2\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a15ff3b838ac0c680dffafecb488c6d34116513d8ea891c503b9e8359891607", "warmup_time": -1}, "join_merge.MergeAsof.time_by_object": {"code": "class MergeAsof:\n    def time_by_object(self, direction, tolerance):\n        merge_asof(\n            self.df1b,\n            self.df2b,\n            on=\"time\",\n            by=\"key\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_object", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8f5adf6bbca5860a4758a9c1cfbba6b102a4dbef99b38b109c41a9797e5b4fc", "warmup_time": -1}, "join_merge.MergeAsof.time_multiby": {"code": "class MergeAsof:\n    def time_multiby(self, direction, tolerance):\n        merge_asof(\n            self.df1e,\n            self.df2e,\n            on=\"time\",\n            by=[\"key\", \"key2\"],\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_multiby", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71fee353035e5fcaa9e6ac36d350ecf80d112864bb929299c18e5c65324d3961", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int": {"code": "class MergeAsof:\n    def time_on_int(self, direction, tolerance):\n        merge_asof(\n            self.df1a, self.df2a, on=\"time\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8064b9b7710b46ed6d51da78eea04ae4593d33f013aa9a3fa7e93f307a23047", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int32": {"code": "class MergeAsof:\n    def time_on_int32(self, direction, tolerance):\n        merge_asof(\n            self.df1d, self.df2d, on=\"time32\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int32", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "caf7ccf963fb86330fb9289dc5d6d8fe7a9c95d41a3c29ad381760e176c2e7ec", "warmup_time": -1}, "join_merge.MergeAsof.time_on_uint64": {"code": "class MergeAsof:\n    def time_on_uint64(self, direction, tolerance):\n        merge_asof(\n            self.df1f, self.df2f, on=\"timeu64\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_uint64", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4078e9c6627567125c755f639e8628c2c91214601be3107a234795040ac04142", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_cat": {"code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_cat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24dbef20c9e18f6d0e96db661214e186e4042cc780d501367b3a8317dc990f23", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_object": {"code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_object", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa09d620dee07971de9ade56cba3d3628df11d1490f916fc629c9b58fff97065", "warmup_time": -1}, "join_merge.MergeOrdered.time_merge_ordered": {"code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on=\"key\", left_by=\"group\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = tm.makeStringIndex(10).values\n        self.left = DataFrame(\n            {\n                \"group\": groups.repeat(5000),\n                \"key\": np.tile(np.arange(0, 10000, 2), 10),\n                \"lvalue\": np.random.randn(50000),\n            }\n        )\n        self.right = DataFrame(\n            {\"key\": np.arange(10000), \"rvalue\": np.random.randn(10000)}\n        )", "min_run_count": 2, "name": "join_merge.MergeOrdered.time_merge_ordered", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2a7e5ebae72547e296e22a48baa55cc38997f5fefb2cfe93ad9cb957033f9481", "warmup_time": -1}, "multiindex_object.CategoricalLevel.time_categorical_level": {"code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index([\"a\", \"b\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n    \n        self.df = DataFrame(\n            {\n                \"a\": np.arange(1_000_000, dtype=np.int32),\n                \"b\": np.arange(1_000_000, dtype=np.int64),\n                \"c\": np.arange(1_000_000, dtype=float),\n            }\n        ).astype({\"a\": \"category\", \"b\": \"category\"})", "min_run_count": 2, "name": "multiindex_object.CategoricalLevel.time_categorical_level", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ed13d98e94a857baa73e3941062551dfcfa7db37d771965d448fb5b23ec9636", "warmup_time": -1}, "multiindex_object.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [np.arange(n), tm.makeStringIndex(n).values, 1000 + np.arange(n)]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)", "min_run_count": 2, "name": "multiindex_object.Duplicated.time_duplicated", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b14ccbe8f895db81ecbefbd4940fa2327b059bf58f9a79f27fa5b821f232101d", "warmup_time": -1}, "multiindex_object.Duplicates.time_remove_unused_levels": {"code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size), np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]", "min_run_count": 2, "name": "multiindex_object.Duplicates.time_remove_unused_levels", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52fc3b5e4ed8968affde380019b654ea84208fe579b557a8061b3a11aa90e75a", "warmup_time": -1}, "multiindex_object.Equals.time_equals_non_object_index": {"code": "class Equals:\n    def time_equals_non_object_index(self):\n        self.mi_large_slow.equals(self.idx_non_object)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "multiindex_object.Equals.time_equals_non_object_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e71ce54998e5e92bc094a5ac8d71bbbabeffd22dd4a37547f4b2462af8b52893", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc": {"code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d5ab3e20ac6ad3ea7917750281182ef71ecc3a54ab6ae19602066a7f468681d", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc_warm": {"code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc_warm", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2fe1c8e21f3befc08d5313fff82e1d45abfa4424a6f744f8092c7f4e264bd03a", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc": {"code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6191908cf16ed040ee49aeccb20a7a309da5ea80ce7c9889d8753473447e490c", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc_warm": {"code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc_warm", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2be10a2c6052f2b18365e5fe215e8601300921ad833f4aa60719b2eb1147f915", "warmup_time": -1}, "multiindex_object.GetLoc.time_small_get_loc_warm": {"code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_small_get_loc_warm", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd340b17354d038bd394c067e1628040d7bf9eb29d9a0fa7d4fe36aa09eb09b6", "warmup_time": -1}, "multiindex_object.GetLoc.time_string_get_loc": {"code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_string_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7018b856539639e5c28d4e33579fbac8e64444952d0ed9f2afa1f62021a17529", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer": {"code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1fcec1ea3f6d165c7b56f30ef6f66dd2d4197808f18d2bf31103680b41f707f0", "warmup_time": -1}, "multiindex_object.Integer.time_is_monotonic": {"code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_is_monotonic", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2343fc872e626e762dc605e552af65c3e6a22302dc96010e47e1642c2d4f300", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_int64": {"code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_int64", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3388758f5be6d27f1c810b1f3ab51c3a59f8c9fa7b7fdd2d3322f9c7c8b41ef7", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_one": {"code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_one", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3c9014e77fd360ec1d0d23b385a7a415db4760d431c8369df8f9c30ea201a461", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_zero": {"code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a514d3e4ada47f58d1d77b5a05a27db517dc74ac3c9fcec8f377ade7cef2e9f2", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_copy": {"code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "multiindex_object:122", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80325b021caac9139ea141463fa3899e70faaba340a77a5940b5299539555292", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_sliced": {"code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_sliced", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "multiindex_object:122", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93aaaf583156bc7774cb478bee76d2815888cf675cdde1433e4a095dfa1c7baf", "warmup_time": -1}, "offset.ApplyIndex.time_apply_index": {"code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        offset.apply_index(self.rng)\n\n    def setup(self, offset):\n        N = 10000\n        self.rng = pd.date_range(start=\"1/1/2000\", periods=N, freq=\"T\")", "min_run_count": 2, "name": "offset.ApplyIndex.time_apply_index", "number": 0, "param_names": ["offset"], "params": [["<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5473796dcbb527b9503d2d3f5ae7a961b2b73b103e99c0a14cf81d959a75a62", "warmup_time": -1}, "offset.OffsetDatetimeIndexArithmetic.time_add_offset": {"code": "class OffsetDatetimeIndexArithmetic:\n    def time_add_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.data + offset\n\n    def setup(self, offset):\n        N = 1000\n        self.data = pd.date_range(start=\"1/1/2000\", periods=N, freq=\"T\")", "min_run_count": 2, "name": "offset.OffsetDatetimeIndexArithmetic.time_add_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8f60fce4f2424912aa7c6614d98831e400f6e4d59afba3ec6c953edcd648f232", "warmup_time": -1}, "offset.OffsetSeriesArithmetic.time_add_offset": {"code": "class OffsetSeriesArithmetic:\n    def time_add_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.data + offset\n\n    def setup(self, offset):\n        N = 1000\n        rng = pd.date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.data = pd.Series(rng)", "min_run_count": 2, "name": "offset.OffsetSeriesArithmetic.time_add_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d7496a6da2f902a802eed05a193648c40b943dd664308999e1789862b3b0045a", "warmup_time": -1}, "package.TimeImport.time_import": {"code": "class TimeImport:\n    def time_import(self):\n        if PY37:\n            # on py37+ we the \"-X importtime\" usage gives us a more precise\n            #  measurement of the import time we actually care about,\n            #  without the subprocess or interpreter overhead\n            cmd = [sys.executable, \"-X\", \"importtime\", \"-c\", \"import pandas as pd\"]\n            p = subprocess.run(cmd, stderr=subprocess.PIPE)\n    \n            line = p.stderr.splitlines()[-1]\n            field = line.split(b\"|\")[-2].strip()\n            total = int(field)  # microseconds\n            return total\n    \n        cmd = [sys.executable, \"-c\", \"import pandas as pd\"]\n        subprocess.run(cmd, stderr=subprocess.PIPE)", "min_run_count": 2, "name": "package.TimeImport.time_import", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9b4b577142f42a010f05c2acc07c45dc17231396cd8d701fbb93eafb43ad1c10", "warmup_time": -1}, "period.Algorithms.time_drop_duplicates": {"code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_drop_duplicates", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5ed71a0e29ea9fe94acdf37fe778becc6a166703e59fe06b43693190e73c358c", "warmup_time": -1}, "period.Algorithms.time_value_counts": {"code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_value_counts", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aaad3304a09d800100a2dc5f7da82c36953722c7da6aca2ca4c2e446a3badc8", "warmup_time": -1}, "period.DataFramePeriodColumn.time_set_index": {"code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df[\"col2\"] = self.rng\n        self.df.set_index(\"col2\", append=True)\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_set_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "223baa21285346a0b70e9d11fe853a0b156662cd2530575dc66cfcb8d65cf46a", "warmup_time": -1}, "period.DataFramePeriodColumn.time_setitem_period_column": {"code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df[\"col\"] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_setitem_period_column", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7044b31af083678ecf627851ca14fa1108e6ec19cd7acf41ebe60f0283fefe8", "warmup_time": -1}, "period.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_align", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ba91f5b4184a97b1e578ce06acd5823a15ef927984c534ef97a97209494f3e9", "warmup_time": -1}, "period.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16c0233f1354d0efad7e0568b42faab3ceda761dbe321e610db062449c038b2b", "warmup_time": -1}, "period.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e473ad8ce23861754e1a2322452188035f32546b5106e9c354504575f161c9dc", "warmup_time": -1}, "period.Indexing.time_series_loc": {"code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_series_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "051bdec8fea0886aa445b372b56bf9dc434ca870d0168882015b967bb1545aa4", "warmup_time": -1}, "period.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cb344ef55a1ccd3f19e672102b836d76b728ced9a4a5813f2d76fc5be1df312b", "warmup_time": -1}, "period.Indexing.time_shape": {"code": "class Indexing:\n    def time_shape(self):\n        self.index.shape\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_shape", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b90560f1d7bd998ce4a07d0c418d358b2118aa7b112df3561dcdb93bbf723905", "warmup_time": -1}, "period.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4ce9c886be5dcc91f24921a741cee9552a169c54f69f0ec4893b19145ca6cda", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_date_range": {"code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_date_range", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90341c890b6fd853e93fe5ad5a5d9935048545a0c2bf70da9324aca627215961", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints": {"code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "40e20dbe294496152b0cab99ad8277ec6836602167d363e0c665de9915971d7d", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints_daily": {"code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints_daily", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ec1c957be1d06e33b08c4eb1a645648cba0172013a8b73a1e8c8d8f8e5725a8", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_pydatetime": {"code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_pydatetime", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e9a86e7434b9d0777e5ccc8fc9165eaf99b3ae701c88bb9a2f2bfbb3a8742c1", "warmup_time": -1}, "plotting.FramePlotting.time_frame_plot": {"code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x=\"x\", y=\"y\", kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\", \"scatter\", \"hexbin\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({\"x\": self.x, \"y\": self.y})", "min_run_count": 2, "name": "plotting.FramePlotting.time_frame_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'", "'scatter'", "'hexbin'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a82a6ba70b4d8b604d338f75ba50369652ada781c3e65bf690c22b54a9d4562d", "warmup_time": -1}, "plotting.Misc.time_plot_andrews_curves": {"code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df[\"Name\"] = [\"A\"] * N", "min_run_count": 2, "name": "plotting.Misc.time_plot_andrews_curves", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a97b4fa399b37c178eee1d0bfb886d2b6939fb52ee57620d4f78773ea3cf3ce", "warmup_time": -1}, "plotting.SeriesPlotting.time_series_plot": {"code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.s = self.s.abs()", "min_run_count": 2, "name": "plotting.SeriesPlotting.time_series_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d767b86e0b27005187efbd490211b0bc52b0a87b042c0dd78093f288337392fb", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_irregular": {"code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_irregular", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09c463e16e938e14d13afbfccdd38fd15d0d8236d8c3c01ceb1743a161c6cbe5", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular": {"code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c03160971a62e9c71dbf1cd41d67d532c08fcdb6ad5e6558e700b18e899ed769", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular_compat": {"code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular_compat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8e4bd7cff7dea2ee4bfcdfe2d8336071341fb5c9ec82e874a8b1800ec00f4338", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_table": {"code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f12479ad74f8626efab8c8468bfaea80edb10121f16cdddcd60cdfce3959b0ca", "warmup_time": -1}, "reindex.Align.time_align_series_irregular_string": {"code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = tm.makeStringIndex(n)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(\n            np.random.randn(subsample_size),\n            index=np.random.choice(indices, subsample_size, replace=False),\n        )", "min_run_count": 2, "name": "reindex.Align.time_align_series_irregular_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cd2788cb4afb3141bb5fc05d8c7aa5a75a1d94b188caf0119da7823e7d0966bb", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups": {"code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9237c94639d80a5c2162f4891f487356ce5485918beccb48398b89abae8f1808", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_bool": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_bool", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9a42ee5a1945bfff466ebffac814442a29e988f9f3380790e00cb8dd3cc5466d", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_int": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9261807f4c65e55fc53d6d73c421d108147f139980b85fdb28fe50e691f36a33", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_na": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_na", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1662080bfa2eab6ff5ba7afa7f71fe3e59da052b90b11bc05312899570a12f72", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_int": {"code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea276bb62cde4cdd53c8e3adbc2c78ee97c243bc711d94a0ea086554df7f0c72", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_string": {"code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_string", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39ae3e74e31a6a5b67fb34e737f839f35d85b5bd99c5121c6e3069b9ec759ab9", "warmup_time": -1}, "reindex.Fillna.time_float_32": {"code": "class Fillna:\n    def time_float_32(self, method):\n        self.ts_float32.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")", "min_run_count": 2, "name": "reindex.Fillna.time_float_32", "number": 0, "param_names": ["method"], "params": [["'pad'", "'backfill'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0197c9edf8b40b8bbcad67f83cfbe53e0eaf8d4ba9bd8b935d53d24b410eaea1", "warmup_time": -1}, "reindex.Fillna.time_reindexed": {"code": "class Fillna:\n    def time_reindexed(self, method):\n        self.ts_reindexed.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")", "min_run_count": 2, "name": "reindex.Fillna.time_reindexed", "number": 0, "param_names": ["method"], "params": [["'pad'", "'backfill'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6bdee4dd2ca6819211b9c9f4c3da575e033bbde298f8a9a8dc35107e0a203d8", "warmup_time": -1}, "reindex.LevelAlign.time_align_level": {"code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_align_level", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a1c48e1f021ca0595344c5b228a595996019c20b124df6cda920dfc2601a30c", "warmup_time": -1}, "reindex.LevelAlign.time_reindex_level": {"code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_reindex_level", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28f65e86fee2be64ff3a604df5fecd6ac0cb444a2c8f3b9c5cf02cfb61142fcc", "warmup_time": -1}, "reindex.LibFastZip.time_lib_fast_zip": {"code": "class LibFastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LibFastZip:\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)", "min_run_count": 2, "name": "reindex.LibFastZip.time_lib_fast_zip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "76fdb90c052b51d11271496acb9a6821f878a7773f3c672274559b2ae5dacd7c", "warmup_time": -1}, "reindex.Reindex.time_reindex_columns": {"code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "788a93ab840e0451eed006c2a03ab21175634464af82c16cd539150321f627af", "warmup_time": -1}, "reindex.Reindex.time_reindex_dates": {"code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_dates", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "072ea7775ff5e2752d9fb95ceb6a9331fa5bb6685587458b5027c97533c6fbfa", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex": {"code": "class Reindex:\n    def time_reindex_multiindex(self):\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cba70158f687c138ffd0245e2329691ba0f77f193a37a1e5740c1cccd377a67a", "warmup_time": -1}, "reindex.ReindexMethod.time_reindex_method": {"code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor(\"1/1/2000\", periods=N, freq=\"1min\")\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]", "min_run_count": 2, "name": "reindex.ReindexMethod.time_reindex_method", "number": 0, "param_names": ["method", "constructor"], "params": [["'pad'", "'backfill'"], ["<function date_range>", "<function period_range>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "65e6920b65629155af433aa881ca6c69f1a43c7ef066c56d2eeadac660651331", "warmup_time": -1}, "replace.Convert.time_replace": {"code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10 ** 3\n        data = {\n            \"Series\": pd.Series(np.random.randint(N, size=N)),\n            \"DataFrame\": pd.DataFrame(\n                {\"A\": np.random.randint(N, size=N), \"B\": np.random.randint(N, size=N)}\n            ),\n        }\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]", "min_run_count": 2, "name": "replace.Convert.time_replace", "number": 0, "param_names": ["constructor", "replace_data"], "params": [["'DataFrame'", "'Series'"], ["'Timestamp'", "'Timedelta'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a381501b15044f4ccf367694555646711d929b2854428d8866a18559013cbbd", "warmup_time": -1}, "replace.FillNa.time_fillna": {"code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10 ** 6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_fillna", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea2d8ce668d229f4ca607218129ac8adad7222a1887b49a779a86e9f1027ce83", "warmup_time": -1}, "replace.FillNa.time_replace": {"code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10 ** 6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_replace", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb3764acc296685f9c32dfbc06b542217babc15807c5131f4fe3168645ca5bdf", "warmup_time": -1}, "replace.ReplaceDict.time_replace_series": {"code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10 ** 5\n        start_value = 10 ** 5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10 ** 3))", "min_run_count": 2, "name": "replace.ReplaceDict.time_replace_series", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5355f1706157acb5ebd177c64d5af0b4b8336bdf839fc88621891a02fc0f7556", "warmup_time": -1}, "replace.ReplaceList.time_replace_list": {"code": "class ReplaceList:\n    def time_replace_list(self, inplace):\n        self.df.replace([np.inf, -np.inf], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10 ** 7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7f2eb52e758e5ccca9aa1d74365b39609e14ea776dc0d6df813cd2a6b40af33", "warmup_time": -1}, "replace.ReplaceList.time_replace_list_one_match": {"code": "class ReplaceList:\n    def time_replace_list_one_match(self, inplace):\n        # the 1 can be held in self._df.blocks[0], while the inf and -inf cant\n        self.df.replace([np.inf, -np.inf, 1], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10 ** 7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list_one_match", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95acf97c93331fe43a4d9f339b438258ec753abd14b795cfa44e62e41ba5db10", "warmup_time": -1}, "reshape.Crosstab.time_crosstab": {"code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77853e1f97d25f0dd2a73b4a91565deb7ad0c5a0f796470e04794789b16efe40", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize": {"code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0a97c166effb33df1099cf73dda0925878dee0410b80330c4d5e5ad365a2fd00", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize_margins": {"code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize_margins", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "762af7c2d612ddea47095ceb57e359a55ba836a8b949abf69b906fef2f254210", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_values": {"code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc=\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8080df822c9d4aab1bb0f157a9086c8b6f8e3dff66a19202b9af66414e7e833d", "warmup_time": -1}, "reshape.Cut.peakmem_cut_interval": {"code": "class Cut:\n    def peakmem_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "name": "reshape.Cut.peakmem_cut_interval", "param_names": ["bins"], "params": [["4", "10", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "65f32ed0d341db6c2b0f5a37e6903c163dddded94bceb58a6014252b0d2afa4e"}, "reshape.Cut.time_cut_datetime": {"code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b452177e79002b6cde2aba150e235a71156a97d3910bc277fea5631102218769", "warmup_time": -1}, "reshape.Cut.time_cut_float": {"code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e3f1351b0833b30982d3b3842bf35e08e9f48d3920e07685ce977c63b098346", "warmup_time": -1}, "reshape.Cut.time_cut_int": {"code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a84c4f6235e020582f0511d88d52bd7b87f5f11c04271b389b762235c59a5001", "warmup_time": -1}, "reshape.Cut.time_cut_interval": {"code": "class Cut:\n    def time_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_interval", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11eeaec35829b8bbb0fe2a6813d3ab35a524ef41e78027894bd523d0dde17a89", "warmup_time": -1}, "reshape.Cut.time_cut_timedelta": {"code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2f5c35407cf29255413562a88e6d55964bb5bde8a9a2b83b85ffeeda159ff65", "warmup_time": -1}, "reshape.Cut.time_qcut_datetime": {"code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1dc3bdc55e69333559a3c1bef3536ee399372354e5ac5066f4527f06b76ec6e", "warmup_time": -1}, "reshape.Cut.time_qcut_float": {"code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f6552b34390d4f7651bb7e8b62568bff93c3b4ffe833fdeac4132f0bdeab5cd", "warmup_time": -1}, "reshape.Cut.time_qcut_int": {"code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb973a705e6ceabff795799bb0662b89dc7d0c4b93112b590dd47ebf1b8e10f9", "warmup_time": -1}, "reshape.Cut.time_qcut_timedelta": {"code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e964d42204717ecb025d8aef6961b4166c8bd7b24db8a0ffa0113bb19b990ad1", "warmup_time": -1}, "reshape.Explode.time_explode": {"code": "class Explode:\n    def time_explode(self, n_rows, max_list_length):\n        self.series.explode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Explode:\n    def setup(self, n_rows, max_list_length):\n    \n        data = [np.arange(np.random.randint(max_list_length)) for _ in range(n_rows)]\n        self.series = pd.Series(data)", "min_run_count": 2, "name": "reshape.Explode.time_explode", "number": 0, "param_names": ["n_rows", "max_list_length"], "params": [["100", "1000", "10000"], ["3", "5", "10"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a48f21156402264510a218cb5f5ef960de2a07fd58de8676b2924153c72fa838", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d": {"code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=pd.api.types.CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5fd1985770aa7131dfd607d68a5294b180bfe26fede57a1a6151aa40db06bd1", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d_sparse": {"code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=pd.api.types.CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d_sparse", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "473b3f15805d91e809350a7b66ac56f3eb5c9a3ee10ee8341d7bf7bf249fe557", "warmup_time": -1}, "reshape.Melt.time_melt_dataframe": {"code": "class Melt:\n    def time_melt_dataframe(self):\n        melt(self.df, id_vars=[\"id1\", \"id2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 3), columns=[\"A\", \"B\", \"C\"])\n        self.df[\"id1\"] = np.random.randint(0, 10, 10000)\n        self.df[\"id2\"] = np.random.randint(100, 1000, 10000)", "min_run_count": 2, "name": "reshape.Melt.time_melt_dataframe", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e0aac4302e06f7a040b4275da61ce9574141fcef7f38960ebf3bc8ef1a05cbe", "warmup_time": -1}, "reshape.Pivot.time_reshape_pivot_time_series": {"code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot(\"date\", \"variable\", \"value\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        data = {\n            \"value\": np.random.randn(N * 50),\n            \"variable\": np.arange(50).repeat(N),\n            \"date\": np.tile(index.values, 50),\n        }\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "reshape.Pivot.time_reshape_pivot_time_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b138b7132956e60c7816e2503c74c204ae14c930a44007c048e9316edbc6fe27", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table": {"code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "691b4a78c4301b2145d3190fcc4b38d84b7a74762b08d16e7d746365233345ff", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_agg": {"code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(\n            index=\"key1\", columns=[\"key2\", \"key3\"], aggfunc=[\"sum\", \"mean\"]\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_agg", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff643f4e3517c1e543ab62c4166d7ed80b390c168a9f355e368d57a6e011e519", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical": {"code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(\n            index=\"col1\", values=\"col3\", columns=\"col2\", aggfunc=np.sum, fill_value=0\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd8fc37bc61253ba8b69b5a10d126dedc1b2f6f4d08514ce5ccbbfb4eb6ef2e3", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical_observed": {"code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(\n            index=\"col1\",\n            values=\"col3\",\n            columns=\"col2\",\n            aggfunc=np.sum,\n            fill_value=0,\n            observed=True,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical_observed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7ffa30cd099819c7ad2104205c0b878a39af9d7dd936029a1156bef1bd223cd", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins": {"code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7317127ece84018006dace4f982399007da7567321d7234441dda0b6835770c9", "warmup_time": -1}, "reshape.SimpleReshape.time_stack": {"code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_stack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14ed9d449ab0c21febf952d6ba4f49a2b47ecf2668c736dc5ab80dc32826c997", "warmup_time": -1}, "reshape.SimpleReshape.time_unstack": {"code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_unstack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dbf93cb1a241b4e6717154b3056e364dc2c520e2dfe51ca842ce83cfd28e3344", "warmup_time": -1}, "reshape.SparseIndex.time_unstack": {"code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame(\n            {\n                \"A\": np.random.randint(50, size=NUM_ROWS),\n                \"B\": np.random.randint(50, size=NUM_ROWS),\n                \"C\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"D\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"E\": np.random.randint(10, size=NUM_ROWS),\n                \"F\": np.random.randn(NUM_ROWS),\n            }\n        )\n        self.df = self.df.set_index([\"A\", \"B\", \"C\", \"D\", \"E\"])", "min_run_count": 2, "name": "reshape.SparseIndex.time_unstack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "abea94ab71de82f53dcb238f1672933e7a4e96827762b3d8b7002704073a2516", "warmup_time": -1}, "reshape.Unstack.time_full_product": {"code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n        self.df = DataFrame(values, index, columns)\n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_full_product", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5be77f4a6ac3274a8c4cb83fac685f4af66aa560d85843f3877f29977a1d685b", "warmup_time": -1}, "reshape.Unstack.time_without_last_row": {"code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n        self.df = DataFrame(values, index, columns)\n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_without_last_row", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "789ac1a30b7a41dc5b6b156e8f94b97f117780dfa8b70ef3585d21d359912716", "warmup_time": -1}, "reshape.WideToLong.time_wide_to_long_big": {"code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i=\"id\", j=\"year\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list(\"ABCD\")\n        yrvars = [l + str(num) for l, num in product(self.letters, range(1, nyrs + 1))]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)), columns=columns)\n        self.df[\"id\"] = self.df.index", "min_run_count": 2, "name": "reshape.WideToLong.time_wide_to_long_big", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0dfccfb326171286278a603775aadbf9a1ffcf6136abd6a7840b322164a49ff", "warmup_time": -1}, "rolling.Apply.time_rolling": {"code": "class Apply:\n    def time_rolling(self, constructor, window, dtype, function, raw):\n        self.roll.apply(function, raw=raw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, constructor, window, dtype, function, raw):\n        N = 10 ** 3\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Apply.time_rolling", "number": 0, "param_names": ["constructor", "window", "dtype", "function", "raw"], "params": [["'DataFrame'", "'Series'"], ["3", "300"], ["'int'", "'float'"], ["<built-in function sum>", "<function sum>", "<function Apply.<lambda>>"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b90b7402f3e82bc2da5a470aee1a54978e96b0017b0ed5012b190cc44119e7f", "warmup_time": -1}, "rolling.EWMMethods.time_ewm": {"code": "class EWMMethods:\n    def time_ewm(self, constructor, window, dtype, method):\n        getattr(self.ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.ewm = getattr(pd, constructor)(arr).ewm(halflife=window)", "min_run_count": 2, "name": "rolling.EWMMethods.time_ewm", "number": 0, "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'mean'", "'std'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d2d0fff3d0bcea62c9c00d332188a5e98cf3aee68c52c20f6299698dd72e1052", "warmup_time": -1}, "rolling.ExpandingMethods.time_expanding": {"code": "class ExpandingMethods:\n    def time_expanding(self, constructor, dtype, method):\n        getattr(self.expanding, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ExpandingMethods:\n    def setup(self, constructor, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.expanding = getattr(pd, constructor)(arr).expanding()", "min_run_count": 2, "name": "rolling.ExpandingMethods.time_expanding", "number": 0, "param_names": ["contructor", "window", "dtype"], "params": [["'DataFrame'", "'Series'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d0bbbbcec297cef32fe95719a3135c55c9199a30bd81f4e0806f8c54649870c", "warmup_time": -1}, "rolling.Methods.peakmem_rolling": {"code": "class Methods:\n    def peakmem_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "name": "rolling.Methods.peakmem_rolling", "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "7e2a3131a7ff5bb7c9dd1bd4f4a4c8d40a6b414a04a147f2dc4884966833d72e"}, "rolling.Methods.time_rolling": {"code": "class Methods:\n    def time_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Methods.time_rolling", "number": 0, "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f43b1b585aa54e5555fc6e79ecbb5ef96b4bba1ce61852f9fc9b193061d1fe3", "warmup_time": -1}, "rolling.Pairwise.time_pairwise": {"code": "class Pairwise:\n    def time_pairwise(self, window, method, pairwise):\n        if window is None:\n            r = self.df.expanding()\n        else:\n            r = self.df.rolling(window=window)\n        getattr(r, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, window, method, pairwise):\n        N = 10 ** 4\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)", "min_run_count": 2, "name": "rolling.Pairwise.time_pairwise", "number": 0, "param_names": ["window", "method", "pairwise"], "params": [["10", "1000", "None"], ["'corr'", "'cov'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bc3a74a3426fcf4ddf5adacee721b3eceab14f6b598d4e108da17536ca805704", "warmup_time": -1}, "rolling.PeakMemFixed.peakmem_fixed": {"code": "class PeakMemFixed:\n    def peakmem_fixed(self):\n        # GH 25926\n        # This is to detect memory leaks in rolling operations.\n        # To save time this is only ran on one method.\n        # 6000 iterations is enough for most types of leaks to be detected\n        for x in range(6000):\n            self.roll.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixed:\n    def setup(self):\n        N = 10\n        arr = 100 * np.random.random(N)\n        self.roll = pd.Series(arr).rolling(10)", "name": "rolling.PeakMemFixed.peakmem_fixed", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "77ce1c06e460c88101541ae777e23badf244aa97c5ec3ac3b20b71aca6c82186"}, "rolling.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile, interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10 ** 5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Quantile.time_quantile", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "param5"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93517902464869edfede633c9a02e9636970a16a231d67f2c556504d5154757d", "warmup_time": -1}, "rolling.VariableWindowMethods.peakmem_rolling": {"code": "class Methods:\n    def peakmem_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.roll = getattr(pd, constructor)(arr, index=index).rolling(window)", "name": "rolling.VariableWindowMethods.peakmem_rolling", "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "6648052c9124b3245a59675896dbce54c40cf38c7b447ab3ebea21369726f38d"}, "rolling.VariableWindowMethods.time_rolling": {"code": "class Methods:\n    def time_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.roll = getattr(pd, constructor)(arr, index=index).rolling(window)", "min_run_count": 2, "name": "rolling.VariableWindowMethods.time_rolling", "number": 0, "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1fa563778646daff4289cf37153612f3118d5b0bd1d5cb749eba2921fab9cd7a", "warmup_time": -1}, "series_methods.All.time_all": {"code": "class All:\n    def time_all(self, N, case):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case):\n        val = case != \"fast\"\n        self.s = Series([val] * N)", "min_run_count": 2, "name": "series_methods.All.time_all", "number": 0, "param_names": ["N", "case"], "params": [["1000", "1000000"], ["'fast'", "'slow'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38d6eaf802692bd858841274c6867cdd0b231b1989e36d1bfc86dea80310ffa0", "warmup_time": -1}, "series_methods.Any.time_any": {"code": "class Any:\n    def time_any(self, N, case):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case):\n        val = case == \"fast\"\n        self.s = Series([val] * N)", "min_run_count": 2, "name": "series_methods.Any.time_any", "number": 0, "param_names": ["N", "case"], "params": [["1000", "1000000"], ["'fast'", "'slow'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "906dda919f041fa914f8d643c360623a3d812bff7a855b20c379dc92db9980c6", "warmup_time": -1}, "series_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))", "min_run_count": 2, "name": "series_methods.Clip.time_clip", "number": 0, "param_names": ["n"], "params": [["50", "1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccfa17d1178249cacc78c3dfa6dbb3851850815c5d14df41a39789ff6adfea2b", "warmup_time": -1}, "series_methods.Dir.time_dir_strings": {"code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=tm.makeStringIndex(10000))", "min_run_count": 2, "name": "series_methods.Dir.time_dir_strings", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e116c6dea26d05ccd39e54ddeab3096a69ba2e18e7daaa811e0cb3114cf2e9b6", "warmup_time": -1}, "series_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10 ** 6\n        data = {\n            \"int\": np.random.randint(1, 10, N),\n            \"datetime\": date_range(\"2000-01-01\", freq=\"S\", periods=N),\n        }\n        self.s = Series(data[dtype])\n        if dtype == \"datetime\":\n            self.s[np.random.randint(1, N, 100)] = NaT", "min_run_count": 2, "name": "series_methods.Dropna.time_dropna", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e001ffd02246487fd23ba2e497935ee748e42bae5b74235f37364d25db2bee84", "warmup_time": -1}, "series_methods.IsIn.time_isin": {"code": "class IsIn:\n    def time_isin(self, dtypes):\n        self.s.isin(self.values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsIn:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(1, 10, 100000)).astype(dtype)\n        self.values = [1, 2]", "min_run_count": 2, "name": "series_methods.IsIn.time_isin", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b3d9cc6d75609adf9a495651078bae70dba81ee46f78f04ad04375e508a17bb7", "warmup_time": -1}, "series_methods.IsInFloat64.time_isin_few_different": {"code": "class IsInFloat64:\n    def time_isin_few_different(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.few_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10 ** 6, dtype=np.float64)\n        self.few_different_values = np.zeros(10 ** 7, dtype=np.float64)\n        self.only_nans_values = np.full(10 ** 7, np.nan, dtype=np.float64)", "min_run_count": 2, "name": "series_methods.IsInFloat64.time_isin_few_different", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82eb8992ae30fa6f8babf46c00b1b150f171a77b4d076a2f701ed6e15c9d4dec", "warmup_time": -1}, "series_methods.IsInFloat64.time_isin_many_different": {"code": "class IsInFloat64:\n    def time_isin_many_different(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.many_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10 ** 6, dtype=np.float64)\n        self.few_different_values = np.zeros(10 ** 7, dtype=np.float64)\n        self.only_nans_values = np.full(10 ** 7, np.nan, dtype=np.float64)", "min_run_count": 2, "name": "series_methods.IsInFloat64.time_isin_many_different", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eef8c79e3c8679df328c8a5a3e83894f608a4d91e7d45aaabdf3dc45825df03c", "warmup_time": -1}, "series_methods.IsInFloat64.time_isin_nan_values": {"code": "class IsInFloat64:\n    def time_isin_nan_values(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.few_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10 ** 6, dtype=np.float64)\n        self.few_different_values = np.zeros(10 ** 7, dtype=np.float64)\n        self.only_nans_values = np.full(10 ** 7, np.nan, dtype=np.float64)", "min_run_count": 2, "name": "series_methods.IsInFloat64.time_isin_nan_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eacab46bb2e530fd978af5391037eff8e2d37e771f55fe96b33651f02d3910db", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_long_series_long_values": {"code": "class IsInForObjects:\n    def time_isin_long_series_long_values(self):\n        # no dominating part\n        self.s_long.isin(self.vals_long)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_long_series_long_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "716d352656a26f8fd89bdc418cfdca0db41dc73a146b55a6953b02711fff80c5", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_long_series_long_values_floats": {"code": "class IsInForObjects:\n    def time_isin_long_series_long_values_floats(self):\n        # no dominating part\n        self.s_long_floats.isin(self.vals_long_floats)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_long_series_long_values_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8ea5b0178a9aa92c34c0e57f182a360368021806f0e8fc908ec495b73f232fd7", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_long_series_short_values": {"code": "class IsInForObjects:\n    def time_isin_long_series_short_values(self):\n        # running time dominated by look-up\n        self.s_long.isin(self.vals_short)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_long_series_short_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a515bcda7dfd31fbeb0c2f9daf5f348f084891141aaf82a3b084c8216dcefb", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_nans": {"code": "class IsInForObjects:\n    def time_isin_nans(self):\n        # if nan-objects are different objects,\n        # this has the potential to trigger O(n^2) running time\n        self.s_nans.isin(self.vals_nans)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_nans", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35b4bd0ed91a3601da21eb3db468d1a954529d7cecb2fa9ee2512747ce2042d9", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_short_series_long_values": {"code": "class IsInForObjects:\n    def time_isin_short_series_long_values(self):\n        # running time dominated by the preprocessing\n        self.s_short.isin(self.vals_long)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_short_series_long_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d3500cfdc7573eca3ab24321537f314c83ea2e54bb41d149319961cf4e2c9624", "warmup_time": -1}, "series_methods.Map.time_map": {"code": "class Map:\n    def time_map(self, mapper, *args, **kwargs):\n        self.s.map(self.map_data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == \"Series\":\n            self.map_data = map_data\n        elif mapper == \"dict\":\n            self.map_data = map_data.to_dict()\n        elif mapper == \"lambda\":\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Map.time_map", "number": 0, "param_names": ["m", "a"], "params": [["'dict'", "'Series'", "'lambda'"], ["'object'", "'category'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8231ec926c8677b7c40a05a21f46762744e6cb8aade12af6e7eea5b58d5f997d", "warmup_time": -1}, "series_methods.NSort.time_nlargest": {"code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nlargest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "253c5ac019c9236c18146b346c88bc19e56f04eb4c5d86ec0da4cd51188b900a", "warmup_time": -1}, "series_methods.NSort.time_nsmallest": {"code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nsmallest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91f7a9783802ebb8d4430865643ddc60d047d6480337c2525bf11ce778093519", "warmup_time": -1}, "series_methods.NanOps.time_func": {"code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        self.s = Series([1] * N, dtype=dtype)\n        self.func = getattr(self.s, func)", "min_run_count": 2, "name": "series_methods.NanOps.time_func", "number": 0, "param_names": ["func", "N", "dtype"], "params": [["'var'", "'mean'", "'median'", "'max'", "'min'", "'sum'", "'std'", "'sem'", "'argmax'", "'skew'", "'kurt'", "'prod'"], ["1000", "1000000"], ["'int8'", "'int32'", "'int64'", "'float64'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41743d399f9f3a98d72e1e375ec978c9fdb05b5710e2e89bf68122cf86350c1c", "warmup_time": -1}, "series_methods.SearchSorted.time_searchsorted": {"code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = \"2\" if dtype == \"str\" else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10 ** 5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)", "min_run_count": 2, "name": "series_methods.SearchSorted.time_searchsorted", "number": 0, "param_names": ["dtype"], "params": [["'int8'", "'int16'", "'int32'", "'int64'", "'uint8'", "'uint16'", "'uint32'", "'uint64'", "'float16'", "'float32'", "'float64'", "'str'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "150c5461a0b3c6fbd3b961cc5ee4bbc9aa478a9e2dcd8bbaf18d5c40a0f71cf1", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor": {"code": "class SeriesConstructor:\n    def time_constructor(self, data):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self, data):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        dict_data = dict(zip(self.idx, range(len(self.idx))))\n        self.data = None if data is None else dict_data", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor", "number": 0, "param_names": ["data"], "params": [["None", "'dict'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff115ed9fb7934d909610ba5283268dd462655d2e463cf0030bc64f6dd3a4cf5", "warmup_time": -1}, "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {"code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, \"a\", None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=int(1e6)))", "min_run_count": 2, "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d5a098eedf58b5a068b69ce1ef386caea4fb22d9a3592d09f33f09e8523157e0", "warmup_time": -1}, "series_methods.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000)).astype(dtype)", "min_run_count": 2, "name": "series_methods.ValueCounts.time_value_counts", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96468feb76190801a31466445c331b28d4e65aba6b0197a5009ee4474cb02953", "warmup_time": -1}, "sparse.Arithmetic.time_add": {"code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_add", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee1c5bad63c3ec6b7f85a0070f71557a8687bfda1ee11013ccd245be2a12f489", "warmup_time": -1}, "sparse.Arithmetic.time_divide": {"code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_divide", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d13aaf4bdcbd713e3c6bacd5b3c7d07d1fc14ee8a5fffdc93fcbd72118989e5", "warmup_time": -1}, "sparse.Arithmetic.time_intersect": {"code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_intersect", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31f113dc64c8d9d5a4d2658467f1fb5a2b3a9960115a69a4763510ed6dc9bb27", "warmup_time": -1}, "sparse.Arithmetic.time_make_union": {"code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_make_union", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4cdd0234d09c55379754d56e3587295ae839c1a8cdd9d0a7f2919bdbc97da5c4", "warmup_time": -1}, "sparse.ArithmeticBlock.time_addition": {"code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_addition", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8fc2841a4836d83f5ffab0e2586b83c8142385ceb1dac830a4f114ab296bfd8", "warmup_time": -1}, "sparse.ArithmeticBlock.time_division": {"code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_division", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bcd9a60e2b8c7042e9296a23c48a02547653c73d4d508bec655414410dc34437", "warmup_time": -1}, "sparse.ArithmeticBlock.time_intersect": {"code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_intersect", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fffcc616a09966bd1697b61a99f21c1fdfff9b0818ea302a69974d536d5031b5", "warmup_time": -1}, "sparse.ArithmeticBlock.time_make_union": {"code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_make_union", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "762a15c3f7d93d6bec720560480677ac0a8ce70e3f59d09d9ce8383133f6333a", "warmup_time": -1}, "sparse.FromCoo.time_sparse_series_from_coo": {"code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        pd.Series.sparse.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(\n            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\n        )", "min_run_count": 2, "name": "sparse.FromCoo.time_sparse_series_from_coo", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b731b3d1c939f96bc19e22f07bb9cb8ab8cc54b2dc2892d6aec275b693a58ebd", "warmup_time": -1}, "sparse.SparseArrayConstructor.time_sparse_array": {"code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10 ** 6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)", "min_run_count": 2, "name": "sparse.SparseArrayConstructor.time_sparse_array", "number": 0, "param_names": ["dense_proportion", "fill_value", "dtype"], "params": [["0.1", "0.01"], ["0", "nan"], ["<class 'numpy.int64'>", "<class 'numpy.float64'>", "<class 'object'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2509acc32bc8fefde58ed633987b18f22627f990fd781f9ad245536ea5397620", "warmup_time": -1}, "sparse.SparseDataFrameConstructor.time_from_scipy": {"code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        pd.DataFrame.sparse.from_spmatrix(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.arr = np.arange(N)\n        self.sparse = scipy.sparse.rand(N, N, 0.005)", "min_run_count": 2, "name": "sparse.SparseDataFrameConstructor.time_from_scipy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "26b43a51bac9f8ea973bd53f4def2fee06f4d3b905d162ea7e2481f58863e80d", "warmup_time": -1}, "sparse.SparseSeriesToFrame.time_series_to_frame": {"code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        pd.DataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = pd.Series(pd.SparseArray(data), index=idx)", "min_run_count": 2, "name": "sparse.SparseSeriesToFrame.time_series_to_frame", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0214aee86326199159d35d984a90c19c358cc968cb480fe2aa55cde51d4ac9b7", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo": {"code": "class ToCoo:\n    def time_sparse_series_to_coo(self):\n        self.ss.sparse.to_coo(row_levels=[0, 1], column_levels=[2, 3], sort_labels=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n        s.index = MultiIndex.from_product([range(10)] * 4)\n        self.ss = s.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9c024e8593fcde09fe6638b47a07815366f112e8c37b2ab4b8ea4d614180d3b", "warmup_time": -1}, "stat_ops.Correlation.peakmem_corr_wide": {"code": "class Correlation:\n    def peakmem_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "name": "stat_ops.Correlation.peakmem_corr_wide", "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "45efa930f57f1ff23d405257fb92f3b4dd101d102aa69c68af346c612ac9d063"}, "stat_ops.Correlation.time_corr": {"code": "class Correlation:\n    def time_corr(self, method):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f34b96d53296f1523e16041e7978c2a8144aa3d3ecc34c0dd5f6e19af29a0248", "warmup_time": -1}, "stat_ops.Correlation.time_corr_series": {"code": "class Correlation:\n    def time_corr_series(self, method):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_series", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "85a6b1b9a301f24940afca4034ee700fbfb22f6cce3fed0ce6cf0cc5919b8b37", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide": {"code": "class Correlation:\n    def time_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "800aa911864d180147d8efe5e69ce644af68c1ee80de8c0b039b09423ae98712", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide_nans": {"code": "class Correlation:\n    def time_corr_wide_nans(self, method):\n        self.df_wide_nans.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide_nans", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e3bca5673084410141a607d4ef601a73fdcb72c2883025592beca8c001a63cc", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_cols": {"code": "class Correlation:\n    def time_corrwith_cols(self, method):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_cols", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "84c144f68db4226f2b4d53128fb4f11bed221633f1386e748e8168bdbb506d5a", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_rows": {"code": "class Correlation:\n    def time_corrwith_rows(self, method):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_rows", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "628335416902a2148763bc646d11fccd0aeb22676a261629959b7dd77581e948", "warmup_time": -1}, "stat_ops.Covariance.time_cov_series": {"code": "class Covariance:\n    def time_cov_series(self):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self):\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))", "min_run_count": 2, "name": "stat_ops.Covariance.time_cov_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5bee701b9034da298c4529077e5841381cbcfd01ee16f2f21ee2a354fa08c56", "warmup_time": -1}, "stat_ops.FrameMultiIndexOps.time_op": {"code": "class FrameMultiIndexOps:\n    def time_op(self, level, op):\n        self.df_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameMultiIndexOps.time_op", "number": 0, "param_names": ["level", "op"], "params": [["0", "1", "[0, 1]"], ["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f96021245703fb9bd8ae05edb7da231d655a3a803d13d8149e59e3eda3350bf4", "warmup_time": -1}, "stat_ops.FrameOps.time_op": {"code": "class FrameOps:\n    def time_op(self, op, dtype, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis):\n        df = pd.DataFrame(np.random.randn(100000, 4)).astype(dtype)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameOps.time_op", "number": 0, "param_names": ["op", "dtype", "axis"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c70f29e8f9bf574e420156e7871750ed7c071dc9452e0984589cddcc7ea9f476", "warmup_time": -1}, "stat_ops.Rank.time_average_old": {"code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10 ** 5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_average_old", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "555dc37265f9c9faaac31b724521056e9364da194707c9152dd2093e8d9880e5", "warmup_time": -1}, "stat_ops.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10 ** 5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_rank", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c474f586dd86a024a5e666f12d15a2cf14cac947a2e70c583be059a583faa6f", "warmup_time": -1}, "stat_ops.SeriesMultiIndexOps.time_op": {"code": "class SeriesMultiIndexOps:\n    def time_op(self, level, op):\n        self.s_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesMultiIndexOps.time_op", "number": 0, "param_names": ["level", "op"], "params": [["0", "1", "[0, 1]"], ["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6fc4f693a9b8e298a5ddeb7e4cec6220a7d8e6570e4060dfd64ee3b9c33b4cf0", "warmup_time": -1}, "stat_ops.SeriesOps.time_op": {"code": "class SeriesOps:\n    def time_op(self, op, dtype):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesOps.time_op", "number": 0, "param_names": ["op", "dtype"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "007247f4af1d54279e79e2cc634ea46b837ded8428815e85092c144682bba58c", "warmup_time": -1}, "strings.Cat.time_cat": {"code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10 ** 5\n        mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])\n        self.s = Series(tm.makeStringIndex(N)).where(mask_gen())\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame(\n                {i: tm.makeStringIndex(N).where(mask_gen()) for i in range(other_cols)}\n            )", "min_run_count": 2, "name": "strings.Cat.time_cat", "number": 0, "param_names": ["other_cols", "sep", "na_rep", "na_frac"], "params": [["0", "3"], ["None", "','"], ["None", "'-'"], ["0.0", "0.001", "0.15"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8eb58a182e7e599789eb81b837dc2769e0d6f0cb6088f85682e60acb166ccac0", "warmup_time": -1}, "strings.Contains.time_contains": {"code": "class Contains:\n    def time_contains(self, regex):\n        self.s.str.contains(\"A\", regex=regex)\n\n    def setup(self, regex):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Contains.time_contains", "number": 0, "param_names": ["regex"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "028b27170ec82a18eb9728a07bd40e1987e56b6f9f1c7c5c69ab59f534b4b779", "warmup_time": -1}, "strings.Dummies.time_get_dummies": {"code": "class Dummies:\n    def time_get_dummies(self):\n        self.s.str.get_dummies(\"|\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5)).str.join(\"|\")", "min_run_count": 2, "name": "strings.Dummies.time_get_dummies", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b7b9d5cd10b2065fbe01d58d676387e948f905052801ab7c630e029ba4194ca", "warmup_time": -1}, "strings.Encode.time_encode_decode": {"code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode(\"utf-8\").str.decode(\"utf-8\")\n\n    def setup(self):\n        self.ser = Series(tm.makeUnicodeIndex())", "min_run_count": 2, "name": "strings.Encode.time_encode_decode", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7991afc08fb85f2e7a8a10a61fdf3f06df4a2d94f48fe9cd517f60f1b2a56a99", "warmup_time": -1}, "strings.Methods.time_center": {"code": "class Methods:\n    def time_center(self):\n        self.s.str.center(100)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_center", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b9344814f4085d71b0ce43968a5e47165ca10b26397dfa73ef4ef99962cc96f", "warmup_time": -1}, "strings.Methods.time_count": {"code": "class Methods:\n    def time_count(self):\n        self.s.str.count(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_count", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f41bf14cace9d72005495af892bf2de9b1b447e2c361721a5a8d9e63b21ec205", "warmup_time": -1}, "strings.Methods.time_endswith": {"code": "class Methods:\n    def time_endswith(self):\n        self.s.str.endswith(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_endswith", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cda6473bee3904de78639be9a0717d017e7701476b8602070d397dddb099dd03", "warmup_time": -1}, "strings.Methods.time_extract": {"code": "class Methods:\n    def time_extract(self):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A(\\\\w*)\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_extract", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "283030056b4364264e8742ea6493214a937c29d387c2242b76d7bc42dfad925b", "warmup_time": -1}, "strings.Methods.time_find": {"code": "class Methods:\n    def time_find(self):\n        self.s.str.find(\"[A-Z]+\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_find", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2235fa3da76fd2686c98e90bb67680381f0d39e90b033ac74719aa29a429bf3", "warmup_time": -1}, "strings.Methods.time_findall": {"code": "class Methods:\n    def time_findall(self):\n        self.s.str.findall(\"[A-Z]+\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_findall", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "260c0d850c2907bcfcd75973e4f8ab7611772e62bd098e2051ee035d7920f803", "warmup_time": -1}, "strings.Methods.time_get": {"code": "class Methods:\n    def time_get(self):\n        self.s.str.get(0)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_get", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b79468d6095596e0af392d83d82f6db768a26102d406a25e94d38ccee27e84ce", "warmup_time": -1}, "strings.Methods.time_join": {"code": "class Methods:\n    def time_join(self):\n        self.s.str.join(\" \")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_join", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "396b6465ded68c24f0fe1f50cfd4b08deaf4d5cee0a0053c57c51bf73cf9b1f0", "warmup_time": -1}, "strings.Methods.time_len": {"code": "class Methods:\n    def time_len(self):\n        self.s.str.len()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_len", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "392723c6a707b1f5d8190105ba0eb4a54979ab46e92d845c87905699c28e0660", "warmup_time": -1}, "strings.Methods.time_lower": {"code": "class Methods:\n    def time_lower(self):\n        self.s.str.lower()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_lower", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ecd8f9c72774a7eeb63eafcf18290d582ea896cdd935fd9647c81284b4f1b750", "warmup_time": -1}, "strings.Methods.time_lstrip": {"code": "class Methods:\n    def time_lstrip(self):\n        self.s.str.lstrip(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_lstrip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1253d4705d239e45730759a958ef43b8b2ab8019f68e970c4e6d86fc357d588", "warmup_time": -1}, "strings.Methods.time_match": {"code": "class Methods:\n    def time_match(self):\n        self.s.str.match(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_match", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5c2377eb554952a2f53ee91707a3bce30bd2a8dd7061fe8f25b8aed0aceea2eb", "warmup_time": -1}, "strings.Methods.time_normalize": {"code": "class Methods:\n    def time_normalize(self):\n        self.s.str.normalize(\"NFC\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_normalize", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31f6520fe9542916dec0ccc42be8b80e87c77ce47fe03a77095a7b06230c1436", "warmup_time": -1}, "strings.Methods.time_pad": {"code": "class Methods:\n    def time_pad(self):\n        self.s.str.pad(100, side=\"both\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_pad", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "947cea1875415b501f0aacba8a00a282695f12ae03b161620558086efdf5b2ae", "warmup_time": -1}, "strings.Methods.time_partition": {"code": "class Methods:\n    def time_partition(self):\n        self.s.str.partition(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_partition", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16a3b89127129f923443b83be69382727529da1accbbac415ac78f2d264a4b18", "warmup_time": -1}, "strings.Methods.time_replace": {"code": "class Methods:\n    def time_replace(self):\n        self.s.str.replace(\"A\", \"\\x01\\x01\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_replace", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1fe400c54c0e1b95db00aea7500145a177e72c8eba62c587f3198eb0382377b", "warmup_time": -1}, "strings.Methods.time_rfind": {"code": "class Methods:\n    def time_rfind(self):\n        self.s.str.rfind(\"[A-Z]+\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_rfind", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6982452cee3b3b8c0351988fa787130dfe84552f61ddf360a3cc0cf62fc18e7a", "warmup_time": -1}, "strings.Methods.time_rpartition": {"code": "class Methods:\n    def time_rpartition(self):\n        self.s.str.rpartition(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_rpartition", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "be3d1177d8ea6a97d2bb3a6796adf66fecc870bfa7abd24d22586a465160dd22", "warmup_time": -1}, "strings.Methods.time_rstrip": {"code": "class Methods:\n    def time_rstrip(self):\n        self.s.str.rstrip(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_rstrip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6d714119dd3b8d0b5d06c6e3b55c1394ef058a112f96aa228a3b0085e8c36497", "warmup_time": -1}, "strings.Methods.time_slice": {"code": "class Methods:\n    def time_slice(self):\n        self.s.str.slice(5, 15, 2)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_slice", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e515a39e259f5624dc88a4caecb3e00b461b1b5b2e9dec6333ad29443fad1c9d", "warmup_time": -1}, "strings.Methods.time_startswith": {"code": "class Methods:\n    def time_startswith(self):\n        self.s.str.startswith(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_startswith", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d94823bfbe228273ba233895e1fd15298da8026705ec53a8b311b192e3d17fcd", "warmup_time": -1}, "strings.Methods.time_strip": {"code": "class Methods:\n    def time_strip(self):\n        self.s.str.strip(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_strip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91a6d36e7561f03c424f5462508959860577e2d21143c1acb0743666ecd14831", "warmup_time": -1}, "strings.Methods.time_title": {"code": "class Methods:\n    def time_title(self):\n        self.s.str.title()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_title", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e9c59a363498907c5060c908db9f450902bec4a559b34e0c05282933cbbf8439", "warmup_time": -1}, "strings.Methods.time_translate": {"code": "class Methods:\n    def time_translate(self):\n        self.s.str.translate({\"A\": \"\\x01\\x01\"})\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_translate", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0193e7e21294656461363cdc325658411dfe6448f0aeaf02e6389c07d1a3f0c8", "warmup_time": -1}, "strings.Methods.time_upper": {"code": "class Methods:\n    def time_upper(self):\n        self.s.str.upper()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_upper", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e11f12067dcb71a1bf8eecbe75ce7398192559ec2acaf59f45cb9ac8910cc28", "warmup_time": -1}, "strings.Methods.time_wrap": {"code": "class Methods:\n    def time_wrap(self):\n        self.s.str.wrap(10)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_wrap", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c15e2aa54f358c2cd9c6b840091c43512b88b86faadf39a6eccddbfddb76af31", "warmup_time": -1}, "strings.Methods.time_zfill": {"code": "class Methods:\n    def time_zfill(self):\n        self.s.str.zfill(10)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_zfill", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9a026c930b7733ea81f88c4178af820b3630d447f883d832cd6bf19f68015b63", "warmup_time": -1}, "strings.Repeat.time_repeat": {"code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10 ** 5\n        self.s = Series(tm.makeStringIndex(N))\n        repeat = {\"int\": 1, \"array\": np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]", "min_run_count": 2, "name": "strings.Repeat.time_repeat", "number": 0, "param_names": ["repeats"], "params": [["'int'", "'array'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1c054ab32273dc4270ccb7ade724c83ebaa9472afd7c7248dc3b28a6167ab3c", "warmup_time": -1}, "strings.Slice.time_vector_slice": {"code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series([\"abcdefg\", np.nan] * 500000)", "min_run_count": 2, "name": "strings.Slice.time_vector_slice", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aaf1ec9c90cc2539c76cae9af1c26b6b5ffb1d0311ec7d6dafe7d228d106ef86", "warmup_time": -1}, "strings.Split.time_rsplit": {"code": "class Split:\n    def time_rsplit(self, expand):\n        self.s.str.rsplit(\"--\", expand=expand)\n\n    def setup(self, expand):\n        self.s = Series(tm.makeStringIndex(10 ** 5)).str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_rsplit", "number": 0, "param_names": ["expand"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e9dd33b3bb35f7877625d8129b7b4abb91190d4bc043df11d8d87258703c708f", "warmup_time": -1}, "strings.Split.time_split": {"code": "class Split:\n    def time_split(self, expand):\n        self.s.str.split(\"--\", expand=expand)\n\n    def setup(self, expand):\n        self.s = Series(tm.makeStringIndex(10 ** 5)).str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_split", "number": 0, "param_names": ["expand"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef325356ef8c7ab3d10891283f59a9f60408fb1586caeb6638c2fbbe1d0b1512", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "timedelta:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56ad9655f66a0485943ce9ca9547af9c97e48f5b12779c60896c3147c5422526", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_days": {"code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_days", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "timedelta:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06c603c515e826893772c4d64fe4de8ff76367d3c422060262604d4917fbec03", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_microseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "timedelta:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6504e61d63ba227783a76d2cab32c1d791b1af813406a8c384fc386ca60b1898", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "timedelta:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1cc39aec7c93cb50ced4bf81ec26506de8bfddaaee6968142c0c018f91e296a", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_seconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "timedelta:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0514e9978f000e47c609125255de6d9536aed804334d426a9222e1347183702d", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_align": {"code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_align", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5833d39497fb06bb05cac21fd9feeebace738d8e1cb626bea9fb0bbd86049ce", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_get_loc": {"code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25e9df433acdb6dcf3c1df99f789a41f9c774fba04d175a24c5b8688dad9a7f3", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_intersection": {"code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_intersection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3f027dc76eb6a9ef0eff1bc06dd59ee562b54fbdb029d2a6a6c4865601424c1", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_series_loc": {"code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_series_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5902b5b4b32fc27d85bee9808b6014b1f9664e7f28f444e498a7d04083c92e05", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_shallow_copy": {"code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e223b83f2fd936b5d339affcfa1ad774949ca2766cc060b98637c34644399c25", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_shape": {"code": "class TimedeltaIndexing:\n    def time_shape(self):\n        self.index.shape\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_shape", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fdba5a1927c7e8b7dd8622a96f481e6db146c64871d845eca8bf885be8daa535", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_union": {"code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_union", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "266034126c423f3e411bf2195dc68cd983b6a181466b383df54ba9341232ad71", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_unique": {"code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_unique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17ea4667001a64a4f9df8c9594ca120a6491a18edd28102cd5712c88535ac416", "warmup_time": -1}, "timedelta.TimedeltaOps.time_add_td_ts": {"code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp(\"2000\")", "min_run_count": 2, "name": "timedelta.TimedeltaOps.time_add_td_ts", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43ee94357697a8810860f1545a7e3611ced939c42a03f72b0000ed8f43d518d3", "warmup_time": -1}, "timedelta.ToTimedelta.time_convert_int": {"code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit=\"s\")\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "timedelta.ToTimedelta.time_convert_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b111092c17bf557721f9ff671019f2f467265db177343fc759a16f916d40d17", "warmup_time": -1}, "timedelta.ToTimedelta.time_convert_string_days": {"code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "timedelta.ToTimedelta.time_convert_string_days", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff81cb43ec547eecd3fcf6162a5f5956b7b937c35667d998cdd6050b29c2f310", "warmup_time": -1}, "timedelta.ToTimedelta.time_convert_string_seconds": {"code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "timedelta.ToTimedelta.time_convert_string_seconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19e7218ecb778f1eb7203410175a1a08ec1e8d38237f4a6f001e5b292c4e98b2", "warmup_time": -1}, "timedelta.ToTimedeltaErrors.time_convert": {"code": "class ToTimedeltaErrors:\n    def time_convert(self, errors):\n        to_timedelta(self.arr, errors=errors)\n\n    def setup(self, errors):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = [f\"{i} days\" for i in ints]\n        self.arr[-1] = \"apple\"", "min_run_count": 2, "name": "timedelta.ToTimedeltaErrors.time_convert", "number": 0, "param_names": ["errors"], "params": [["'coerce'", "'ignore'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "020cbaee888cb83c4c26d33022b0f19054dde290eccdf7fc86a53cc08b0d22bf", "warmup_time": -1}, "timeseries.AsOf.time_asof": {"code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3e2e62f9b0969e4e1da322ca6220cc304d5b6d723264da74d17ab2771bd292c", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan": {"code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "64dbbe4ddbe15ee388df6641ecf1f1e553d6f09647d3b494f59685cc66d3bf2a", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan_single": {"code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95da61afb9ec7dad20266bb55452ec70a8f610a5daf5de5f64a569f182420fb4", "warmup_time": -1}, "timeseries.AsOf.time_asof_single": {"code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "488d983701b8b4cb91d811f97f0b16348da50efbb9b2b34241f51ad91ae7cb36", "warmup_time": -1}, "timeseries.AsOf.time_asof_single_early": {"code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single_early", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "161306e14c591cbfb62f6b2051a4808e8f0227b1d2ff41509badd3e8a254b94d", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e275de6b99ba6a06d82734fc5fd2106ab45939f0c24573c82bf8654eabf6c26f", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_date": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_date", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce5d47c01e0522ef823ea6f24cd928adecdc8bb565b8891588cef7a597864ee5", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c1f37eb07da219478ff957be9a2b8e9f4787d0b77f4ffe37084ee97a4b3e57f", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1536985e526572c8be380754cc46f9adec3c29f4cdcce42cff0c258be53fb396", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2098f4e7f3bcb70aa59d88c184598defc25544ed8779b7d068e83b100f6f8472", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_time": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_time", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30e1748aa1cbd359819193fc2b4fe8cd0ada270200ba94457ae18cdbf8e876a9", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_year": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_year", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3d8d6f02e27018f26b53e7699f9705df922cfcff833d5682bd5bd9632f3ec68", "warmup_time": -1}, "timeseries.DatetimeIndex.time_add_timedelta": {"code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_add_timedelta", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d17561bf07eda75fca5be3f8f3bf9dc93358476c02895a95d6e48fd93965ef9", "warmup_time": -1}, "timeseries.DatetimeIndex.time_get": {"code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_get", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9d49554855cf7f28885dc19d04fc882c3e4756fdbb477c1feabf4e3ef78c5015", "warmup_time": -1}, "timeseries.DatetimeIndex.time_normalize": {"code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_normalize", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f03c3d9595f26105495ee05546299488a878071eb5f099900e9dc7023fb20b36", "warmup_time": -1}, "timeseries.DatetimeIndex.time_timeseries_is_month_start": {"code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eff692fbd7dfa0bf1c39275fc684030a6cb8e0705e9cf82c4dd0252b39d9ec25", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_date": {"code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_date", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f297519483e31ed5ffeee3718013b18bf96f805a4b1a3dfb9063e052ae88c84e", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_pydatetime": {"code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_pydatetime", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "222935f885a442eae007019a4331500f9af43350080b7d1c1faf1eb7ce9186a0", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_time": {"code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_time", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb5e8239bf229fc3e0991f2c86a965f685f81276084df7c017474ac4f3fb581a", "warmup_time": -1}, "timeseries.DatetimeIndex.time_unique": {"code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_unique", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9ccc40ce3b46b242274e3e61dce50e09bf5ce1b1131e1785f7945a12aedd694", "warmup_time": -1}, "timeseries.Factorize.time_factorize": {"code": "class Factorize:\n    def time_factorize(self, tz):\n        self.dti.factorize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, tz):\n        N = 100000\n        self.dti = date_range(\"2011-01-01\", freq=\"H\", periods=N, tz=tz)\n        self.dti = self.dti.repeat(5)", "min_run_count": 2, "name": "timeseries.Factorize.time_factorize", "number": 0, "param_names": ["t"], "params": [["None", "'Asia/Tokyo'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8c89c551371506ca4e800015fe9aa2d0265fcf72fba2b395c4527a706a481952", "warmup_time": -1}, "timeseries.InferFreq.time_infer_freq": {"code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start=\"1/1/1700\", freq=\"D\", periods=10000)\n            self.idx._data._freq = None\n        else:\n            self.idx = date_range(start=\"1/1/1700\", freq=freq, periods=10000)", "min_run_count": 2, "name": "timeseries.InferFreq.time_infer_freq", "number": 0, "param_names": ["freq"], "params": [["None", "'D'", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6fbc0361a4fc83fb79ca1945b0d78ebd4f8b26d58f4d4518f69548287a90bc2e", "warmup_time": -1}, "timeseries.IrregularOps.time_add": {"code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.IrregularOps.time_add", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d6d8ce63eeb7493f26143590195d36210414b95c1f555c9b5520ef4ce40f8ee7", "warmup_time": -1}, "timeseries.Iteration.time_iter": {"code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10 ** 6\n        self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0e8467c9fac009ff1cbdf35236714bc49b1491293306de08eb945131b8fccd2", "warmup_time": -1}, "timeseries.Iteration.time_iter_preexit": {"code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10 ** 6\n        self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter_preexit", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f2e2fbcd8984886abca860a868481455463b6c33f33d1317bb1e52f509bae87b", "warmup_time": -1}, "timeseries.Lookup.time_lookup_and_cleanup": {"code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"S\")\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]", "min_run_count": 2, "name": "timeseries.Lookup.time_lookup_and_cleanup", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56affd6bde67bbd710425ecad787b306358e276d222655f214bd88b43295edd4", "warmup_time": -1}, "timeseries.ResampleDataFrame.time_method": {"code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start=\"20130101\", periods=100000, freq=\"50L\")\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample(\"1s\"), method)", "min_run_count": 2, "name": "timeseries.ResampleDataFrame.time_method", "number": 0, "param_names": ["method"], "params": [["'max'", "'mean'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9019269f5444960e4d9df5981d496cd4a6d825381d957e89cb84d8e75782473", "warmup_time": -1}, "timeseries.ResampleDatetetime64.time_resample": {"code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample(\"1S\").last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(\n            start=\"2000-01-01 00:00:00\", end=\"2000-01-01 10:00:00\", freq=\"555000U\"\n        )\n        self.dt_ts = Series(5, rng3, dtype=\"datetime64[ns]\")", "min_run_count": 2, "name": "timeseries.ResampleDatetetime64.time_resample", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5509d40bbee6c6b5cb28537dd6e775fc56f67f793410a856db59e1b02b423ac", "warmup_time": -1}, "timeseries.ResampleSeries.time_resample": {"code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {\n            \"period\": period_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n            \"datetime\": date_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n        }\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)", "min_run_count": 2, "name": "timeseries.ResampleSeries.time_resample", "number": 0, "param_names": ["index", "freq", "method"], "params": [["'period'", "'datetime'"], ["'5min'", "'1D'"], ["'mean'", "'ohlc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6f349cedc62746ed4c61a8d0a8bfba5bd818a04240bb33019f07a96475463ea", "warmup_time": -1}, "timeseries.ResetIndex.time_reest_datetimeindex": {"code": "class ResetIndex:\n    def time_reest_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start=\"1/1/2000\", periods=1000, freq=\"H\", tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)", "min_run_count": 2, "name": "timeseries.ResetIndex.time_reest_datetimeindex", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f52e3b646ab4784ab103bb280656229ba4c12b4d642ec47e6e9e85831cf3a371", "warmup_time": -1}, "timeseries.SortIndex.time_get_slice": {"code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_get_slice", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "481f42cfc27d96e42d9a54190e3e4a7478636830b143acc3c6c9a797ba23f300", "warmup_time": -1}, "timeseries.SortIndex.time_sort_index": {"code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_sort_index", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e5c64e7b4d20d7c75f5c04aaf9d28d96a6cb6d1d67b9c3b210ad187de36ca183", "warmup_time": -1}, "timeseries.TimeDatetimeConverter.time_convert": {"code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")", "min_run_count": 2, "name": "timeseries.TimeDatetimeConverter.time_convert", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec587c19f9fc168d46b31890ca2dd023bbae7678655b0219733c111876aaca8d", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "756b45777a695a791714d2605b1ffe5b02b3d375155f95b355ff4fc8fd8a1646", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_string_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_string_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "833932db64b226a24bb1bbdc650cb211a8447a5f4abcaaa463c2409c2cd98ab9", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_string_dates_and_format": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format=\"%Y-%m-%d\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_string_dates_and_format", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7b013ce695476d226a54205bb6caadf6ecdd8d9e860395d02dd061f3ed12a44", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_string_tzoffset_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_string_tzoffset_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b295204f30ec321c133b4e5cf4cb2c315da2600d007c6ee7bdf6506a05c40d1e", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_unique_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_unique_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71644c77c2b579672d01ad606174b5a665e316952e8089e938a1119df2c0c023", "warmup_time": -1}, "timeseries.ToDatetimeCacheSmallCount.time_unique_date_strings": {"code": "class ToDatetimeCacheSmallCount:\n    def time_unique_date_strings(self, cache, count):\n        to_datetime(self.unique_date_strings, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCacheSmallCount:\n    def setup(self, cache, count):\n        rng = date_range(start=\"1/1/1971\", periods=count)\n        self.unique_date_strings = rng.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "timeseries.ToDatetimeCacheSmallCount.time_unique_date_strings", "number": 0, "param_names": ["cache", "count"], "params": [["True", "False"], ["50", "500", "5000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f1b77b83865e585bd49d343df00f78c5830904e0c5cd5d8519429faedd24be72", "warmup_time": -1}, "timeseries.ToDatetimeFormat.time_exact": {"code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format=\"%d%b%y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * 100000)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")", "min_run_count": 2, "name": "timeseries.ToDatetimeFormat.time_exact", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dfd3bfdf14d17f9ff2e06acb6a2895e0ba8b62e887fafc09ffd413a8124f7aaf", "warmup_time": -1}, "timeseries.ToDatetimeFormat.time_no_exact": {"code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format=\"%d%b%y\", exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * 100000)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")", "min_run_count": 2, "name": "timeseries.ToDatetimeFormat.time_no_exact", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "669e5cd4b69c2990367a28d4a92b6e5cc90e2e8773c011790ec10fb61f055921", "warmup_time": -1}, "timeseries.ToDatetimeFormatQuarters.time_infer_quarter": {"code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series([\"2Q2005\", \"2Q05\", \"2005Q1\", \"05Q1\"] * 10000)", "min_run_count": 2, "name": "timeseries.ToDatetimeFormatQuarters.time_infer_quarter", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38c26091a098dae47d4027da784cbce429b5f53a782889c0e6e5e2683dec01f5", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601": {"code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1531fbcf18768ba85951bf1940c964e1daf2137f700bd1a84dc386b121757563", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_format": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_format", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d63b6ea1aa680dc15677868976dd9c20c3d3e0a7d33493e7e3fb47c4137cfa8c", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_format_no_sep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format=\"%Y%m%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_format_no_sep", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "942846a154981c8007b34307051912ad839df85e7a3b2d892506646dc9555df6", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_nosep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_nosep", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3c9c8969b2d1bd75b976218cdd7719366ef47db3af071f1630dfd8dff3ee3ab0", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_tz_spaceformat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "348cb5b54fdfff434ae18ca802ed7b0978d50861ed28ebeb00cea737c5a1b02c", "warmup_time": -1}, "timeseries.ToDatetimeNONISO8601.time_different_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = int(N / 2)\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "timeseries.ToDatetimeNONISO8601.time_different_offset", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "db6b89c7cc2339fca294294cebf55c60955b86d1804e239dd614207bd0eedb38", "warmup_time": -1}, "timeseries.ToDatetimeNONISO8601.time_same_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = int(N / 2)\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "timeseries.ToDatetimeNONISO8601.time_same_offset", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "530f66b2871f099ca8a01bc892b9240cc7af4de29b76a13703ead4070adab761", "warmup_time": -1}, "timeseries.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {"code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=10000, freq=\"D\")\n        self.stringsD = Series(rng.strftime(\"%Y%m%d\"))", "min_run_count": 2, "name": "timeseries.ToDatetimeYYYYMMDD.time_format_YYYYMMDD", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0231b0750bd151893d2d73a3bf8eaff1e01f54151e5cc7eafa1dd85d3d401394", "warmup_time": -1}, "timeseries.TzLocalize.time_infer_dst": {"code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous=\"infer\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(\n            start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n        )\n        self.index = date_range(start=\"10/29/2000\", end=\"10/29/2000 00:59:59\", freq=\"S\")\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(\n            date_range(start=\"10/29/2000 2:00:00\", end=\"10/29/2000 3:00:00\", freq=\"S\")\n        )", "min_run_count": 2, "name": "timeseries.TzLocalize.time_infer_dst", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "535825674e3168b99ae7eb4f9416ccc0ed0b0e23916aa315064bbfb5c040435f", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add": {"code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfb2ef7f8d94ebf443a43ab768a426b24846a01bcb9e60873cfca5ac9d84acbb", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_10": {"code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "412f51bfc037b5b10f23387d475123e2c8ebd62a69e6a5692a07f7924f5149ac", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_apply": {"code": "class OffestDatetimeArithmetic:\n    def time_apply(self, offset):\n        offset.apply(self.date)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_apply", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "af692257767a29f497ae7d9cc6c0be4b43945e05f84879665f39032250403461", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_apply_np_dt64": {"code": "class OffestDatetimeArithmetic:\n    def time_apply_np_dt64(self, offset):\n        offset.apply(self.dt64)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_apply_np_dt64", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f194bced40cf0d9aa4959b756652f9c4823ddca885b6bcb420be8afa14e70afa", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "775bbe2574e947fdebb23ba6451a8510d68d5dfaf0e0813a6967a39209d770fc", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a5bf6590a5f4e89c95b4b22ecc27ec52e4cb03e8255cef5009879bb71dbc69", "warmup_time": -1}, "tslibs.offsets.OnOffset.time_on_offset": {"code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.is_on_offset(date)\n\n    def setup(self, offset):\n        self.dates = [\n            datetime(2016, m, d)\n            for m in [10, 11, 12]\n            for d in [1, 2, 3, 28, 29, 30, 31]\n            if not (m == 11 and d == 31)\n        ]", "min_run_count": 2, "name": "tslibs.offsets.OnOffset.time_on_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae5cbac53a07afd70222f6a228bac6518d5df75e369f5e8450db66831ba8afa2", "warmup_time": -1}, "tslibs.period.PeriodConstructor.time_period_constructor": {"code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period(\"2012-06-01\", freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "tslibs.period.PeriodConstructor.time_period_constructor", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d98fc24ec3bee7645af5de9f3e7af5e28f028c74e4785bda4ceb36f1d46a671d", "warmup_time": -1}, "tslibs.period.PeriodProperties.time_property": {"code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodProperties.time_property", "number": 0, "param_names": ["freq", "attr"], "params": [["'M'", "'min'"], ["'year'", "'month'", "'day'", "'hour'", "'minute'", "'second'", "'is_leap_year'", "'quarter'", "'qyear'", "'week'", "'daysinmonth'", "'dayofweek'", "'dayofyear'", "'start_time'", "'end_time'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c0fa44f9b9f197537446c79ae6f7ce95ab1d18e2e68b5acb2a96103c097f4c6", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_asfreq": {"code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq(\"A\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_asfreq", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "deedbf5d3c7fd1ba4050791ac771023591ce7ddf98c14082e8627b2b2646cfeb", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_now": {"code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_now", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b3c4792b946da369832c7ae6904edf46919fdca2bf03ad4006e36d728c2816bb", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_to_timestamp": {"code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_to_timestamp", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27afe42121b54cb80919887f7d10be0869044b9c877bf53c7bfcd1f5f622e713", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_components": {"code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(\n            days=1,\n            hours=2,\n            minutes=3,\n            seconds=4,\n            milliseconds=5,\n            microseconds=6,\n            nanoseconds=7,\n        )", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_components", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3bd2910bfa3ff10306ddb8a2fb92253e52ce6ab650da2e7e757af15eb440a50b", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(datetime.timedelta(days=1, seconds=1))", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7998e3eec400317041ad6877a81d629e8889824eca22e9f2f3018c0c44ee4d8c", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_int": {"code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8434314c7e4a58ab4943126d48db7f2c963f479996e722c14bf383967d6ba9d6", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format": {"code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta(\"P4DT12H30M5S\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "308e49a3c2fbdd2bf31e1a961ca75b88fc08885558893bb57cbcafe688be0555", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_missing": {"code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta(\"nat\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_missing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0478c6a24b38a413f3cd712533950835d8b41f9229ae23b78d885c09d90f966", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(np.timedelta64(1, \"ms\"))", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8efcf8c1ffe8c22869ce653e2f1cf14a772d501814f6dbff15a22e8a0ee3a9bb", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_string": {"code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta(\"1 days\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "125f8a610da995d297ac1e4a2be2316efcc5731b0bf168f483c9b803c69f9bd1", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_unit": {"code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit=\"d\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_unit", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b0f61a37e44bf0781fe2bfd9057acb6907fd559c80e907a6f2db0a77c8f6ba51", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_days": {"code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_days", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c", "warmup_time": -1}, "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst": {"code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime.datetime(2016, 3, 27, 1)\n        self.tzinfo = pytz.timezone(\"CET\").localize(dt, is_dst=False).tzinfo\n        self.ts2 = Timestamp(dt)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef706cb28280171e57261ce2883942a74f7a6c273b6d90430445c8be0b8bf471", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromordinal": {"code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromordinal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8558b46ef8e615bdb4e39a24bb46d841af38c3ac7f1dee29558e7836c5f1f325", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromtimestamp": {"code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromtimestamp", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4afd2da54b515083d180740e9f4a4d2fd4d3c965f1d92457517630372009379b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_dateutil": {"code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp(\"2017/08/25 08:16:14 AM\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_dateutil", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9af29b3c5d287db48c44ca54992f7b9d37054ed462830bb660800f2e2728cb2b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp(\"2017-08-25 08:16:14\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b5c96df20a02762fbe8cf5abe5f9ff35f8a5f384ce23cf59767e8568f34c4226", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp(\"2017-08-25 08:16:14-0500\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53dfdd6d97eaa8c526cdb3ce0e52f3712d135dc172c35f2023bbfa807171e1a5", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_now": {"code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp(\"now\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_now", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cad7c0a494ee4805bddda5e122aac265c5c0278fadaf049b32266bc4b464f358", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_today": {"code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp(\"today\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_today", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9b9adaec1ddf1bc239f4d456518430483907973367902c9f55196282e7b6e1f", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_ceil": {"code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_ceil", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1428582cbad6d3d555950451594e390024aad454751ca9d18540ddf7f7548c4a", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_floor": {"code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_floor", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29681cac2448139b28d8817e024d6d3c08bcd7fe4594fb26564ed03e81c94f31", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_normalize": {"code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_normalize", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7688ade61af780f34bdb840481260073c8bfb88a7504a06758c91f033fb951d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_None": {"code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_None", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "395164d585e187bf1f2ecd1f965a26fe6f63a204fb26eb6daf8c2544e7895f5f", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_tz": {"code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=pytz.timezone(\"US/Eastern\"))\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_tz", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4364c2bc5207c0340c1149b8fb230b76c97f7646891613c57bd11cf528e78d77", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_julian_date": {"code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_julian_date", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b986ab53361d72e7f0d0ea59b3584f48d6d6fc4994e87be9157f503231f22e70", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_pydatetime": {"code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_pydatetime", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1db879395196c84d3fd8f358a23b86aaef86f45475d0f83716f8a546e489a627", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_convert": {"code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_convert", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43ec3d5f390c7c62a00c06c942395078df2cc729fd8f92a4b0276815f342896d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_localize": {"code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_localize", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ed9c18cc2666c8a010ac46b26f73181d886d5bad76c5a2e012111741777d94c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofweek": {"code": "class TimestampProperties:\n    def time_dayofweek(self, tz, freq):\n        self.ts.dayofweek\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofweek", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c6daadf9626b1beb421ea24564aa6c857f50b32c4bfdf865a679ff78c075a09c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofyear": {"code": "class TimestampProperties:\n    def time_dayofyear(self, tz, freq):\n        self.ts.dayofyear\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofyear", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1970996700077d3916288f2ebfa66314fd0fa16faa65d298f43d1c452b376c1f", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_days_in_month": {"code": "class TimestampProperties:\n    def time_days_in_month(self, tz, freq):\n        self.ts.days_in_month\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_days_in_month", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f1ec12e96719dcfd857c4d2520d3c197e9c5e623eb69bd481bba8d50a3b56c7c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_freqstr": {"code": "class TimestampProperties:\n    def time_freqstr(self, tz, freq):\n        self.ts.freqstr\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_freqstr", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b7c86fb415025ed9782c86ea08bfa95b66d8c30532a8337935b49a716d37c3b", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_leap_year": {"code": "class TimestampProperties:\n    def time_is_leap_year(self, tz, freq):\n        self.ts.is_leap_year\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_leap_year", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7a94f193c44fde8fc63549fc4515913a4284f65aa3b2cf68e4b099f5e68ecb58", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_end": {"code": "class TimestampProperties:\n    def time_is_month_end(self, tz, freq):\n        self.ts.is_month_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_end", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b5b47e2086d98cadc559128155943e2868f7af254659e927f11302852497f3b8", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_start": {"code": "class TimestampProperties:\n    def time_is_month_start(self, tz, freq):\n        self.ts.is_month_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_start", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9096eeefe2b95da5c24266d715fa7c18a2d5a1ef9e09b034e1231cd6e8295d70", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_end": {"code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz, freq):\n        self.ts.is_quarter_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_end", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82a65562c4cca8e68b3c7f8be34145a2bc1d71a34c4544e528038b5808d6a0c1", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_start": {"code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz, freq):\n        self.ts.is_quarter_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_start", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1088250670cc9f98108690c31465e1f62b79e9ecdad8ebd4fd150e098f5930b7", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_end": {"code": "class TimestampProperties:\n    def time_is_year_end(self, tz, freq):\n        self.ts.is_year_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_end", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e78c5d23cc3ed6005c4779c52acfaca34ed16a1f7d9d100cb88cb153d2e8350f", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_start": {"code": "class TimestampProperties:\n    def time_is_year_start(self, tz, freq):\n        self.ts.is_year_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_start", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c29221e715f65d7b7ad3989a0229500ded6c2ca2d804bfc21943e229df8644ef", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_microsecond": {"code": "class TimestampProperties:\n    def time_microsecond(self, tz, freq):\n        self.ts.microsecond\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_microsecond", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4f3bd00c49a4eceb4fd4a85cf81ad8cc0f4807dfb7c10e06be9feb1790502eda", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_month_name": {"code": "class TimestampProperties:\n    def time_month_name(self, tz, freq):\n        self.ts.month_name()\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_month_name", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2a9cc7b41015b79534db9bdba3b505bbb41874eee513498664e27e4a087424d4", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_quarter": {"code": "class TimestampProperties:\n    def time_quarter(self, tz, freq):\n        self.ts.quarter\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_quarter", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61276b5e2273989bcd7c633cda4e3036d2eee15ac46f9a9ebfc5e306d3657b54", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_tz": {"code": "class TimestampProperties:\n    def time_tz(self, tz, freq):\n        self.ts.tz\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_tz", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5fb6e5c5690352c8be03312a08a681e97bd092c6a523c1d55be5617e7b1ecc65", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_week": {"code": "class TimestampProperties:\n    def time_week(self, tz, freq):\n        self.ts.week\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_week", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2b1baa43468ce7c41c65ca461aa4df21820e31dbec8ca816b6619fb5f66ba801", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_weekday_name": {"code": "class TimestampProperties:\n    def time_weekday_name(self, tz, freq):\n        self.ts.day_name\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_weekday_name", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c26888b4c7574e557df7938a70eee70e8eae1848bfe4a5da7714cf7964dc5e0d", "warmup_time": -1}}, "machines": {"T470": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz", "machine": "T470", "num_cpu": "4", "os": "Linux 5.0.0-20-generic", "ram": "20305904", "version": 1}, "T470-W10": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz", "machine": "T470-W10", "os": "Linux 4.4.0-17134-Microsoft", "ram": "20822880", "version": 1}}, "tags": {"0.3.0": 288, "debian/0.4.0-1": 874, "debian/0.4.1-1": 933, "debian/0.4.3-1": 1084, "debian/0.5.0+git7-gcf32be2-1": 1194, "debian/0.6.1-1": 1632, "debian/0.7.0-1": 2077, "debian/0.7.1+git1-ga2e86c2-1": 2247, "debian/0.7.3-1": 2555, "debian/0.8.0-1": 3432, "debian/0.8.0-2": 3509, "debian/0.8.0_b2+git68-g7240b87-1": 3358, "debian/0.8.0_b2-1": 3280, "debian/0.8.0_rc2+git26-g76c6351-1": 3407, "debian/0.8.1-1": 3572, "v0.10.0": 4834, "v0.10.0b1": 4741, "v0.10.1": 5044, "v0.11.0": 5886, "v0.11.0rc1": 5790, "v0.12.0": 6817, "v0.12.0rc1": 6687, "v0.13.0": 8164, "v0.13.0_ahl1": 8259, "v0.13.0_ahl2": 8352, "v0.13.0rc1": 8008, "v0.13.1": 8705, "v0.14.0": 9753, "v0.14.0rc1": 9657, "v0.14.1": 10180, "v0.15.0": 10893, "v0.15.0rc1": 10833, "v0.15.1": 10996, "v0.15.2": 11228, "v0.15.2pre": 11082, "v0.15pre": 10541, "v0.16.0": 11634, "v0.16.0rc1": 11578, "v0.16.1": 11993, "v0.16.2": 12164, "v0.16.3": 12178, "v0.17.0": 12997, "v0.17.0rc1": 12823, "v0.17.0rc2": 12968, "v0.17.1": 13266, "v0.18.0": 13730, "v0.18.0rc1": 13628, "v0.18.0rc2": 13719, "v0.18.1": 13940, "v0.19.0": 14434, "v0.19.0rc1": 14386, "v0.19.1": 14539, "v0.19.2": 14810, "v0.20.0": 15469, "v0.20.0rc1": 15404, "v0.20.0rc2": 15461, "v0.20.1": 15475, "v0.20.2": 15678, "v0.20.3": 15790, "v0.21.0": 16245, "v0.21.0.dev": 15476, "v0.21.0rc1": 16199, "v0.21.1": 16696, "v0.22.0": 16825, "v0.22.0.dev0": 16246, "v0.23.0": 17693, "v0.23.0.dev0": 16798, "v0.23.0rc1": 17634, "v0.23.0rc2": 17636, "v0.23.1": 17755, "v0.23.2": 17792, "v0.23.3": 17796, "v0.23.4": 17804, "v0.24.0": 19155, "v0.24.0.dev0": 17694, "v0.24.0rc1": 19068, "v0.24.1": 19250, "v0.24.2": 19491, "v0.25.0": 20377, "v0.25.0.dev0": 19156, "v0.25.0rc0": 20273, "v0.25.1": 20700, "v0.25.2": 21099, "v0.25.3": 21236, "v0.26.0.dev0": 20378, "v0.4.0": 862, "v0.4.1": 926, "v0.4.2": 981, "v0.4.3": 1029, "v0.5.0": 1185, "v0.6.0": 1342, "v0.6.1": 1440, "v0.7.0": 2072, "v0.7.0rc1": 1812, "v0.7.1": 2196, "v0.7.2": 2358, "v0.7.3": 2539, "v0.8.0": 3426, "v0.8.0b1": 3088, "v0.8.0b2": 3276, "v0.8.0rc1": 3374, "v0.8.0rc2": 3375, "v0.8.1": 3566, "v0.9.0": 4041, "v0.9.0rc1": 3927, "v0.9.0rc2": 3970, "v0.9.1": 4306, "v0.9.1rc1": 4264, "v1.0.0rc0": 22249}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}